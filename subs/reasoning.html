<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Advances at the LLM Frontier – Generative AI for Economic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fad5ab29a14bbe0a7a7d29177f3f13bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" type="text/css" href="expandable.css">
<script src="expandable.js"></script>
<script src="references1.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Generative AI for Economic Research</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../get-started.html"> 
<span class="menu-text">Get Started</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-new-developments" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">New Developments</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-new-developments">    
        <li>
    <a class="dropdown-item" href="../subs/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/reasoning.html">
 <span class="dropdown-text">Reasoning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/access.html">
 <span class="dropdown-text">Access Modes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/search.html">
 <span class="dropdown-text">Search</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/improvements.html">
 <span class="dropdown-text">Technical Improvements</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/practical.html">
 <span class="dropdown-text">Practical Applications</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-applications" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Applications</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-applications">    
        <li>
    <a class="dropdown-item" href="../applications.html">
 <span class="dropdown-text">Summary</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/ideation.html">
 <span class="dropdown-text">Ideation and Feedback</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/writing.html">
 <span class="dropdown-text">Writing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/background.html">
 <span class="dropdown-text">Background Research</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/data.html">
 <span class="dropdown-text">Data Analytics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/math.html">
 <span class="dropdown-text">Mathematical Derivations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/promoting.html">
 <span class="dropdown-text">Promoting Research</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../resources.html"> 
<span class="menu-text">Further Resources</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/genaiforecon/site"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#advances-in-reasoning" id="toc-advances-in-reasoning" class="nav-link active" data-scroll-target="#advances-in-reasoning">Advances in Reasoning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Advances at the LLM Frontier</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="advances-in-reasoning" class="level1">
<h1>Advances in Reasoning</h1>
<p>
One of the most significant advances in recent months is that LLMs are becoming better at reasoning. Traditional LLMs generate output via token-by-token prediction, as described, e.g., in Section 2 of the originally published version of this paper <span class="reference" id="korinek23GenAI" style="p"></span>. Although this basic architecture has proven surprisingly powerful, it makes it hard for basic LLMs to go back in the text that they have already generated to reason about it and iteratively improve it, as humans do when they write. A good analogy is that token generation by LLMs proceeds like a human's stream-of-consciousness. This makes it easy for such systems to emulate what <span class="reference" id="kahneman2011thinking"></span> called system-1 thinking but difficult to perform cognitive tasks that correspond to system-2 thinking and require reasoning. For example, a famous test that poses no problem for fourth-graders but has regularly tripped up even the most advanced LLMs before o1 was the so-called strawberry test: asking an LLM "How many R's are there in strawberry?" typically delivers 

<span class="footnote" word="false responses.">
    One of the reasons for this rather basic failure is that LLMs encode text not in letters, as we do in the English language, but in tokens that correspond to syllables or words and that imply that the spelling is not directly observable for LLMs when they process text. This implies that the model needs to reason about the English spelling corresponding to the underlying tokens. <span class="reference" id="dellacqua2023jaggedfrontier"></span> use the term "jagged frontier" to observe that LLMs easily perform some tasks but fail at other tasks that are of seemingly similar difficulty for humans. 
</span>
</p>

<p>
Aware of these limitations, researchers have worked hard on finding ways to enable LLMs to become better at reasoning <span class="reference" id="huang2023survey"></span>, <span class="reference" id="plaat2024reasoning"></span>. An influential mechanism to obtain better-reasoned results has been chain-of-thought prompting, which instructs LLMs to proceed step-by-step when generating responses to a prompt. This technique has delivered significant performance gains by guiding LLMs to break down complex questions into smaller logical steps that are easier to accomplish—akin to a student who performs better on an exam when asked to report his intermediate steps. <span class="reference" id="wei2022chain"></span> show that chain-of-thought prompting considerably improves LLM performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. 

For example, when given a question like "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?" they show that OpenAI's GPT-3 from 2020 failed ("The answer is 27.") but succeeds when guided to reason through the calculation, producing the answer: "The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9."

</p>

<p>
When academics reason about a novel research problem, an additional strategy that they employ is to perform a sort of tree search: they generate different hypotheses, evaluate them, pursue the most promising ones, and refine them further. Recent advances in LLM-based reasoning attempt to emulate this process. For example, <span class="reference" id="yao2023tree"></span> propose what they call a tree-of-thoughts technique, which extends chain-of-thought prompting by generating multiple intermediate steps or proverbial "thoughts" at each stage of the reasoning process. This allows LLMs to explore different paths of reasoning, evaluate their potential, and select the most promising ones to continue—much like, for example, a chess engine evaluating different moves. This approach has shown particular promise in solving complex reasoning tasks that require planning and strategic thinking. In spring 2024, Anthropic introduced a feature that allows Claude to engage in short episodes of reasoning that are hidden from the user behind a message like "Thinking deeply..." or "Ruminating..." before generating output. This led to clear performance gains, but with little fanfare.


</p>

<p>
OpenAI's o1 series of models, released on September 12, 2024, is the first that is explicitly designed for LLM-based <span class="footnote" word="reasoning">
    Originally nicknamed "Q*" and later "strawberry," its creators argued that the system's architecture is sufficiently different from its earlier GPT series to merit a new name that is simply an abbreviation of "OpenAI 1."
</span> <span class="reference" id="openai2024learning" style="p">.

Although an official description of the model's architecture is not publicly available, OpenAI seems to have employed reinforcement learning to hone the model's automated use of the two techniques described in the preceding two paragraphs: it employs a chain-of-thought technique to break down complex steps into simpler ones while also employing a form of tree search to attempt different approaches to solving a problem and to recognize and correct mistakes. 

Unlike earlier LLMs, o1 models react to prompts by first generating reasoning tokens that are hidden from the user—akin to a simulated inner monologue—as the model "thinks" through the problem at hand. Depending on the question, this may take from a few seconds to several minutes. Once the hidden thinking process is finished, the model generates a response for the user that summarizes the outcome of the reasoning process. 

This mechanism has enabled o1 to achieve significant gains in reasoning compared to GPT-4o, which itself was a leader in this category before o1's release. However, <span class="reference" id="mirzadeh2024reasoning"></span> document that even the reasoning capabilities of o1 still have significant shortcomings, for example, that small changes in numbers or the addition of irrelevant information reduce model performance.


</span></p>
<p>The o1 series consists of several models. In Sept.&nbsp;2024, OpenAI released a preview version of the full model, o1-preview, as well as a smaller and more cost-efficient model, o1-mini, which is particularly well-suited for math and coding applications and better than o1-preview in some of these applications. The full version o1 is the most powerful of the three and expected later in fall 2024. <a href="#fig:o1-benchmarks"> Figure 2 </a> visualizes the advances compared to GPT-4o on three benchmarks: in the American Invitational Mathematics Examination (AIME), the qualifying exam for the US Mathematical Olympiad, o1 performed at a level corresponding to the top-500 contestants; in the Codeforces programming competition, it performed at the 89th percentile of participants; in the hardest (diamond) category of the Graduate-Level Google-Proof Q&amp;A benchmark, which tests for complex reasoning abilities in biology, chemistry, and physics, it outperformed PhD-level human experts.</p>
<div class="figure" id="fig:o1-benchmarks">
    <div style="text-align: center;">
        <img src="o1-benchmarks.png" alt="o1's performance on reasoning benchmarks" style="width: 100%;">
        <p class="caption">
            <b>Figure <span id="fig:o1-benchmarks">2</span></b>: o1's performance on reasoning benchmarks. <br>
            <small>Source: <span class="reference" id="openai2024learning"></span>. Note: Solid bars show one-shot accuracy; shaded regions show performance of a majority vote of 64 responses.</small>
        </p>
    </div>
</div>

Interestingly, o1 also fundamentally changes the economics of operating frontier AI models: Under the traditional LLM paradigm, the computational cost of training models exceeded the cost of generating output (inference) by orders of magnitude. By contrast, o1 relies heavily on generating reasoning tokens during inference, and—in analogy to the scaling laws for training LLMs discussed in Section 2 of the original article—the model's responses improve predictably in the amount of reasoning tokens employed <span class="reference" id="openai2024learning"></span>. This implies far greater variable costs compared to traditional LLMs. At present, o1 models are only available to OpenAI's paying customers, with limits on the number of queries that can be performed per week.
<p>
The following reproduces an experience of mine with o1-preview for a task that was far beyond the capabilities of earlier LLMs:
</p>
<!-- First Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Prompt:</b> The following is a no-arbitrage relationship between an interest rate on new long-term debt in period \( t \), \( R_{N,t} \), and expected future short-term rates, \( R_{t+s} \):</span>
        <span class="prompt_rest inline-expand" id="content1p">
            <p>
                \[
                \frac{1}{R_{N,t}+\delta}=E\sum_{i=0}^{\infty}\left[\frac{\left(1-\delta\right)^{i}}{\prod_{s=0}^{i}\left(1+R_{t+s}\right)}\right]
                \]
            </p>
            <p>
                Can you log-linearize this expression around the steady-state value of the interest rates, which we denote by \( R^\ast \), and which is the same for both interest rates? Denote deviations from the steady state with lower-case variables.
            </p>
        </span>
        <a href="#" class="expandable-toggle" data-target="content1p">[+] click to expand</a>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (o1-preview):</b> (Thought for 53 seconds)</div>
    <a href="#" class="expandable-toggle" data-target="content1">[+] click to expand</a>
    <div id="content1" class="response_rest">
        <p><b>Original Equation:</b></p>
        <p>
            \[
            \frac{1}{R_{N,t} + \delta} = E_t \left[ \sum_{i=0}^\infty \frac{(1 - \delta)^i}{\prod_{s=0}^{i} (1 + R_{t+s})} \right]
            \]
        </p>

        <p><b>Steady State Analysis:</b></p>
        <p>At steady state, \( R_{N,t} = R^\ast \) and \( R_{t+s} = R^\ast \). The equation simplifies to:</p>
        <p>
            \[
            \frac{1}{R^\ast + \delta} = \frac{1}{1 + R^\ast} \cdot \frac{1}{1 - k}
            \]
        </p>
        <p>where \( k = \frac{1 - \delta}{1 + R^\ast} \).</p>

        <p><b>Log-Linearization Steps:</b></p>
        <ol>
            <li>
                <b>Left-Hand Side (LHS):</b> Expand \( \frac{1}{R_{N,t} + \delta} \) around \( R^\ast \):
                \[
                \frac{1}{R_{N,t} + \delta} \approx \frac{1}{R^\ast + \delta} \left(1 - \frac{r_{N,t}}{R^\ast + \delta}\right)
                \]
            </li>
            <li>
                <b>Right-Hand Side (RHS):</b> Approximate numerator and denominator:
                <ul>
                    <li><b>Denominator:</b>
                        \[
                        \prod_{s=0}^{i} (1 + R_{t+s}) \approx (1 + R^\ast)^{i+1} \exp\left(\frac{1}{1 + R^\ast} \sum_{s=0}^{i} r_{t+s}\right)
                        \]
                    </li>
                    <li><b>Numerator:</b>
                        \[
                        (1 - \delta)^i \approx e^{-i\delta}
                        \]
                    </li>
                </ul>
            </li>
            <li>
                <b>Final Log-Linearized Expression:</b>
                \[
                r_{N,t} = (1 - k) \sum_{s=0}^\infty k^s r_{t+s}
                \]
            </li>
        </ol>

        <p><b>Answer:</b> Yes; the log-linearized expression is:</p>
        <p>
            \[
            r_{N,t} = (1 - k) \sum_{s=0}^\infty k^s r_{t+s}
            \]
        </p>
        <p>where \( k = \frac{1 - \delta}{1 + R^\ast} \).</p>
    </div>
</div>

<!-- Second Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Follow-up Prompt:</b> Great. Can you express this as a forward difference equation in the style of \( r_{N,t} = \text{coeff1} \cdot r_{N,t+1} + \text{coeff2} \cdot r_{t} \)?</span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (o1-preview):</b> (Thought for 22 seconds) Yes, we can express the log-linearized relationship as a forward difference equation: </div>
    <a href="#" class="expandable-toggle" data-target="content1c">[+] click to expand</a>
    <div id="content1c" class="response_rest">
        <p>
            \[
            r_{N,t} = k \, r_{N,t+1} + (1 - k) \, r_t
            \]
        </p>
        <p>where \( k = \frac{1 - \delta}{1 + R^\ast} \).</p>

        <p><b>Derivation:</b></p>
        <p><a href="https://chatgpt.com/share/672e8f7a-56c8-8002-a79f-adcc3f488092" target="_blank">(Link to full derivation)</a></p>

        <p><b>Final Answer:</b></p>
        <p>
            \[
            r_{N,t} = k \, r_{N,t+1} + (1 - k) \, r_t
            \]
        </p>
        <p>where \( k = \frac{1 - \delta}{1 + R^\ast} \).</p>
    </div>
</div>
<div class="expandable-container-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Analysis:</b> This example illustrates that even o1-preview, which is less capable than the ultimate o1, can perform complex mathematical derivations that can save researchers significant amounts of time.</span>
        <span class="prompt_rest inline-expand" id="contentAnalysis1">
            I should note that the prompt in the chat contains an important hint for how to efficiently approach the problem, that the steady state of the two interest rate variables will be the same. Without this hint, the system struggled. Even with the hint, the model occasionally produced mistakes in derivations such as the one requested in the chat but was frequently able to correct mistakes when I pointed them out. Moreover, the derivation steps reported in the example appear at times a bit clumsy—it looks like this LLM is still "in its infancy".
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="contentAnalysis1">[+]</a>
    </div>
</div>

According to <span class="reference" id="jones2024awe"></span>, o1 has impressed many scientists with its complex problem-solving performance, which is particularly beneficial in disciplines that rely on mathematical modeling. While o1 can reason through problems step by step, they also noted that these chains of thoughts can increase the risk of "hallucinations." 

<p>For complex coding tasks, o1 excels at following, generating, and debugging intricate code structures. Its reasoning capabilities enable it to tackle problems that require deeper contextual understanding and strategic thinking than earlier LLMs, making it particularly valuable for academics working on sophisticated coding projects. The following example documents o1-preview’s response to a request to code a solution ot the Ramsey growth model, which earlier LLMs could not do (as documented in the December 2023 version of the paper):</p>
<!-- First Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Prompt:</b> Can you write Python code to solve the Ramsey growth model for standard parameter values?</span>
        <a href="#" class="expandable-toggle" data-target="content2p">[+] click to expand</a>
        <span class="prompt_rest inline-expand" id="content2p">
            <p>(o1-preview)</p>
        </span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (o1-preview):</b> Thought for 34 seconds</div>
    <a href="#" class="expandable-toggle" data-target="content2">[+] click to expand</a>
    <div id="content2" class="response_rest">
        <p>Certainly! Below is Python code that solves the Ramsey growth model using standard parameter values. The code sets up the differential equations representing the Ramsey model, computes the steady-state values, and then uses a shooting method to find the optimal initial consumption that leads to convergence to the steady state. It then simulates the model over time and plots the capital and consumption per capita.</p>

        <pre><code class="language-python">
import numpy as np
from scipy.integrate import solve_ivp
from scipy.optimize import root_scalar
import matplotlib.pyplot as plt

# Parameters
alpha = 0.3   # Output elasticity of capital
rho = 0.04    # Time preference rate
delta = 0.05  # Depreciation rate
theta = 2.0   # Coefficient of relative risk aversion (CRRA)
n = 0.01      # Population growth rate

# Steady-state capital per capita
k_star = (alpha / (rho + delta)) ** (1 / (1 - alpha))
# Steady-state consumption per capita
c_star = k_star ** alpha - (n + delta) * k_star

print(f"Steady-state capital per capita (k*): {k_star:.4f}")
print(f"Steady-state consumption per capita (c*): {c_star:.4f}")

# Initial capital per capita (start below steady state)
k0 = 0.5 * k_star

# Time span for the simulation
t_span = [0, 100]  # From t=0 to t=100
t_eval = np.linspace(t_span[0], t_span[1], 1000)  # Time points for evaluation

# Differential equations of the Ramsey model
def ramsey(t, y):
    k, c = y
    dkdt = k ** alpha - c - (n + delta) * k
    dcdt = (1 / theta) * (alpha * k ** (alpha - 1) - rho - delta) * c
    return [dkdt, dcdt]

# Shooting method to find the optimal initial consumption c0
def shooting_function(c0):
    y0 = [k0, c0]
    sol = solve_ivp(ramsey, t_span, y0, t_eval=t_eval, method='RK45')
    k_T = sol.y[0, -1]
    return k_T - k_star  # We want k(T) to be close to k_star

# Initial guesses for c0
c0_lower = 0.1 * c_star
c0_upper = 2.0 * c_star

# Use root_scalar to find the root of the shooting function
res = root_scalar(shooting_function, bracket=[c0_lower, c0_upper], method='brentq')
if res.converged:
    c0 = res.root
    print(f"Optimal initial consumption per capita (c0): {c0:.4f}")
else:
    raise ValueError("Root-finding did not converge to a solution.")

# Simulate the model with the optimal initial consumption
y0 = [k0, c0]
sol = solve_ivp(ramsey, t_span, y0, t_eval=t_eval, method='RK45')
k = sol.y[0]
c = sol.y[1]
t = sol.t

# Plotting the results
plt.figure(figsize=(12, 5))

# Plot for capital per capita over time
plt.subplot(1, 2, 1)
plt.plot(t, k, label='Capital per capita (k)')
plt.axhline(y=k_star, color='r', linestyle='--', label='Steady-state k*')
plt.xlabel('Time')
plt.ylabel('Capital per capita (k)')
plt.title('Capital per Capita Over Time')
plt.legend()

# Plot for consumption per capita over time
plt.subplot(1, 2, 2)
plt.plot(t, c, label='Consumption per capita (c)')
plt.axhline(y=c_star, color='r', linestyle='--', label='Steady-state c*')
plt.xlabel('Time')
plt.ylabel('Consumption per capita (c)')
plt.title('Consumption per Capita Over Time')
plt.legend()

plt.tight_layout()
plt.show()
        </code></pre>

        <p><b>Explanation:</b></p>
        <ul>
            <li><b>Parameters:</b> The code uses standard parameter values commonly found in the literature.</li>
            <li><b>Steady-State Calculation:</b> It computes the steady-state values of capital and consumption per capita.</li>
            <li><b>Differential Equations:</b> The <code>ramsey</code> function defines the system of differential equations for capital accumulation and consumption growth.</li>
            <li><b>Shooting Method:</b> The <code>shooting_function</code> uses a shooting method to find the optimal initial consumption <code>c0</code> that ensures convergence to the steady state.</li>
            <li><b>Simulation:</b> It simulates the model over the specified time span using <code>solve_ivp</code>.</li>
            <li><b>Plotting:</b> The results are plotted to show the paths of capital and consumption per capita over time.</li>
        </ul>

        <p><b>Output:</b></p>
        <p>The code will display the steady-state values and the optimal initial consumption. It will then produce two plots showing how capital per capita and consumption per capita evolve over time, converging to their steady-state values.</p>

        <p><b>Notes:</b></p>
        <p>The shooting method is essential because the Ramsey model is saddle-path stable, meaning there is a unique consumption path that leads to the steady state from a given initial capital stock. If the root-finding does not converge, you may need to adjust the initial guesses for <code>c0</code> or check the parameter values.</p>

        <p>This code provides a complete solution to the Ramsey growth model using standard parameter values and should serve as a solid foundation for further analysis or extensions of the model.</p>
    </div>
</div>
<div class="expandable-container-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Analysis:</b> The code is written elegantly and explained well. </span>
        <span class="prompt_rest inline-expand" id="content-ramsey">
            <div style="text-align: center;">
                <img src="o1-ramsey.png" alt="Solution to Ramsey model produced by o1" style="width: 80%;">
                <p class="caption">
                    <b>Figure <span id="fig:ramsey">4</span></b>: Solution to Ramsey model produced by o1
                </p>
            </div>
        </span>
        <a href="#" class="expandable-toggle2" data-target="content-ramsey">[+] click to see figure </a>
    </div>
</div>



<p>
Meta recently published a paper on an approach called "Thought Preference Optimization" that demonstrates that the benefits of LLMs thinking can extend even further <span class="reference" id="wu2024thinkingllms"></span>. Their method shows that optimizing thought generation before responding improves performance across a broad range of applications, from marketing and content creation to general knowledge tasks. It is likely that this approach will be implemented by future versions of Meta's open-source models.
</p>
<p>
<i> The Road to LLM Agents </i> -- A key strategic goal of frontier AI labs is to evolve LLMs into autonomous AI agents—systems that can maintain objectives across multiple exchanges, plan sequences of actions, and independently pursue specified goals <span class="reference" id="Heikkila2024" style="p"></span>. While current LLMs primarily react to immediate prompts, agents would proactively gather information, formulate plans, and take actions to accomplish tasks. The advances in reasoning capabilities described above represent a crucial step toward this goal, as autonomous agents require the ability to plan multi-step actions and revise strategies based on outcomes.
</p>
<p>Two other key requirements for agency are already emerging: first, the ability to maintain coherent objectives over time through long-term memory and expanded context windows, as discussed earlier in this section; and second, the capability to interact with external tools and APIs to gather information and take actions in the world. The latter developments will be covered in the next subsection on access modes, particularly in the context of LLMs’ autonomous “computer use” capabilities, and in the ensuing subsection on LLM-powered search, which gives LLMs real-time internet access. As these components come together, we may see LLMs evolve from passive tools into more active research collaborators.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>