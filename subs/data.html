<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Applications of LLMs – Generative AI for Economic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fad5ab29a14bbe0a7a7d29177f3f13bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" type="text/css" href="expandable.css">
<script src="expandable.js"></script>
<script src="references1.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Generative AI for Economic Research</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../get-started.html"> 
<span class="menu-text">Get Started</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-new-developments" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">New Developments</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-new-developments">    
        <li>
    <a class="dropdown-item" href="../subs/overview.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/reasoning.html">
 <span class="dropdown-text">Reasoning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/access.html">
 <span class="dropdown-text">Access Modes</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/search.html">
 <span class="dropdown-text">Search</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/improvements.html">
 <span class="dropdown-text">Technical Improvements</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/practical.html">
 <span class="dropdown-text">Practical Applications</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-applications" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Applications</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-applications">    
        <li>
    <a class="dropdown-item" href="../applications.html">
 <span class="dropdown-text">Summary</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/ideation.html">
 <span class="dropdown-text">Ideation and Feedback</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/writing.html">
 <span class="dropdown-text">Writing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/background.html">
 <span class="dropdown-text">Background Research</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/coding.html">
 <span class="dropdown-text">Coding</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/data.html">
 <span class="dropdown-text">Data Analytics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/math.html">
 <span class="dropdown-text">Mathematical Derivations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../subs/promoting.html">
 <span class="dropdown-text">Promoting Research</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../resources.html"> 
<span class="menu-text">Further Resources</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/genaiforecon/site"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-analysis" id="toc-data-analysis" class="nav-link active" data-scroll-target="#data-analysis">Data Analysis</a>
  <ul class="collapse">
  <li><a href="#locating-data-sources" id="toc-locating-data-sources" class="nav-link" data-scroll-target="#locating-data-sources">Locating Data Sources</a></li>
  <li><a href="#creating-figures" id="toc-creating-figures" class="nav-link" data-scroll-target="#creating-figures">Creating Figures</a></li>
  <li><a href="#extracting-data-from-text" id="toc-extracting-data-from-text" class="nav-link" data-scroll-target="#extracting-data-from-text">Extracting Data from Text</a></li>
  <li><a href="#reformatting-data" id="toc-reformatting-data" class="nav-link" data-scroll-target="#reformatting-data">Reformatting Data</a></li>
  <li><a href="#classifying-and-scoring-text" id="toc-classifying-and-scoring-text" class="nav-link" data-scroll-target="#classifying-and-scoring-text">Classifying and Scoring Text</a></li>
  <li><a href="#extracting-sentiment" id="toc-extracting-sentiment" class="nav-link" data-scroll-target="#extracting-sentiment">Extracting Sentiment</a></li>
  <li><a href="#simulating-human-test-subjects" id="toc-simulating-human-test-subjects" class="nav-link" data-scroll-target="#simulating-human-test-subjects">Simulating Human Test Subjects</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Applications of LLMs</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="data-analysis" class="level1">
<h1>Data Analysis</h1>
<div class="expandable-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start_minimal">
            LLMs can help locate data sources, format data, extract data from text, classify and score text, create figures, extract sentiment, and even simulate human test subjects. Most of these capabilities can be accessed not only through a web interface as shown in the demonstrations below, but also via an API (Application Programming Interface)
        </span>
        <span class="prompt_rest_minimal inline-expand" id="content3031">
            that allows large amounts of data to be formatted, extracted, classified etc. The operations can also be performed in batches to remain within the token limit for each request. Moreover, building on the section on coding, it goes without saying that LLMs can write the computer code necessary to access their own APIs—for example, try out "Write python code to ask GPT-4 to do any data extraction or manipulation task. 
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content3031">[+]</a>
    </div>
</div>

<div class="expandable-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start_minimal">
            When performing data analysis tasks in bulk, cost is an important consideration. Although a single prompt to a cutting-edge LLM costs just fractions of a cent, the cost of performing thousands or millions of queries quickly adds up. For many of the tasks described below, smaller and cheaper models are available. In those cases, it is not advisable to use the most cutting-edge LLM. 
        </span>
        <span class="prompt_rest_minimal inline-expand" id="content3031p2">
            <br>
            <p> </p>
            This category has benefited from the growing accuracy of LLMs, which now rival humans in tasks like classifying text or extracting sentiment. For individual researcher use, collaborative tools for data analysis in ChatGPT and Claude are becoming increasingly powerful and user-friendly. For bulk data analysis, cost declines and better models are making it possible to process larger and larger amounts of data. 
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content3031p2">[+]</a>
    </div>
</div>

<section id="locating-data-sources" class="level2">
<h2 class="anchored" data-anchor-id="locating-data-sources">Locating Data Sources</h2>
<p>LLMs can be useful starting from the first step of data analysis, i.e., in identifying and locating appropriate data sources. The following example illustrates the role that Claude 3 can play in advising users on what data sources to consider:</p>
<!-- First Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b> Prompt: </b> What data would be useful to analyze the effects of AI on the labor market and where can I find it? </span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b> Response (Claude 3): </b> To analyze the effects of AI on the labor market, you would need data from various sources. Here are some key data points and potential sources:</div>
    <a href="#" class="expandable-toggle" data-target="content31">[+] click to expand</a>
    <div id="content31" class="response_rest">
        <ol>
            <li><b>Employment data by industry and occupation</b>
                <ul>
                    <li>Bureau of Labor Statistics (BLS) in the US</li>
                    <li>Eurostat for European countries</li>
                    <li>National statistical agencies of other countries</li>
                </ul>
            </li>

            <li><b>Adoption rates of AI technologies by industry</b>
                <ul>
                    <li>Market research reports from companies like Gartner, IDC, or McKinsey</li>
                    <li>Academic studies and surveys</li>
                    <li>Company reports and press releases</li>
                </ul>
            </li>

            <li><i>[Points 3. to 9. omitted for space reasons.]</i></li>
        </ol>

        <p>Combining data from these various sources can provide a comprehensive picture of how AI is affecting the labor market across industries, occupations, and demographic groups. It's important to note that data availability and quality may vary across countries and regions.</p>
    </div>
</div>
<div class="expandable-container-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b> Analysis: </b> Although the list provided by Claude is somewhat of a laundry list and generic, it serves as a good brainstorming basis that may give the researcher ideas about novel data sources. Moreover, Claude is also happy to offer follow-up advice on how to best download data sources and how to best clean them.
        </span>
    </div>
</div>

</section>
<section id="creating-figures" class="level2">
<h2 class="anchored" data-anchor-id="creating-figures">Creating Figures</h2>
<p>As described in <a href="../subs/access.html">the access page</a> on workspaces for interactive LLM collaboration, one of the most useful functions of ChatGPT for economists is Advanced Data Analysis, which employs the coding capabilities of GPT-4 to create versatile figures and graphs. In mid-2024, OpenAI made the resulting figures and graphs interactive.</p>
<p>In the following example, I uploaded a file that contained stock market prices for three large technology companies and instructed ChatGPT Advanced Data Analysis to create one graph displaying stock performance labeled with the corresponding betas and another graph displaying portfolio <span class="footnote" data-word="weights."> To compile the underlying stock market data, I asked ChatGPT to write a script to download the data, as described in the Online Appendix of the paper. </span></p>
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Prompt:</b> Can you display a graph that shows the performance of these securities normalized to start at 100? <b>[Uploaded stock_data.csv]</b>
        </span>
    </div>
    <hr>
    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start">
        <b>Response (ChatGPT Advanced Data Analysis):</b>
        <b>[Code generated and executed]</b>
    </div>
    <a href="#" class="expandable-toggle" data-target="content32">[+] click to expand</a>
    <div id="content32" class="response_rest">
        <p>
            The dataset contains the closing prices for the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&amp;P 500 index (^GSPC) over a certain period of time.
        </p>
        <p>
            Let's normalize the prices to start at 100 and plot the resulting performance of these securities. This normalization will allow us to compare the performance of the securities relative to their initial prices. To normalize the data, we'll divide all prices by their initial price and then multiply by 100.
        </p>
        <p><b>[Code generated and executed]</b></p>
        <p><b>[Code generated and executed]</b></p>
        <p>
            <b>LaTeX graphic inclusion:</b><br>
            <code>\begin{center} \includegraphics[width=0.8\textwidth]{performance1.png} \end{center}</code>
        </p>
        <p>
            Here is the graph showing the performance of the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&amp;P 500 index (^GSPC), all normalized to start at 100. The x-axis represents time (the dates), and the y-axis represents the normalized prices.
        </p>
        <p>
            From the graph, we can see how each of these securities has performed relative to its starting point over time. This type of comparison can be helpful when assessing the relative performance of different securities or indices.
        </p>
    </div>
</div>

<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Follow-up Prompt:</b> Calculate the beta for each of the stocks and add it to the legend. Change the colors to make them easier to distinguish. Use the title "One-Decade Performance of Three Big Tech Companies".
        </span>
    </div>
    <hr>
    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start">
        <b>Response (ChatGPT Advanced Data Analysis):</b>
        <b>[Code generated and executed]</b>
    </div>
    <a href="#" class="expandable-toggle" data-target="content32ctd">[+] click to expand</a>
    <div id="content32ctd" class="response_rest">
        <p>
            The beta of a stock is a measure of the stock's volatility in relation to the overall market. The overall market has a beta of 1.0, and individual stocks are ranked according to how much they deviate from the market.
        </p>
        <p>
            A stock that swings more than the market over time has a beta above 1.0. If a stock moves less than the market, the stock's beta is less than 1.0. High-beta stocks are supposed to be riskier but provide higher return potential; low-beta stocks pose less risk but also lower returns.
        </p>
        <p>
            Let's calculate the beta for each of these stocks over the given period. We can calculate beta using the formula:
        </p>
        $$
        \beta = \frac{Cov(r_E,r_M)}{Var(r_M)}
        $$
        <p>
            where:
        </p>
        <ul>
            <li>\( r_E \) is the return of the stock</li>
            <li>\( r_M \) is the return of the market</li>
            <li>\( Cov(r_E,r_M) \) is the covariance between the stock and market returns</li>
            <li>\( Var(r_M) \) is the variance of the market returns</li>
        </ul>
        <p>
            For the market return, we'll use the S&amp;P 500 index (^GSPC). We'll calculate daily returns for each stock and the market, then calculate the beta for each stock.
        </p>
        <p>
            After that, I'll recreate the graph with the new colors and the calculated betas included in the legend. The colors will be chosen to provide good contrast and clear visibility.
        </p>
        <p><b>[Code generated and executed]</b></p>
        <p>
            Here are the beta values for the stocks:
        </p>
        <ul>
            <li>Google (GOOG): 1.1317</li>
            <li>Meta (META): 1.2537</li>
            <li>Microsoft (MSFT): 1.2108</li>
        </ul>
        <p>
            These values indicate that all three stocks are generally more volatile than the market (S&amp;P 500), since their beta values are greater than 1.
        </p>
        <p>
            Now let's update the graph with the new title, colors, and the beta values in the legend.
        </p>
        <p><b>[Code generated and executed]</b></p>
        <p>
            <b>LaTeX graphic inclusion:</b><br>
            <code>\begin{center} \includegraphics[width=0.8\textwidth]{performance2.png} \end{center}</code>
        </p>
        <p>
            Here is the updated graph with the new title, colors, and beta values included in the legend.
        </p>
        <p>
            The graph represents the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&amp;P 500 index (^GSPC), all normalized to start at 100. The beta values for the stocks, which measure their volatility in relation to the overall market, are included in the legend.
        </p>
    </div>
</div>

<!-- Third Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Follow-up Prompt:</b> Double the size of the title, legend, axes labels and ticks. Label "^GSPC" in the legend as "S&amp;P 500".
        </span>
    </div>
    <hr>
    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start">
        <b>Response (ChatGPT Advanced Data Analysis):</b>
        <b>[Code generated and executed]</b>
    </div>
    <a href="#" class="expandable-toggle" data-target="content32ctd1">[+] click to expand</a>
    <div id="content32ctd1" class="response_rest">
        <p>
            <b>LaTeX graphic inclusion:</b><br>
            <code>\begin{center} \includegraphics[width=0.8\textwidth]{performance3.png} \end{center}</code>
        </p>
        <p>
            Here is the updated graph with the requested changes:
        </p>
        <ul>
            <li>The title, legend, axes labels, and ticks have all been doubled in size.</li>
            <li>The "^GSPC" label in the legend has been changed to "S&amp;P 500".</li>
        </ul>
        <p>
            This graph shows the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&amp;P 500 index, all normalized to start at 100. The beta values for the stocks are included in the legend.
        </p>
    </div>
</div>

<!-- Fourth Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Follow-up Prompt:</b> Assume I put $100 in each of the three stocks at the start. Can you show a pie chart that shows how much I would have in each stock now?
        </span>
    </div>
    <hr>
    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start">
        <b>Response (ChatGPT Advanced Data Analysis):</b>
        <b>[Code generated and executed]</b>
    </div>
    <a href="#" class="expandable-toggle" data-target="content32ctd2">[+] click to expand</a>
    <div id="content32ctd2" class="response_rest">
        <p>
            <b>LaTeX graphic inclusion:</b><br>
            <code>\begin{center} \includegraphics[width=0.8\textwidth]{piechart1.png} \end{center}</code>
        </p>
        <p>
            Here is a pie chart that shows the current value of a $100 investment made in each of the three big tech stocks (Google, Meta, and Microsoft) at the start of the period represented in the data.
        </p>
        <p>
            The pie chart is divided into three sections, each representing one of the stocks. The size of each section corresponds to the current value of the initial $100 investment in that stock, expressed as a percentage of the total value of all three investments. The percentages are also labeled on the chart for clarity.
        </p>
    </div>
</div>
<!-- Fifth Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Follow-up Prompt:</b> Can you label each position with its current dollar value in addition to the percentage? Can you make one of the pieces pop out of the pie?
        </span>
    </div>
    <hr>
    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start">
        <b>Response (ChatGPT Advanced Data Analysis):</b>
        <b>[Code generated and executed]</b>
    </div>
    <a href="#" class="expandable-toggle" data-target="content32ctd3">[+] click to expand</a>
    <div id="content32ctd3" class="response_rest">
        <p>
            <b>LaTeX graphic inclusion:</b><br>
            <code>\begin{center} \includegraphics[width=0.8\textwidth]{piechart2.png} \end{center}</code>
        </p>
        <p>
            Here is the updated pie chart. Each slice now includes both the current dollar value and the percentage of the total portfolio that it represents.
        </p>
        <p>
            The first slice, representing the Google stock, is "exploded" or offset from the pie to highlight it. This visual effect can be useful for emphasizing a particular piece of a pie chart. In this case, it emphasizes that Google has the highest value of the three stocks based on an initial $100 investment.
        </p>
        <p>
            <b>(Author's note:</b> the figure is correct, but ChatGPT's statement that Google has the highest value is false—this serves as a reminder that Advanced Data Analysis cannot "see" the figures it creates.)
        </p>
    </div>
</div>
<div class="expandable-container-minimal">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start">
            <b>Analysis:</b> Relying on the almost endless capabilities of Python, ChatGPT Advanced Data Analysis can display many other types of figures.
        </span>
    </div>
</div>

</section>
<section id="extracting-data-from-text" class="level2">
<h2 class="anchored" data-anchor-id="extracting-data-from-text">Extracting Data from Text</h2>
<p>A powerful capability of LLMs for data analysis is to extract data from written text. The following example is a simple illustration:</p>
<!-- First Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Prompt:</b> Mark got an A in econ and a B+ in math. Sally got an A- in both econ and math. Frank got a B in econ and a C in math. Reformat as follows: <br> Name &amp; econ grade &amp; math grade</span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (GPT-4):</b></div>
    <a href="#" class="expandable-toggle" data-target="content33">[+] click to expand</a>
    <div id="content33" class="response_rest">
        <p>Mark &amp; A &amp; B+<br>
        Sally &amp; A- &amp; A-<br>
        Frank &amp; B &amp; C</p>
    </div>
</div>
<!-- Analysis Box -->
<div class="expandable-container-minimal">
    <!-- INLINE EXPAND ANALYSIS -->
    <div>
        <span class="prompt_start"><b>Analysis:</b> The LLM correctly processes the meaning of the expression "both in econ and math" for Sally and extracts the grades accordingly.</span>
    </div>
</div>

</section>
<section id="reformatting-data" class="level2">
<h2 class="anchored" data-anchor-id="reformatting-data">Reformatting Data</h2>
<p>LLMs are equally versatile translating data into the desired format. Building on the previous example, I asked the LLM to format the data first into comma-separated values (CSV) format and then as a LaTeX table:</p>
<!-- First Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Follow-up Prompt:</b> Reformat in CSV format.</span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (GPT-4):</b></div>
    <a href="#" class="expandable-toggle" data-target="content_csv">[+] click to expand</a>
    <div id="content_csv" class="response_rest">
        <pre>Name,econ grade,math grade
Mark,A,B+
Sally,A-,A-
Frank,B,C
        </pre>
    </div>
</div>

<!-- Second Expandable Box -->
<div class="expandable-container">
    <!-- INLINE EXPAND PROMPT -->
    <div>
        <span class="prompt_start"><b>Follow-up Prompt:</b> Write as a LaTeX table.</span>
    </div>

    <hr>

    <!-- BLOCK EXPAND RESPONSE -->
    <div class="response_start"><b>Response (GPT-4):</b></div>
    <a href="#" class="expandable-toggle" data-target="content_latex">[+] click to expand</a>
    <div id="content_latex" class="response_rest">
        <pre>\begin{tabular}{lcc} 
    \hline 
    Name &amp; econ grade &amp; math grade \\ 
    \hline 
    Mark &amp; A &amp; B+ \\ 
    Sally &amp; A- &amp; A- \\ 
    Frank &amp; B &amp; C \\ 
    \hline 
\end{tabular}
        </pre>
    </div>
</div>
<div class="expandable-container-minimal">
    <div>
        <span class="prompt_start"><b>Analysis:</b> GPT-4 excelled at both these and other similar tasks.</span>
    </div>
</div>

</section>
<section id="classifying-and-scoring-text" class="level2">
<h2 class="anchored" data-anchor-id="classifying-and-scoring-text">Classifying and Scoring Text</h2>
<span> 
Social science research frequently employs statistical techniques to represent text as data <div class="reference" id="gentzkowal2019" style="p"></div>. Modern LLMs can go beyond traditional techniques for this because they are increasingly capable of processing the meaning of the sentences that they are fed. 
</span>

<div class="expandable-minimal">
    <div>
        <span class="prompt_start_minimal">The following example asks GPT-4 to classify whether a given task listed in the US Department of Labor's Occupational Information Network (O*NET) database is easy or hard to automate</span>
        <span class="prompt_rest_minimal inline-expand" id="content3334"> 
            and to justify its classification.
            <span class="footnote" word="classification.">
                <div class="reference" id="eloundoual23"></div> employ GPT-4 in this manner to systematically estimate the labor market impact of LLMs.
            </span> 
            Following the principle of chain-of-thought prompting suggested by <div class="reference" id="wei2022chain"></div>, the prompt asks first for the justification in order to induce the LLM to reason about its response before performing the actual classification. This is akin to asking a student to think before they respond to a question.
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content3334">[+]</a>
    </div>
</div>
<div class="expandable-container">
    <div>
        <span class="prompt_start">
            <b>Prompt (GPT-4):</b> Here are 5 tasks from O*Net:
        </span>
        <span class="prompt_rest inline-expand" id="content34_prompt">
            <ol>
                <li>Monitor operational records and reports to ensure accuracy and efficiency.</li>
                <li>Develop and implement policies and procedures for recordkeeping.</li>
                <li>Prepare and maintain employee records.</li>
                <li>Maintain and update filing, inventory, mailing, and database systems.</li>
                <li>Compile and prepare reports, charts, and graphs.</li>
            </ol>
            Provide a 5-10-word description of how easy to automate each task is and classify into "easy" or "hard" to automate. Provide your output in the form of a table with the following columns: no; task; justification; classification.
        </span>
        <a href="#" class="expandable-toggle" data-target="content34_prompt">[+] click to expand</a>
    </div>

    <hr>

    <div class="response_start"><b>Response (GPT-4):</b></div>
    <a href="#" class="expandable-toggle" data-target="content34">[+] click to expand</a>
    <div id="content34" class="response_rest">
        
<table class="caption-top table" data-quarto-postprocess="true" data-border="1" data-cellpadding="5" data-cellspacing="0">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">Task</th>
<th data-quarto-table-cell-role="th">Justification</th>
<th data-quarto-table-cell-role="th">Result</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Monitor operational records and reports to ensure accuracy and efficiency.</td>
<td>Requires understanding of context and critical thinking.</td>
<td>Hard</td>
</tr>
<tr class="even">
<td>2</td>
<td>Develop and implement policies and procedures for recordkeeping.</td>
<td>Requires human judgement and decision making.</td>
<td>Hard</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Prepare and maintain employee records.</td>
<td>Mostly data entry and retrieval, easily automated.</td>
<td>Easy</td>
</tr>
<tr class="even">
<td>4</td>
<td>Maintain and update filing, inventory, mailing, and database systems.</td>
<td>Mostly data entry and retrieval, easily automated.</td>
<td>Easy</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Compile and prepare reports, charts, and graphs.</td>
<td>Data processing and visualization can be automated.</td>
<td>Easy</td>
</tr>
</tbody>
</table>

    </div>
</div>
<div class="expandable-container-minimal">
    <div>
        <span class="prompt_start">
            <b>Analysis:</b> The results are reasonable, although I should emphasize that they are not entirely robust. Just like a human evaluator who may make different calls depending on seemingly random circumstances, the model's answers to what is essentially the same question change when the wording of the prompt is changed—and in some cases even when the order of the listed tasks is modified.
        </span>
    </div>
</div>

</section>
<section id="extracting-sentiment" class="level2">
<h2 class="anchored" data-anchor-id="extracting-sentiment">Extracting Sentiment</h2>
<p>LLMs can also extract sentiment from text. They can, for example, classify tweets into “positive” or “negative”. Similarly, they can categorize statements by the Federal Open Market Committee (FOMC) that sets US interest rates, as illustrated in the following example:</p>
<div class="expandable-container">
   <div>
       <span class="prompt_start">
           <b>Prompt (GPT-4):</b> Is the following FOMC statement from December 2022 hawkish or dovish?
       </span>
       <span class="prompt_rest inline-expand" id="content35_prompt">
           <p>
           Recent indicators point to modest growth in spending and production... 
           <a href="https://www.federalreserve.gov/newsevents/pressreleases/monetary20221214a.htm" target="_blank">
               [From federalreserve.gov, remainder omitted for space reasons]
           </a>
           </p>
       </span>
       <a href="#" class="expandable-toggle" data-target="content35_prompt">[+] click to expand</a>
   </div>

   <hr>

   <div class="response_start"><b>Response (GPT-4):</b> The statement is <b>hawkish</b>.</div>
   <a href="#" class="expandable-toggle" data-target="content35">[+] click to expand</a>
   <div id="content35" class="response_rest"> <p> The FOMC is indicating a concern about elevated inflation and is taking action by raising the target range for the federal funds rate and reducing its holdings of Treasury securities and agency debt. The statement also suggests that further increases in the target range may be appropriate in the future to return inflation to the 2 percent objective. This indicates a tightening of monetary policy, which is a characteristic of a hawkish stance.</p>
   </div>
</div>

<div class="expandable-container-minimal">
   <div>
       <span class="prompt_start">
           <b>Analysis:</b> The assessment is correct and well-argued. 
       </span>
   </div>
</div>
<div class="expandable-minimal">
    <div>
        <span class="prompt_start_minimal">
            I also explored whether the LLM could identify whether the December 2022 or February 2023 FOMC statement was more hawkish, but its ability to assess Fed-speak was not quite nuanced enough
        </span>
        <span class="prompt_rest_minimal inline-expand" id="content3637">
            — it focused mainly on the level of interest rates in February 2023 being higher as opposed to the small and nuanced changes in the text of the statement that indicated a potential change in direction. It did so even when I explicitly instructed it to report its assessment while “disregarding the target level for the federal funds rate.” Only when I manually replaced the numbers for the target level by “[range]” did the system correctly replicate the assessment that the February 2023 statement was slightly more dovish, as was widely reported in the financial press at the
            <span class="footnote" word="time.">
                See, for example, 
                <a href="https://www.cnbc.com/2023/02/01/live-updates-fed-rate-hike-february.html" style="font-size:90%; color:blue; text-decoration:underline;" target="_blank">
                    CNBC coverage
                </a>.
            </span> 
            <div class="reference" id="ardekani2023econsentgpt"></div> develop an economic sentiment prediction model along similar lines and employ it to analyze US economic news and the ECB's monetary policy announcements.
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content3637">[+]</a>
    </div>
</div>


</section>
<section id="simulating-human-test-subjects" class="level2">
<h2 class="anchored" data-anchor-id="simulating-human-test-subjects">Simulating Human Test Subjects</h2>
<div class="expandable-container-minimal">
    <div>
        <span class="prompt_start">
            <div class="reference" id="argyleb22"></div> propose the use of LLMs to simulate human subjects, based on the observation that the training data of LLMs contains a large amount of information about humanity.
        </span>
        <span class="prompt_rest inline-expand" id="content3839">
            They condition GPT-3 on the socio-demographic backstories of real humans and demonstrate that subsequent answers to survey questions are highly correlated with the actual responses of humans with the described backgrounds, in a nuanced and multifaceted manner. <div class="reference" id="Horton2022"></div> showcases applications to economics, using simulated test subjects to replicate and extend upon several behavioral experiments. <div class="reference" id="BrandIsraeliNgwe2023"></div> demonstrate how to use LLMs to obtain useful information for market research.
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content3839">[+]</a>
    </div>
</div>
<p>The following example illustrates the concept:</p>
<div class="expandable-container">
    <div>
        <span class="prompt_start"><b>Prompt (GPT-4):</b> For each of the following voters, provide a one-word rating to indicate whether they are more likely to approve or disapprove of a policy proposal to loosen US immigration restrictions on highly-educated workers:</span>
        <span class="prompt_rest inline-expand" id="content40_prompt">
            <ol>
                <li>A 32-year old female lawyer in Houston, TX who is Hispanic</li>
                <li>A 73-year old male retired doctor in Rome, GA who is Caucasian</li>
                <li>A 25-year old software engineer in San Francisco, CA who is Asian and identifies as non-binary</li>
                <li>A 45-year old female grocery check-out clerk in Brooklyn, NY who is second-generation Italian</li>
                <li>A 55-year old male insurance agent in Lake City, FL who is Caucasian</li>
            </ol>
        </span>
        <a href="#" class="expandable-toggle" data-target="content40_prompt">[+] click to expand</a>
    </div>

    <hr>

    <div class="response_start"><b>Response (GPT-4):</b></div>
    <a href="#" class="expandable-toggle" data-target="content40">[+] click to expand</a>
    <div id="content40" class="response_rest">
        <ol>
            <li>Approve</li>
            <li>Disapprove</li>
            <li>Approve</li>
            <li>Approve</li>
            <li>Disapprove</li>
        </ol>
    </div>
</div>
<div class="expandable-minimal">
    <div>
        <span class="prompt_start_minimal">
            There is a significant risk that the simulated results simply propagate false stereotypes, and they must hence be used with great care. However, they also contain valuable information.
        </span>
        <span class="prompt_rest_minimal inline-expand" id="content4142">
            If used correctly, they can provide useful insights about our society, from which all the data used to train the LLMs ultimately originate. For experimental economists who prefer keeping to human subjects, 
            <div class="reference" id="Charnessal2023"></div> describe how LLMs can help to improve the design and implementation of experiments. 
            <div class="reference" id="chang2024bestpracticesexperimental"></div> propose 12 best practices for generative AI in experimental research, ranging from the pre-treatment stage to the design and implementation stage, to the analysis stage.
        </span>
        <a href="#" class="expandable-toggle-minimal" data-target="content4142">[+]</a>
    </div>
</div>



</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>