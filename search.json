[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Further Resources",
    "section": "",
    "text": "One Useful Thing: Blog by Ethan Mollick, translating cutting-edge research into practical insights, often focused on AI's impacts on work and education. \n\n The Rundown AI: Newsletter providing a daily 5min summary of the latest AI news.  \n\nCoursera Course on the Economics of AI (graduate level) by Anton Korinek"
  },
  {
    "objectID": "subs/background.html",
    "href": "subs/background.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "There are a variety of tasks that researchers perform in order to conduct background research and learn about both existing and new work in their research area. These include summarizing text, searching relevant literature, seeking to understand new concepts, and translating text from other languages.\n        \n        \n            Advances in background research have derived primarily from the capacity of frontier LLMs to process larger and larger amounts of text in their context window. This enables cutting-edge systems to process multiple academic papers or books and even YouTube videos with growing accuracy. However, when performing literature reviews, LLMs still struggle with synthesizing the state of the art on a given research topic.\n        \n        [+]"
  },
  {
    "objectID": "subs/background.html#summarization",
    "href": "subs/background.html#summarization",
    "title": "Applications of LLMs",
    "section": "Summarization",
    "text": "Summarization\nFirst, LLMs are very capable at summarizing. They are adept at extracting the most relevant content from a passage of text, as illustrated here:\n\n\n    \n    \n         Prompt:  Summarize the following text in one sentence: [Abstract of this paper from earlier Chat inserted] \n    \n\n    \n\n    \n      Response (GPT-4):  \n    [+] click to expand\n    \n        The author discusses the potential of Generative AI, specifically large language models like ChatGPT, to revolutionize research in various domains such as ideation, writing, data analysis, coding, and mathematics, and suggests that economists can significantly increase productivity by automating micro tasks with AI, with the performance of these systems expected to improve over time.\n    \n\n\n\n    \n    \n          Analysis:  The summary sentence it provided covers all the important bases. \n    \n\n\nBoth Claude and ChatGPT have now a sufficiently large context window to process entire academic papers as well as many books. To provide an example, I used the \"Upload\" button to feed the original Feb 2023 NBER working paper version of this paper  into Claude 2 and asked for a short summary -- \"short\" in order to not take up too much space here: \n\n\n\n    \n    \n         Prompt:  Provide a short summary of this paper. [Attachment: w30957.pdf]\n    \n\n    \n\n    \n      Response (Claude 2):  \n    [+] click to expand\n    \n        This paper describes how large language models (LLMs) like ChatGPT are starting to display useful capabilities across a range of research tasks in economics. The author categorizes 25 potential use cases into six domains: ideation, writing, background research, data analysis, coding, and mathematical derivations. For each domain, the paper provides instructions and examples to demonstrate current LLM abilities, rating them on a scale from experimental to highly useful. The author argues LLMs can help automate micro tasks and increase researcher productivity in the short run. In the long run, the paper speculates cognitive automation via LLMs may have profound implications for economic research and the value of human cognitive labor.\n    \n\n\n    \n    \n          Analysis:  The long context window of Claude implies that it can keep the entire text of a typical paper in its working memory. \n    \n\n\n\n\nThe model can respond to follow-up questions on the content, going into significant detail on the text provided.\n\n    \n    \n        Additional examples of useful prompts\n        \n            \n                What is the evidence supporting these points [or a specific point from the summary]?\n                What are the author's main conclusions?\n                What are the most interesting (or most novel) ideas in this paper?\n                Can you explain the main findings of section [enter number]?\n            \n        \n        [+] click to expand\n    \n\n\nClaude allows the user to upload up to five documents and to ask the LLM to perform tasks such as comparing them or identifying connections between them.\nGoogle DeepMind’s Gemini has the capacity to digest YouTube videos if the corresponding extension is activated in the settings of Gemini.\n\n\n    \n    \n         Prompt:  Provide a one-paragraph summary of this: https://www.youtube.com/watch?v=sjL6Gl6ZIqs \n\n    \n\n    \n      Response (Gemini):  \n    [+] click to expand\n    \n        This video is about a new large language model, Claude 3 Opus, created by Anthropic. In the video, the creators test Claude 3 Opus's ability to analyze the world economy. The video shows that Claude 3 Opus can access and process information from the web using a tool called web view. It can then use this information to answer questions and complete tasks. For example, the video shows that Claude 3 Opus can generate a graph of US GDP trends and predict future GDP growth. The video also shows that Claude 3 Opus can break down complex problems into subproblems and distribute the work among other versions of itself, which is called dispatch sub agents. This allows Claude 3 Opus to analyze the economies of multiple countries simultaneously. Overall, the video demonstrates that Claude 3 Opus is a powerful tool that can be used to analyze complex economic data.\n    \n\n \n\n    \n    \n          Analysis:  The summary provided is excellent. This new capability makes it possible to streamline the lengthy process of retrieving information from videos in a much simpler form, providing new sources of information for economic research."
  },
  {
    "objectID": "subs/background.html#literature-research",
    "href": "subs/background.html#literature-research",
    "title": "Applications of LLMs",
    "section": "Literature Research",
    "text": "Literature Research\n\nWhen writing the original version of this article , LLMs were of limited usefulness for searching and referencing the academic literature. When asked for citations or references, they were often able to provide standard references that are frequently cited in the literature (say, Rothschild-Stiglitz), but basic LLMs frequently hallucinated authoritative-sounding papers that do not actually exist or made other simple factual mistakes. The following is an example for GPT-4 in Fall 2023:\n\n\n\n    \n    \n         Prompt:  Provide citation information for Anton Korinek's paper with Zach Bethune. \n    \n\n    \n\n    \n      Response (GPT-4):  \n    [+] click to expand\n    \n        Bethune, Z., & Korinek, A. (2021). Covid-19 Infection Externalities: Trading Off Lives vs. Livelihoods. Journal of Monetary Economics, 117, 1-13.\n    \n\n\n\n\n    \n    \n        \n             Analysis:  The paper title is correct, but the publication information is hallucinated — and this is for a paper with over 200 citations. For small variations of my prompt (e.g., putting the authors in alphabetical order), the LLM responded that it could not find such a paper. Requests for academic literature frequently lead to invented paper titles and journals that, however, sound superficially plausible. \n            \n            systematically examine the capability of GPT-3.5 to write about every JEL code and find that more than 30% of the citations generated do not exist.\n        \n    \n\n\n\n\n\nTraditional LLMs struggle with academic references because they cannot retain their training data verbatim, but instead retain an abstract representation of it that involves some loss of information. While this approach works for many general concepts, it falls short for academic references where precision is crucial.\n\n    \n    \n        \n            Recent advances in LLM-powered search have significantly improved the ability of LLMs to help with literature research. There are alternative tools available that employ LLMs to help researchers find academic references.\n        \n        \n            For example, LLMs with web connections such as Bing or Bard can be prompted to look up specific papers on the internet and generate reference information from their findings. Moreover, the website \n            https://elicit.org\n            allows searches of the academic literature and displays a list of papers (that really exist) based on simple user prompts. It also includes a brief summary generated by an LLM.\n        \n        [+]"
  },
  {
    "objectID": "subs/background.html#background-internet-research",
    "href": "subs/background.html#background-internet-research",
    "title": "Applications of LLMs",
    "section": "Background Internet Research",
    "text": "Background Internet Research\nAs already observed in the search page, LLM-powered search tools have also become powerful instruments for factual research. Like all LLMs, search tools based on LLMs sometimes hallucinates, but they do so much less frequently than LLMs that do not have the ability to access the web. Moreover, they offer links supporting the statements that they make, which the user can follow to judge the reliability of the sources and verify the model’s output.\nThe following is an example:\n\n\n    \n    \n         Prompt:  Can you explain the EU AI Act? \n    \n\n    \n\n    \n      Response (Perplexity.AI Pro):  \n    [+] click to expand\n    \n        The EU AI Act is a groundbreaking piece of legislation that aims to regulate artificial intelligence systems within the European Union. Here's a comprehensive overview of its key aspects:\n\n        Risk-Based Approach\n        The AI Act classifies AI systems into four risk categories:\n\n        \n            Unacceptable risk: These AI systems are prohibited outright.\n            High risk: Strictly regulated with specific requirements.\n            Limited risk: Subject to transparency obligations.\n            Minimal risk: Allowed with minimal restrictions.\n        \n\n        Key Provisions\n        [2 pages of descriptions]\n\n        Conclusion\n        The EU AI Act represents the world's first comprehensive legal framework for AI, aiming to foster innovation while protecting fundamental rights and ensuring ethical AI development. It sets a global standard for AI regulation and is likely to have far-reaching impacts on AI development and deployment worldwide.\n    \n\n\n\n    \n    \n        \n             Analysis:  After submitting a query, the site first shows the keywords it searches for (in my example, \"EU AI Act explanation,\" \"European Union Artificial Intelligence Act overview,\" and \"What is the EU AI Act?\"), then a preliminary list of the materials it evaluates as \"Reading\" (in my example, 11 websites). Then it generates a response that starts with a clickable list of sources, continues with a synthesis of the materials found, and ends with a conclusion that summarizes everything. The summary it provided is satisfactory, although I had to ask a follow-up question for it to report the date it was passed. Note that the leading LLM-based chatbots without search (e.g., Anthropic) were not able to correctly answer the question since their training data cut off before the passage of the act.\n        \n    \n\n\nIn my explorations, I found that LLM-powered search works well for general factual questions but regularly runs into difficulties in identifying the most relevant sources for more specialized queries. For example, when asking for academic literature on a given topic, a regular occurrence is that they base significant parts of their responses on obscure papers that happen to have a title that closely matches the query. Further progress will require that these tools better learn to prioritize the most impactful academic references, perhaps as measured by citation counts and journal and researcher impact factors."
  },
  {
    "objectID": "subs/background.html#formatting-references",
    "href": "subs/background.html#formatting-references",
    "title": "Applications of LLMs",
    "section": "Formatting References",
    "text": "Formatting References\nAlthough they are really bad at generating references, even simple LLMs (such as GPT3.5) are quite capable at formatting references in the desired manner once the correct citation information is provided:\n\n\n    \n    \n         Prompt:  Convert the following reference to BibTeX format: \n        \n            Anton Korinek, Large Language Models and Cognitive Automation for Economic Research, NBER Working Paper 30957, February 2023.\n        \n        [+] click to expand\n    \n\n    \n\n    \n      Response (GPT-4):  \n    [+] click to expand\n    \n        @techreport{korinek2023large,\n title={Large Language Models and Cognitive Automation for Economic Research},\n author={Korinek, Anton},\n year={2023},\n institution={NBER},\n type={Working Paper},\n number={30957},\n month={February}\n}\n        \n    \n\n\n\n\n    \n    \n         Follow-up Prompt:  Format it in Chicago style. \n    \n\n    \n\n    \n      Response (GPT-4):  \n    [+] click to expand\n    \n        Korinek, Anton. 2023. \"Large Language Models and Cognitive Automation for Economic Research.\" NBER Working Paper No. 30957, February.\n    \n\n\nLLMs can convert a whole bibliography in batch format, for example from APA to Chicago format or into bibtex format.\n\n    \n    \n        \n            For very highly-cited works that the LLM has frequently encountered in its training data, a prompt like \"bibtex reference for stiglitz weiss\" also works well and saves the user from having to copy or type the detailed citation information of the work in question. However, it is advisable to double-check the information."
  },
  {
    "objectID": "subs/background.html#translating-text",
    "href": "subs/background.html#translating-text",
    "title": "Applications of LLMs",
    "section": "Translating Text",
    "text": "Translating Text\n\n\n demonstrate that LLMs starting with GPT-3.5 perform competitively with commercial translation products on high-resource languages. The following is an example:\n\n\n\n    \n    \n         Prompt:  Translate the following sentence into Spanish, German, and Finnish: \n        \n            \"Generative AI, in particular large language models (LLMs) such as ChatGPT, has the potential to revolutionize research in many disciplines.\"\n        \n        [+] click to expand\n    \n\n    \n\n\n Response (GPT-4): \n[+] click to expand\n\n    Spanish: La IA generativa, en particular los modelos de lenguaje grandes (LLMs) como ChatGPT, tiene el potencial de revolucionar la investigación en muchas disciplinas.\n    German: Generative KI, insbesondere große Sprachmodelle (LLMs) wie ChatGPT, hat das Potenzial, die Forschung in vielen Disziplinen zu revolutionieren.\n    Finnish: Generatiivinen tekoäly, erityisesti suuret kielimallit (LLM) kuten ChatGPT, voi mullistaa tutkimusta monilla aloilla.\n  \n\n\n\nDuring pre-training, LLMs develop representations of concepts that abstract beyond any single language, and this makes them able to easily map text from one language to the other. Performance on lower-resource languages for which less digitized text and fewer digitized translations are available is worse."
  },
  {
    "objectID": "subs/background.html#explaining-concepts",
    "href": "subs/background.html#explaining-concepts",
    "title": "Applications of LLMs",
    "section": "Explaining Concepts",
    "text": "Explaining Concepts\nLLMs can act as a tutor and explain many common economic concepts – at a level that is useful for students who are trying to learn new materials, and even for more advanced researchers who are branching out beyond their main area of expertise. For good explanations, it is critical to employ the most cutting-edge LLMs.\n\n\n    \n    \n         Prompt:  What are instrumental variables useful for? \n    \n\n    \n\n    \n     Response (GPT-4): \n    [+] click to expand\n    \n        Instrumental variables are useful for addressing issues of endogeneity in statistical analysis, particularly in regression analysis. Endogeneity can occur due to unobserved variables, measurement errors, or simultaneity, which can lead to biased and inconsistent parameter estimates.\n\n        Instrumental variables are used to isolate the effect of the variable of interest from the effects of other confounding variables. They are particularly useful in situations where it is not possible to directly observe all relevant variables, or where the variable of interest is correlated with the error term.\n\n        In addition, instrumental variables can be used to estimate causal relationships in observational data, where random assignment of treatments is not possible. They provide a way to mimic the conditions of a randomized controlled trial, which is considered the gold standard for causal inference.\n    \n\n\n    \n    \n        \n             Analysis:  When employing LLMs in this way, follow-up questions that go into further detail can be very useful and allow the user to obtain personalized tutoring.\n        \n    \n\n\n    \n    \n        Other concept questions that the LLM answered well included the following:\n        \n            \n                What is the invisible hand theorem and why does it hold?\n                What is Monte Carlo simulation?\n                How does Cournot equilibrium differ from Bertrand equilibrium?\n                What are the leading theories of exchange rate determination?\n            \n        \n        [+] click to expand\n    \n\n\nBut sometimes LLMs, especially earlier versions, hallucinate when providing answers. The following is an example using the older GPT-3.5 model text-davinci-003, which powered the original free version of ChatGPT in late 2022:\n\n\n    \n    \n         Prompt:  What is the second theorem of welfare economics? \n    \n\n    \n\n    \n     Response (GPT-3.5): \n    [+] click to expand\n    \n        The Second Theorem of Welfare Economics states that any competitive equilibrium is Pareto efficient. This means that any competitive market outcome is the most efficient outcome possible, as it cannot be improved upon without making at least one individual worse off.\n\n        (Author's note: this is clearly the first not the second theorem!)\n    \n\n\n    \n    \n        \n             Analysis:  The two fundamental theorems of welfare economics are cornerstones of modern economics, but the text generated by GPT-3.5 confuses the two. Although LLMs give clear and impressive responses in many instances, this illustrates that their output cannot always be trusted, even on what seem like basic questions about fundamental concepts. Since LLMs can be quite helpful and powerful as tutors, one of the dilemmas they introduce is that students are likely to use them even though they occasionally produce false responses with great confidence."
  },
  {
    "objectID": "subs/data.html",
    "href": "subs/data.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can help locate data sources, format data, extract data from text, classify and score text, create figures, extract sentiment, and even simulate human test subjects. Most of these capabilities can be accessed not only through a web interface as shown in the demonstrations below, but also via an API (Application Programming Interface)\n        \n        \n            that allows large amounts of data to be formatted, extracted, classified etc. The operations can also be performed in batches to remain within the token limit for each request. Moreover, building on the section on coding, it goes without saying that LLMs can write the computer code necessary to access their own APIs—for example, try out \"Write python code to ask GPT-4 to do any data extraction or manipulation task. \n        \n        [+]\n    \n\n\n\n    \n    \n        \n            When performing data analysis tasks in bulk, cost is an important consideration. Although a single prompt to a cutting-edge LLM costs just fractions of a cent, the cost of performing thousands or millions of queries quickly adds up. For many of the tasks described below, smaller and cheaper models are available. In those cases, it is not advisable to use the most cutting-edge LLM. \n        \n        \n            \n             \n            This category has benefited from the growing accuracy of LLMs, which now rival humans in tasks like classifying text or extracting sentiment. For individual researcher use, collaborative tools for data analysis in ChatGPT and Claude are becoming increasingly powerful and user-friendly. For bulk data analysis, cost declines and better models are making it possible to process larger and larger amounts of data. \n        \n        [+]\n    \n\n\n\n\nLLMs can be useful starting from the first step of data analysis, i.e., in identifying and locating appropriate data sources. The following example illustrates the role that Claude 3 can play in advising users on what data sources to consider:\n\n\n    \n    \n         Prompt:  What data would be useful to analyze the effects of AI on the labor market and where can I find it? \n    \n\n    \n\n    \n     Response (Claude 3):  To analyze the effects of AI on the labor market, you would need data from various sources. Here are some key data points and potential sources:\n    [+] click to expand\n    \n        \n            Employment data by industry and occupation\n                \n                    Bureau of Labor Statistics (BLS) in the US\n                    Eurostat for European countries\n                    National statistical agencies of other countries\n                \n            \n\n            Adoption rates of AI technologies by industry\n                \n                    Market research reports from companies like Gartner, IDC, or McKinsey\n                    Academic studies and surveys\n                    Company reports and press releases\n                \n            \n\n            [Points 3. to 9. omitted for space reasons.]\n        \n\n        Combining data from these various sources can provide a comprehensive picture of how AI is affecting the labor market across industries, occupations, and demographic groups. It's important to note that data availability and quality may vary across countries and regions.\n    \n\n\n    \n    \n        \n             Analysis:  Although the list provided by Claude is somewhat of a laundry list and generic, it serves as a good brainstorming basis that may give the researcher ideas about novel data sources. Moreover, Claude is also happy to offer follow-up advice on how to best download data sources and how to best clean them.\n        \n    \n\n\n\n\n\nAs described in the access page on workspaces for interactive LLM collaboration, one of the most useful functions of ChatGPT for economists is Advanced Data Analysis, which employs the coding capabilities of GPT-4 to create versatile figures and graphs. In mid-2024, OpenAI made the resulting figures and graphs interactive.\nIn the following example, I uploaded a file that contained stock market prices for three large technology companies and instructed ChatGPT Advanced Data Analysis to create one graph displaying stock performance labeled with the corresponding betas and another graph displaying portfolio  To compile the underlying stock market data, I asked ChatGPT to write a script to download the data, as described in the Online Appendix of the paper. \n\n    \n    \n        \n            Prompt: Can you display a graph that shows the performance of these securities normalized to start at 100? [Uploaded stock_data.csv]\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            The dataset contains the closing prices for the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&P 500 index (^GSPC) over a certain period of time.\n        \n        \n            Let's normalize the prices to start at 100 and plot the resulting performance of these securities. This normalization will allow us to compare the performance of the securities relative to their initial prices. To normalize the data, we'll divide all prices by their initial price and then multiply by 100.\n        \n        [Code generated and executed]\n        [Code generated and executed]\n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance1.png} \\end{center}\n        \n        \n            Here is the graph showing the performance of the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&P 500 index (^GSPC), all normalized to start at 100. The x-axis represents time (the dates), and the y-axis represents the normalized prices.\n        \n        \n            From the graph, we can see how each of these securities has performed relative to its starting point over time. This type of comparison can be helpful when assessing the relative performance of different securities or indices.\n        \n    \n\n\n\n    \n    \n        \n            Follow-up Prompt: Calculate the beta for each of the stocks and add it to the legend. Change the colors to make them easier to distinguish. Use the title \"One-Decade Performance of Three Big Tech Companies\".\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            The beta of a stock is a measure of the stock's volatility in relation to the overall market. The overall market has a beta of 1.0, and individual stocks are ranked according to how much they deviate from the market.\n        \n        \n            A stock that swings more than the market over time has a beta above 1.0. If a stock moves less than the market, the stock's beta is less than 1.0. High-beta stocks are supposed to be riskier but provide higher return potential; low-beta stocks pose less risk but also lower returns.\n        \n        \n            Let's calculate the beta for each of these stocks over the given period. We can calculate beta using the formula:\n        \n        $$\n        \\beta = \\frac{Cov(r_E,r_M)}{Var(r_M)}\n        $$\n        \n            where:\n        \n        \n            \\( r_E \\) is the return of the stock\n            \\( r_M \\) is the return of the market\n            \\( Cov(r_E,r_M) \\) is the covariance between the stock and market returns\n            \\( Var(r_M) \\) is the variance of the market returns\n        \n        \n            For the market return, we'll use the S&P 500 index (^GSPC). We'll calculate daily returns for each stock and the market, then calculate the beta for each stock.\n        \n        \n            After that, I'll recreate the graph with the new colors and the calculated betas included in the legend. The colors will be chosen to provide good contrast and clear visibility.\n        \n        [Code generated and executed]\n        \n            Here are the beta values for the stocks:\n        \n        \n            Google (GOOG): 1.1317\n            Meta (META): 1.2537\n            Microsoft (MSFT): 1.2108\n        \n        \n            These values indicate that all three stocks are generally more volatile than the market (S&P 500), since their beta values are greater than 1.\n        \n        \n            Now let's update the graph with the new title, colors, and the beta values in the legend.\n        \n        [Code generated and executed]\n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance2.png} \\end{center}\n        \n        \n            Here is the updated graph with the new title, colors, and beta values included in the legend.\n        \n        \n            The graph represents the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&P 500 index (^GSPC), all normalized to start at 100. The beta values for the stocks, which measure their volatility in relation to the overall market, are included in the legend.\n        \n    \n\n\n\n\n    \n    \n        \n            Follow-up Prompt: Double the size of the title, legend, axes labels and ticks. Label \"^GSPC\" in the legend as \"S&P 500\".\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance3.png} \\end{center}\n        \n        \n            Here is the updated graph with the requested changes:\n        \n        \n            The title, legend, axes labels, and ticks have all been doubled in size.\n            The \"^GSPC\" label in the legend has been changed to \"S&P 500\".\n        \n        \n            This graph shows the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&P 500 index, all normalized to start at 100. The beta values for the stocks are included in the legend.\n        \n    \n\n\n\n\n    \n    \n        \n            Follow-up Prompt: Assume I put $100 in each of the three stocks at the start. Can you show a pie chart that shows how much I would have in each stock now?\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{piechart1.png} \\end{center}\n        \n        \n            Here is a pie chart that shows the current value of a $100 investment made in each of the three big tech stocks (Google, Meta, and Microsoft) at the start of the period represented in the data.\n        \n        \n            The pie chart is divided into three sections, each representing one of the stocks. The size of each section corresponds to the current value of the initial $100 investment in that stock, expressed as a percentage of the total value of all three investments. The percentages are also labeled on the chart for clarity.\n        \n    \n\n\n\n    \n    \n        \n            Follow-up Prompt: Can you label each position with its current dollar value in addition to the percentage? Can you make one of the pieces pop out of the pie?\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{piechart2.png} \\end{center}\n        \n        \n            Here is the updated pie chart. Each slice now includes both the current dollar value and the percentage of the total portfolio that it represents.\n        \n        \n            The first slice, representing the Google stock, is \"exploded\" or offset from the pie to highlight it. This visual effect can be useful for emphasizing a particular piece of a pie chart. In this case, it emphasizes that Google has the highest value of the three stocks based on an initial $100 investment.\n        \n        \n            (Author's note: the figure is correct, but ChatGPT's statement that Google has the highest value is false—this serves as a reminder that Advanced Data Analysis cannot \"see\" the figures it creates.)\n        \n    \n\n\n    \n    \n        \n            Analysis: Relying on the almost endless capabilities of Python, ChatGPT Advanced Data Analysis can display many other types of figures.\n        \n    \n\n\n\n\n\nA powerful capability of LLMs for data analysis is to extract data from written text. The following example is a simple illustration:\n\n\n    \n    \n        Prompt: Mark got an A in econ and a B+ in math. Sally got an A- in both econ and math. Frank got a B in econ and a C in math. Reformat as follows:  Name & econ grade & math grade\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        Mark & A & B+\n        Sally & A- & A-\n        Frank & B & C\n    \n\n\n\n    \n    \n        Analysis: The LLM correctly processes the meaning of the expression \"both in econ and math\" for Sally and extracts the grades accordingly.\n    \n\n\n\n\n\nLLMs are equally versatile translating data into the desired format. Building on the previous example, I asked the LLM to format the data first into comma-separated values (CSV) format and then as a LaTeX table:\n\n\n    \n    \n        Follow-up Prompt: Reformat in CSV format.\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        Name,econ grade,math grade\nMark,A,B+\nSally,A-,A-\nFrank,B,C\n        \n    \n\n\n\n\n    \n    \n        Follow-up Prompt: Write as a LaTeX table.\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        \\begin{tabular}{lcc} \n    \\hline \n    Name & econ grade & math grade \\\\ \n    \\hline \n    Mark & A & B+ \\\\ \n    Sally & A- & A- \\\\ \n    Frank & B & C \\\\ \n    \\hline \n\\end{tabular}\n        \n    \n\n\n    \n        Analysis: GPT-4 excelled at both these and other similar tasks.\n    \n\n\n\n\n\n \nSocial science research frequently employs statistical techniques to represent text as data . Modern LLMs can go beyond traditional techniques for this because they are increasingly capable of processing the meaning of the sentences that they are fed. \n\n\n\n    \n        The following example asks GPT-4 to classify whether a given task listed in the US Department of Labor's Occupational Information Network (O*NET) database is easy or hard to automate\n         \n            and to justify its classification.\n            \n                 employ GPT-4 in this manner to systematically estimate the labor market impact of LLMs.\n             \n            Following the principle of chain-of-thought prompting suggested by , the prompt asks first for the justification in order to induce the LLM to reason about its response before performing the actual classification. This is akin to asking a student to think before they respond to a question.\n        \n        [+]\n    \n\n\n    \n        \n            Prompt (GPT-4): Here are 5 tasks from O*Net:\n        \n        \n            \n                Monitor operational records and reports to ensure accuracy and efficiency.\n                Develop and implement policies and procedures for recordkeeping.\n                Prepare and maintain employee records.\n                Maintain and update filing, inventory, mailing, and database systems.\n                Compile and prepare reports, charts, and graphs.\n            \n            Provide a 5-10-word description of how easy to automate each task is and classify into \"easy\" or \"hard\" to automate. Provide your output in the form of a table with the following columns: no; task; justification; classification.\n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        \n\n\n\nNo\nTask\nJustification\nResult\n\n\n\n\n1\nMonitor operational records and reports to ensure accuracy and efficiency.\nRequires understanding of context and critical thinking.\nHard\n\n\n2\nDevelop and implement policies and procedures for recordkeeping.\nRequires human judgement and decision making.\nHard\n\n\n3\nPrepare and maintain employee records.\nMostly data entry and retrieval, easily automated.\nEasy\n\n\n4\nMaintain and update filing, inventory, mailing, and database systems.\nMostly data entry and retrieval, easily automated.\nEasy\n\n\n5\nCompile and prepare reports, charts, and graphs.\nData processing and visualization can be automated.\nEasy\n\n\n\n\n    \n\n\n    \n        \n            Analysis: The results are reasonable, although I should emphasize that they are not entirely robust. Just like a human evaluator who may make different calls depending on seemingly random circumstances, the model's answers to what is essentially the same question change when the wording of the prompt is changed—and in some cases even when the order of the listed tasks is modified.\n        \n    \n\n\n\n\n\nLLMs can also extract sentiment from text. They can, for example, classify tweets into “positive” or “negative”. Similarly, they can categorize statements by the Federal Open Market Committee (FOMC) that sets US interest rates, as illustrated in the following example:\n\n   \n       \n           Prompt (GPT-4): Is the following FOMC statement from December 2022 hawkish or dovish?\n       \n       \n           \n           Recent indicators point to modest growth in spending and production... \n           \n               [From federalreserve.gov, remainder omitted for space reasons]\n           \n           \n       \n       [+] click to expand\n   \n\n   \n\n   Response (GPT-4): The statement is hawkish.\n   [+] click to expand\n     The FOMC is indicating a concern about elevated inflation and is taking action by raising the target range for the federal funds rate and reducing its holdings of Treasury securities and agency debt. The statement also suggests that further increases in the target range may be appropriate in the future to return inflation to the 2 percent objective. This indicates a tightening of monetary policy, which is a characteristic of a hawkish stance.\n   \n\n\n\n   \n       \n           Analysis: The assessment is correct and well-argued. \n       \n   \n\n\n    \n        \n            I also explored whether the LLM could identify whether the December 2022 or February 2023 FOMC statement was more hawkish, but its ability to assess Fed-speak was not quite nuanced enough\n        \n        \n            — it focused mainly on the level of interest rates in February 2023 being higher as opposed to the small and nuanced changes in the text of the statement that indicated a potential change in direction. It did so even when I explicitly instructed it to report its assessment while “disregarding the target level for the federal funds rate.” Only when I manually replaced the numbers for the target level by “[range]” did the system correctly replicate the assessment that the February 2023 statement was slightly more dovish, as was widely reported in the financial press at the\n            \n                See, for example, \n                \n                    CNBC coverage\n                .\n             \n             develop an economic sentiment prediction model along similar lines and employ it to analyze US economic news and the ECB's monetary policy announcements.\n        \n        [+]\n    \n\n\n\n\n\n\n\n    \n        \n             propose the use of LLMs to simulate human subjects, based on the observation that the training data of LLMs contains a large amount of information about humanity.\n        \n        \n            They condition GPT-3 on the socio-demographic backstories of real humans and demonstrate that subsequent answers to survey questions are highly correlated with the actual responses of humans with the described backgrounds, in a nuanced and multifaceted manner.  showcases applications to economics, using simulated test subjects to replicate and extend upon several behavioral experiments.  demonstrate how to use LLMs to obtain useful information for market research.\n        \n        [+]\n    \n\nThe following example illustrates the concept:\n\n    \n        Prompt (GPT-4): For each of the following voters, provide a one-word rating to indicate whether they are more likely to approve or disapprove of a policy proposal to loosen US immigration restrictions on highly-educated workers:\n        \n            \n                A 32-year old female lawyer in Houston, TX who is Hispanic\n                A 73-year old male retired doctor in Rome, GA who is Caucasian\n                A 25-year old software engineer in San Francisco, CA who is Asian and identifies as non-binary\n                A 45-year old female grocery check-out clerk in Brooklyn, NY who is second-generation Italian\n                A 55-year old male insurance agent in Lake City, FL who is Caucasian\n            \n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        \n            Approve\n            Disapprove\n            Approve\n            Approve\n            Disapprove\n        \n    \n\n\n    \n        \n            There is a significant risk that the simulated results simply propagate false stereotypes, and they must hence be used with great care. However, they also contain valuable information.\n        \n        \n            If used correctly, they can provide useful insights about our society, from which all the data used to train the LLMs ultimately originate. For experimental economists who prefer keeping to human subjects, \n             describe how LLMs can help to improve the design and implementation of experiments. \n             propose 12 best practices for generative AI in experimental research, ranging from the pre-treatment stage to the design and implementation stage, to the analysis stage.\n        \n        [+]"
  },
  {
    "objectID": "subs/data.html#locating-data-sources",
    "href": "subs/data.html#locating-data-sources",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can be useful starting from the first step of data analysis, i.e., in identifying and locating appropriate data sources. The following example illustrates the role that Claude 3 can play in advising users on what data sources to consider:\n\n\n    \n    \n         Prompt:  What data would be useful to analyze the effects of AI on the labor market and where can I find it? \n    \n\n    \n\n    \n     Response (Claude 3):  To analyze the effects of AI on the labor market, you would need data from various sources. Here are some key data points and potential sources:\n    [+] click to expand\n    \n        \n            Employment data by industry and occupation\n                \n                    Bureau of Labor Statistics (BLS) in the US\n                    Eurostat for European countries\n                    National statistical agencies of other countries\n                \n            \n\n            Adoption rates of AI technologies by industry\n                \n                    Market research reports from companies like Gartner, IDC, or McKinsey\n                    Academic studies and surveys\n                    Company reports and press releases\n                \n            \n\n            [Points 3. to 9. omitted for space reasons.]\n        \n\n        Combining data from these various sources can provide a comprehensive picture of how AI is affecting the labor market across industries, occupations, and demographic groups. It's important to note that data availability and quality may vary across countries and regions.\n    \n\n\n    \n    \n        \n             Analysis:  Although the list provided by Claude is somewhat of a laundry list and generic, it serves as a good brainstorming basis that may give the researcher ideas about novel data sources. Moreover, Claude is also happy to offer follow-up advice on how to best download data sources and how to best clean them."
  },
  {
    "objectID": "subs/data.html#creating-figures",
    "href": "subs/data.html#creating-figures",
    "title": "Applications of LLMs",
    "section": "",
    "text": "As described in the access page on workspaces for interactive LLM collaboration, one of the most useful functions of ChatGPT for economists is Advanced Data Analysis, which employs the coding capabilities of GPT-4 to create versatile figures and graphs. In mid-2024, OpenAI made the resulting figures and graphs interactive.\nIn the following example, I uploaded a file that contained stock market prices for three large technology companies and instructed ChatGPT Advanced Data Analysis to create one graph displaying stock performance labeled with the corresponding betas and another graph displaying portfolio  To compile the underlying stock market data, I asked ChatGPT to write a script to download the data, as described in the Online Appendix of the paper. \n\n    \n    \n        \n            Prompt: Can you display a graph that shows the performance of these securities normalized to start at 100? [Uploaded stock_data.csv]\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            The dataset contains the closing prices for the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&P 500 index (^GSPC) over a certain period of time.\n        \n        \n            Let's normalize the prices to start at 100 and plot the resulting performance of these securities. This normalization will allow us to compare the performance of the securities relative to their initial prices. To normalize the data, we'll divide all prices by their initial price and then multiply by 100.\n        \n        [Code generated and executed]\n        [Code generated and executed]\n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance1.png} \\end{center}\n        \n        \n            Here is the graph showing the performance of the securities Google (GOOG), Meta (META), Microsoft (MSFT), and the S&P 500 index (^GSPC), all normalized to start at 100. The x-axis represents time (the dates), and the y-axis represents the normalized prices.\n        \n        \n            From the graph, we can see how each of these securities has performed relative to its starting point over time. This type of comparison can be helpful when assessing the relative performance of different securities or indices.\n        \n    \n\n\n\n    \n    \n        \n            Follow-up Prompt: Calculate the beta for each of the stocks and add it to the legend. Change the colors to make them easier to distinguish. Use the title \"One-Decade Performance of Three Big Tech Companies\".\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            The beta of a stock is a measure of the stock's volatility in relation to the overall market. The overall market has a beta of 1.0, and individual stocks are ranked according to how much they deviate from the market.\n        \n        \n            A stock that swings more than the market over time has a beta above 1.0. If a stock moves less than the market, the stock's beta is less than 1.0. High-beta stocks are supposed to be riskier but provide higher return potential; low-beta stocks pose less risk but also lower returns.\n        \n        \n            Let's calculate the beta for each of these stocks over the given period. We can calculate beta using the formula:\n        \n        $$\n        \\beta = \\frac{Cov(r_E,r_M)}{Var(r_M)}\n        $$\n        \n            where:\n        \n        \n            \\( r_E \\) is the return of the stock\n            \\( r_M \\) is the return of the market\n            \\( Cov(r_E,r_M) \\) is the covariance between the stock and market returns\n            \\( Var(r_M) \\) is the variance of the market returns\n        \n        \n            For the market return, we'll use the S&P 500 index (^GSPC). We'll calculate daily returns for each stock and the market, then calculate the beta for each stock.\n        \n        \n            After that, I'll recreate the graph with the new colors and the calculated betas included in the legend. The colors will be chosen to provide good contrast and clear visibility.\n        \n        [Code generated and executed]\n        \n            Here are the beta values for the stocks:\n        \n        \n            Google (GOOG): 1.1317\n            Meta (META): 1.2537\n            Microsoft (MSFT): 1.2108\n        \n        \n            These values indicate that all three stocks are generally more volatile than the market (S&P 500), since their beta values are greater than 1.\n        \n        \n            Now let's update the graph with the new title, colors, and the beta values in the legend.\n        \n        [Code generated and executed]\n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance2.png} \\end{center}\n        \n        \n            Here is the updated graph with the new title, colors, and beta values included in the legend.\n        \n        \n            The graph represents the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&P 500 index (^GSPC), all normalized to start at 100. The beta values for the stocks, which measure their volatility in relation to the overall market, are included in the legend.\n        \n    \n\n\n\n\n    \n    \n        \n            Follow-up Prompt: Double the size of the title, legend, axes labels and ticks. Label \"^GSPC\" in the legend as \"S&P 500\".\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{performance3.png} \\end{center}\n        \n        \n            Here is the updated graph with the requested changes:\n        \n        \n            The title, legend, axes labels, and ticks have all been doubled in size.\n            The \"^GSPC\" label in the legend has been changed to \"S&P 500\".\n        \n        \n            This graph shows the one-decade performance of the three big tech companies: Google (GOOG), Meta (META), and Microsoft (MSFT), as well as the S&P 500 index, all normalized to start at 100. The beta values for the stocks are included in the legend.\n        \n    \n\n\n\n\n    \n    \n        \n            Follow-up Prompt: Assume I put $100 in each of the three stocks at the start. Can you show a pie chart that shows how much I would have in each stock now?\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{piechart1.png} \\end{center}\n        \n        \n            Here is a pie chart that shows the current value of a $100 investment made in each of the three big tech stocks (Google, Meta, and Microsoft) at the start of the period represented in the data.\n        \n        \n            The pie chart is divided into three sections, each representing one of the stocks. The size of each section corresponds to the current value of the initial $100 investment in that stock, expressed as a percentage of the total value of all three investments. The percentages are also labeled on the chart for clarity.\n        \n    \n\n\n\n    \n    \n        \n            Follow-up Prompt: Can you label each position with its current dollar value in addition to the percentage? Can you make one of the pieces pop out of the pie?\n        \n    \n    \n    \n    \n        Response (ChatGPT Advanced Data Analysis):\n        [Code generated and executed]\n    \n    [+] click to expand\n    \n        \n            LaTeX graphic inclusion:\n            \\begin{center} \\includegraphics[width=0.8\\textwidth]{piechart2.png} \\end{center}\n        \n        \n            Here is the updated pie chart. Each slice now includes both the current dollar value and the percentage of the total portfolio that it represents.\n        \n        \n            The first slice, representing the Google stock, is \"exploded\" or offset from the pie to highlight it. This visual effect can be useful for emphasizing a particular piece of a pie chart. In this case, it emphasizes that Google has the highest value of the three stocks based on an initial $100 investment.\n        \n        \n            (Author's note: the figure is correct, but ChatGPT's statement that Google has the highest value is false—this serves as a reminder that Advanced Data Analysis cannot \"see\" the figures it creates.)\n        \n    \n\n\n    \n    \n        \n            Analysis: Relying on the almost endless capabilities of Python, ChatGPT Advanced Data Analysis can display many other types of figures."
  },
  {
    "objectID": "subs/data.html#extracting-data-from-text",
    "href": "subs/data.html#extracting-data-from-text",
    "title": "Applications of LLMs",
    "section": "",
    "text": "A powerful capability of LLMs for data analysis is to extract data from written text. The following example is a simple illustration:\n\n\n    \n    \n        Prompt: Mark got an A in econ and a B+ in math. Sally got an A- in both econ and math. Frank got a B in econ and a C in math. Reformat as follows:  Name & econ grade & math grade\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        Mark & A & B+\n        Sally & A- & A-\n        Frank & B & C\n    \n\n\n\n    \n    \n        Analysis: The LLM correctly processes the meaning of the expression \"both in econ and math\" for Sally and extracts the grades accordingly."
  },
  {
    "objectID": "subs/data.html#reformatting-data",
    "href": "subs/data.html#reformatting-data",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs are equally versatile translating data into the desired format. Building on the previous example, I asked the LLM to format the data first into comma-separated values (CSV) format and then as a LaTeX table:\n\n\n    \n    \n        Follow-up Prompt: Reformat in CSV format.\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        Name,econ grade,math grade\nMark,A,B+\nSally,A-,A-\nFrank,B,C\n        \n    \n\n\n\n\n    \n    \n        Follow-up Prompt: Write as a LaTeX table.\n    \n\n    \n\n    \n    Response (GPT-4):\n    [+] click to expand\n    \n        \\begin{tabular}{lcc} \n    \\hline \n    Name & econ grade & math grade \\\\ \n    \\hline \n    Mark & A & B+ \\\\ \n    Sally & A- & A- \\\\ \n    Frank & B & C \\\\ \n    \\hline \n\\end{tabular}\n        \n    \n\n\n    \n        Analysis: GPT-4 excelled at both these and other similar tasks."
  },
  {
    "objectID": "subs/data.html#classifying-and-scoring-text",
    "href": "subs/data.html#classifying-and-scoring-text",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Social science research frequently employs statistical techniques to represent text as data . Modern LLMs can go beyond traditional techniques for this because they are increasingly capable of processing the meaning of the sentences that they are fed. \n\n\n\n    \n        The following example asks GPT-4 to classify whether a given task listed in the US Department of Labor's Occupational Information Network (O*NET) database is easy or hard to automate\n         \n            and to justify its classification.\n            \n                 employ GPT-4 in this manner to systematically estimate the labor market impact of LLMs.\n             \n            Following the principle of chain-of-thought prompting suggested by , the prompt asks first for the justification in order to induce the LLM to reason about its response before performing the actual classification. This is akin to asking a student to think before they respond to a question.\n        \n        [+]\n    \n\n\n    \n        \n            Prompt (GPT-4): Here are 5 tasks from O*Net:\n        \n        \n            \n                Monitor operational records and reports to ensure accuracy and efficiency.\n                Develop and implement policies and procedures for recordkeeping.\n                Prepare and maintain employee records.\n                Maintain and update filing, inventory, mailing, and database systems.\n                Compile and prepare reports, charts, and graphs.\n            \n            Provide a 5-10-word description of how easy to automate each task is and classify into \"easy\" or \"hard\" to automate. Provide your output in the form of a table with the following columns: no; task; justification; classification.\n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        \n\n\n\nNo\nTask\nJustification\nResult\n\n\n\n\n1\nMonitor operational records and reports to ensure accuracy and efficiency.\nRequires understanding of context and critical thinking.\nHard\n\n\n2\nDevelop and implement policies and procedures for recordkeeping.\nRequires human judgement and decision making.\nHard\n\n\n3\nPrepare and maintain employee records.\nMostly data entry and retrieval, easily automated.\nEasy\n\n\n4\nMaintain and update filing, inventory, mailing, and database systems.\nMostly data entry and retrieval, easily automated.\nEasy\n\n\n5\nCompile and prepare reports, charts, and graphs.\nData processing and visualization can be automated.\nEasy\n\n\n\n\n    \n\n\n    \n        \n            Analysis: The results are reasonable, although I should emphasize that they are not entirely robust. Just like a human evaluator who may make different calls depending on seemingly random circumstances, the model's answers to what is essentially the same question change when the wording of the prompt is changed—and in some cases even when the order of the listed tasks is modified."
  },
  {
    "objectID": "subs/data.html#extracting-sentiment",
    "href": "subs/data.html#extracting-sentiment",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can also extract sentiment from text. They can, for example, classify tweets into “positive” or “negative”. Similarly, they can categorize statements by the Federal Open Market Committee (FOMC) that sets US interest rates, as illustrated in the following example:\n\n   \n       \n           Prompt (GPT-4): Is the following FOMC statement from December 2022 hawkish or dovish?\n       \n       \n           \n           Recent indicators point to modest growth in spending and production... \n           \n               [From federalreserve.gov, remainder omitted for space reasons]\n           \n           \n       \n       [+] click to expand\n   \n\n   \n\n   Response (GPT-4): The statement is hawkish.\n   [+] click to expand\n     The FOMC is indicating a concern about elevated inflation and is taking action by raising the target range for the federal funds rate and reducing its holdings of Treasury securities and agency debt. The statement also suggests that further increases in the target range may be appropriate in the future to return inflation to the 2 percent objective. This indicates a tightening of monetary policy, which is a characteristic of a hawkish stance.\n   \n\n\n\n   \n       \n           Analysis: The assessment is correct and well-argued. \n       \n   \n\n\n    \n        \n            I also explored whether the LLM could identify whether the December 2022 or February 2023 FOMC statement was more hawkish, but its ability to assess Fed-speak was not quite nuanced enough\n        \n        \n            — it focused mainly on the level of interest rates in February 2023 being higher as opposed to the small and nuanced changes in the text of the statement that indicated a potential change in direction. It did so even when I explicitly instructed it to report its assessment while “disregarding the target level for the federal funds rate.” Only when I manually replaced the numbers for the target level by “[range]” did the system correctly replicate the assessment that the February 2023 statement was slightly more dovish, as was widely reported in the financial press at the\n            \n                See, for example, \n                \n                    CNBC coverage\n                .\n             \n             develop an economic sentiment prediction model along similar lines and employ it to analyze US economic news and the ECB's monetary policy announcements.\n        \n        [+]"
  },
  {
    "objectID": "subs/data.html#simulating-human-test-subjects",
    "href": "subs/data.html#simulating-human-test-subjects",
    "title": "Applications of LLMs",
    "section": "",
    "text": "propose the use of LLMs to simulate human subjects, based on the observation that the training data of LLMs contains a large amount of information about humanity.\n        \n        \n            They condition GPT-3 on the socio-demographic backstories of real humans and demonstrate that subsequent answers to survey questions are highly correlated with the actual responses of humans with the described backgrounds, in a nuanced and multifaceted manner.  showcases applications to economics, using simulated test subjects to replicate and extend upon several behavioral experiments.  demonstrate how to use LLMs to obtain useful information for market research.\n        \n        [+]\n    \n\nThe following example illustrates the concept:\n\n    \n        Prompt (GPT-4): For each of the following voters, provide a one-word rating to indicate whether they are more likely to approve or disapprove of a policy proposal to loosen US immigration restrictions on highly-educated workers:\n        \n            \n                A 32-year old female lawyer in Houston, TX who is Hispanic\n                A 73-year old male retired doctor in Rome, GA who is Caucasian\n                A 25-year old software engineer in San Francisco, CA who is Asian and identifies as non-binary\n                A 45-year old female grocery check-out clerk in Brooklyn, NY who is second-generation Italian\n                A 55-year old male insurance agent in Lake City, FL who is Caucasian\n            \n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        \n            Approve\n            Disapprove\n            Approve\n            Approve\n            Disapprove\n        \n    \n\n\n    \n        \n            There is a significant risk that the simulated results simply propagate false stereotypes, and they must hence be used with great care. However, they also contain valuable information.\n        \n        \n            If used correctly, they can provide useful insights about our society, from which all the data used to train the LLMs ultimately originate. For experimental economists who prefer keeping to human subjects, \n             describe how LLMs can help to improve the design and implementation of experiments. \n             propose 12 best practices for generative AI in experimental research, ranging from the pre-treatment stage to the design and implementation stage, to the analysis stage.\n        \n        [+]"
  },
  {
    "objectID": "subs/promoting.html",
    "href": "subs/promoting.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "After having written a paper, the next step is to promote it. There are few areas in which LLMs have been as impactful as in marketing. This is particularly relevant for research papers, which are highly structured and information-dense self-contained pieces of knowledge—the current generation of LLMs has become capable of processing the content of entire research papers and are excellent at transforming that content into different formats, including formats that are conducive for promotion. Accordingly, there are several excellent use cases of LLMs for research promotion.\n\n\n \n    For the following exercise, I uploaded the original working paper version of this paper  to GPT-4o and asked it to generate social media posts, in this particular example for X (formerly Twitter):\n\n\n    \n        \n            Prompt: Write a series of X posts to promote the attached paper. Use simple sentences and make them catchy. [Attachment: w30957.pdf]\n        \n    \n\n    \n\n    Response (GPT-4o):\n    [+] click to expand\n    \n        \n            Exciting new possibilities! My latest NBER paper explores 25 ways language models like ChatGPT can boost research in economics. From ideation to coding, LLMs are transforming our workflows! #AI #EconResearch #LLM\n            Did you know? Large language models are now capable of automating micro-tasks like data analysis, writing, and even mathematical derivations in economic research. Check out my paper for more insights! #AIinEconomics #ProductivityBoost\n            Researchers, take note! LLMs aren't just about writing—they can also help with background research, coding, and more. Discover 6 key areas where they can assist in my latest paper. #CognitiveAutomation #AI #Economics\n            What’s the future of cognitive labor? My paper dives into how LLMs could reshape the role of human economists, making us more efficient while raising new questions about the future of work. #FutureOfWork #AIRevolution\n            Want to stay ahead in research? Learn how to incorporate LLMs into your daily tasks and increase productivity. Don’t miss the insights in my NBER paper! #Economics #AItools #GenerativeAI\n        \n    \n\n\n    \n        \n            Analysis: The LLM adapts to the optimal format for different social media platforms. Upon request, it can also incorporate suitable emoticons or links.\n        \n    \n\n\n\n\n\nSuccessful promotion leads to invitations to present your paper. The latest generation of LLMs released in 2024 also have the capability to draft slides based on a research paper. This is a difficult exercise because it requires that the model exhibits detailed recall across a long paper.\n\n    \n        \n            Prompt: Can you create a 20-slide deck for the attached economic research paper?[Attachment: w30957.pdf]\n        \n    \n\n    \n\n    Response (Claude 3):\n    [+] click to expand\n    \n        Here is a 20-slide deck summarizing the key points from the research paper \"Language Models and Cognitive Automation for Economic Research\" by Anton Korinek:\n\n        Slide 1: Title Slide\n        \n            Paper title: \"Language Models and Cognitive Automation for Economic Research\"\n            Author: Anton Korinek\n        \n\n        Slide 2: Introduction\n        \n            Large language models (LLMs) can revolutionize economic research\n            Describes 25 use cases of LLMs across 6 domains\n            Provides instructions and examples for each use case\n            Classifies usefulness of capabilities from experimental to highly useful\n        \n\n        Slide 3: What are LLMs?\n        \n            LLMs are foundation models\n            Large deep learning models pre-trained on lots of data\n            Form abstract representations and world model from training data\n            Capabilities improve according to predictable scaling laws as compute and data increase\n            Many capabilities are emergent, arising suddenly at specific thresholds\n        \n\n        [Slides 4–18 omitted for space reasons]\n\n        Slide 19: Importance of Economic Ideas\n        \n            Economists can translate human concepts to analytic forms for AIs\n            Economic ideas will influence worldview of future AI systems\n            \"Soon or late, it is ideas which are dangerous for good or evil\" (Keynes)\n        \n\n        Slide 20: Conclusion\n        \n            LLMs are becoming useful for automating research tasks\n            Humans still have comparative advantage in generating research for now\n            Important to adopt LLMs to boost productivity\n            Prepare for potentially transformative long-term impacts\n        \n    \n\n\n    \n    \n        Analysis: The generated slides provide an excellent first draft on which to build. Notably impressive in the latest version of Claude used in the example was its ability to recall detailed information from the paper, successfully generating 20 content-rich slides without noticeable memory lapses. Additionally, the LLM effectively segmented the material, distributing it appropriately across the requested number of slides.\n    \n\n\n\n\n\n\nOne of the most effective ways of promoting research papers to a broader audience is to write blog posts that convey their message in simple terms. This is an easy task for modern LLMs---users can upload the underlying paper to provide the content, and the LLM can create a blog post to the user's specifications. The following is an example that builds on the prompt that generated with Anthropic Prompt Generator to draft a summary of the first version of this paper .\n\n\n    \n        \n            Prompt: Your task is to help draft a blog post for the Brookings Institution based on an economics research paper. The full text of the paper is attached. The target audience for this blog post are economic researchers.[Attachment: w30957.pdf]  \n            \n            [continuing with the prompt generated in Chat (reference omitted)]\n        \n    \n\n    \n\n    Response (GPT-4o): How AI Is Reshaping Economic Research: Exploring Language Models for Cognitive Automation\n    [+] click to expand\n    \n        Recent advances in artificial intelligence have brought transformative tools like large language models (LLMs) into the toolkit of economic researchers. These models, such as OpenAI's ChatGPT, are not just conversational agents; they represent a major leap in how cognitive tasks can be automated, promising to significantly alter the landscape of research in economics. In his recent paper, \"Language Models and Cognitive Automation for Economic Research,\" Anton Korinek lays out 25 ways that these models can be leveraged, offering insights that are highly relevant for economic researchers looking to understand the potential impact of AI on their field.\n\n        Six Domains of LLM Utility in Economic Research\n\n        Korinek's paper categorizes the applications of LLMs into six key domains. These applications span from idea generation to coding, offering a comprehensive toolkit for researchers.\n\n        \n            Ideation and Writing: LLMs can assist researchers from the very start of a project, helping brainstorm ideas, generate counterarguments, and refine initial drafts.\n        \n\n        [Remainder omitted for space reasons]\n    \n\n\n    \n        \n            Analysis: The draft blog posts generated by the current generation of frontier LLMs are generally well done and, after some editing, save significant time compared to having to write such a post from scratch.\n        \n    \n\n\n\n\n\nLarge language models (LLMs) have emerged as powerful tools for conducting and assisting with interviews related to academic research. Their capabilities in this domain can be leveraged in two primary ways: answering interview questions and generating insightful questions for various audiences.\nLLMs can be used to answer interview questions on behalf of researchers, using their published work as a knowledge base. This approach is particularly useful when researchers are preparing responses for written interviews or need assistance in formulating clear and concise answers. For example, using a research paper as a reference, an LLM could provide detailed answers to questions about the impact of AI on economic research.\n\n    \n        \n            Prompt: I received an interview request on the impact of AI on economic research from The Chronicle of Higher Education. Can you help me draft responses based on the attached paper of mine? I am pasting the questions here:\n        \n        \n            \n                You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n                In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n                You mention that LLMs can be used to simulate human subjects for research. What are the ethical considerations and potential pitfalls of this approach, and how might it change the landscape of behavioral economics?\n                The paper touches on the limitations of current LLMs, particularly in areas like mathematical derivations. How do you see these limitations being addressed in future iterations of LLMs, and what implications might this have for theoretical economics?\n                You draw parallels between the rise of LLMs and Garry Kasparov's observations about chess computers. How do you think economists should prepare for a future where AI systems might produce superior economic models? What skills should economists focus on developing?\n            \n            [Attachment: w30957.pdf]\n        \n        [+] click to expand\n    \n\n    \n\n    Response (Claude 3.5 Sonnet):\n    [+] click to expand\n    \n        Certainly! I'd be happy to help you draft responses based on your paper. I'll provide suggested responses for each question, drawing directly from the content and ideas presented in your paper.\n\n        1. You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n\n        Suggested response: \"Based on my analysis, I believe the capabilities related to writing and data analysis have the most potential to revolutionize economic research in the near term. LLMs are particularly adept at tasks like synthesizing text, editing, and generating catchy titles or summaries. These capabilities can significantly streamline the writing process, allowing researchers to focus more on ideas and analysis rather than the mechanics of writing.\n\n        In terms of data analysis, LLMs show great promise in extracting data from text, reformatting data, and classifying and scoring text. These capabilities can automate many time-consuming tasks in data preparation and initial analysis, potentially accelerating the research process.\n\n        It's worth noting that I've rated several capabilities in these domains as 'highly useful' in my paper, indicating that incorporating them into research workflows can already save significant time and boost productivity. As these tools continue to improve, I expect their impact on how we conduct research to grow substantially.\"\n\n        2. In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n\n        Suggested response: \"As LLMs become more advanced, I anticipate a shift in the role of human economists. In the medium term, I expect LLM-based assistants and tutors to become increasingly useful for generating content that makes up research papers. Human researchers will likely focus more on their comparative advantages—posing questions, suggesting directions for obtaining answers, discriminating which parts of the produced content are useful, editing, and providing feedback.\n\n        In essence, the role may evolve to be more akin to that of an advisor or research manager. Economists will likely spend more time organizing research efforts, coordinating teams, and procuring data sources.\n\n        However, in the longer term, as LLMs continue to advance, the need for human inputs, edits, and feedback may diminish. We may find ourselves increasingly just rubber-stamping the output produced by ever-more advanced LLMs. Ultimately, it's possible that sufficiently advanced AI systems may be able to produce and articulate superior economic models, potentially making the cognitive work of human economists redundant.\n\n        This potential future underscores the importance of economists focusing on tasks that leverage uniquely human traits and adapting to work alongside increasingly capable AI systems.\"\n\n        [Remainder omitted for space reasons]\n    \n\n\n    \n        \n            Analysis: The LLM provided well-crafted responses that accurately reflect the perspective provided in the attached background paper from February 2023. In its response to the first question, it even employed the classical human trick of punting the exact question (asking for one specific capability) and focusing on a more general question that summarizes several categories of use cases.\n        \n        \n            \n            This approach works well because the LLM can draw on the paper it was provided to generate insightful and relevant responses that align with the researcher's work and the interviewer's audience. The model maintains consistency with the original research while adapting the language to suit an interview format, making complex ideas more accessible to a broader audience.\n        \n        [+]\n    \n\nLLMs can also be employed to generate thought-provoking and relevant interview questions. This capability can be tailored to different target audiences, enhancing the impact and reach of research promotion efforts. For instance:\n\n    \n        \n            Prompt: I am a journalist working for the Chronicle of Higher Education. I enjoyed reading the attached paper and scheduled an interview with the author. What would be five good questions to ask him based on the content of the paper?\n        \n        \n            [Attachment: w30957.pdf]\n        \n        [+] click to expand\n    \n\n    \n\n    Response (Claude 3.5 Sonnet): Based on the content of the paper, here are five good questions you could ask the author in your interview:\n    [+] click to expand\n    \n        \n            You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n            In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n            You mention that LLMs can be used to simulate human subjects for research. What are the ethical considerations and potential pitfalls of this approach, and how might it change the landscape of behavioral economics?\n            The paper touches on the limitations of current LLMs, particularly in areas like mathematical derivations. How do you see these limitations being addressed in future iterations of LLMs, and what implications might this have for theoretical economics?\n            You draw parallels between the rise of LLMs and Garry Kasparov's observations about chess computers. How do you think economists should prepare for a future where AI systems might produce superior economic models? What skills should economists focus on developing?\n        \n\n        These questions cover a range of topics from the paper, including specific capabilities of LLMs, their potential impact on the field of economics, ethical considerations, current limitations, and future implications for the profession. They should provide a good basis for an in-depth discussion with the author about the key themes of his paper.\n    \n\n\n    \n    \n        Analysis: The questions—coincidentally the ones answered in the previous chat—are thoughtfully selected, effectively covering the most critical components of the paper.\n    \n\n\nThe capability of generating insightful questions is useful not only for journalists but also for economists for two key reasons.\n\n\n    \n    \n        First, economists often find themselves in situations where they are asked to suggest questions that would lead to interesting conversations targeted at specific audiences.\n         Journalists, podcast hosts, and moderators at panel events regularly turn to their interviewees or speakers for such input. LLMs can be an invaluable tool in these scenarios, helping economists quickly generate relevant and engaging questions tailored to different audiences. For instance, the questions generated in the previous example would be markedly different from those aimed at a business newspaper, a policy think tank, or a general interest magazine. By leveraging LLMs, economists can effectively shape the discourse around their research and ensure it resonates with diverse audiences.\n        [+]\n    \n\n\n    \n    \n        Second, LLMs allow researchers to prepare thoroughly for high-stakes interviews.\n         In such cases, the prompt could be modified to generate challenging questions that the researcher might face, for example, by adding a phrase like \"What would be some challenging questions that I may face?\" This approach can help to anticipate difficult questions (especially if the interviewers themselves turn to LLMs) and prepare thoughtful responses in advance.\n        [+]\n    \n\n\n\n\nPerhaps the most impressive tools when it comes to promoting research papers is the ability of Google’s NotebookLM to generate `deep dive’ podcasts. The system works by first generating an outline of the source material and identifying linkeages, revising that outline, producing a detailed version of the script, performing a round of critique and the associated modifications, and then adding disfluencies to make the conversation sound more natural.\n\n\n    \n    \n        Prompt: Generate deep dive conversation. [Attachment: w30957.pdf]\n    \n\n    \n\n    \n    Response (NotebookLM):\n    [+] click to expand\n    \n        Male host: Okay, so you're interested in the economics of AI...\n        Female host: Yeah.\n        Male host: ...specifically, all the buzz about these large language models, LLMs.\n        Female host: mmhmm\n        Male host: You're in the right place, because we're doing a deep dive into how these things actually work, what they could do for economists like you right now, and what the future might hold.\n        Female host: And it's a future that's changing rapidly. It seems like every day there's some new breakthrough in what these models can do.\n        Male host: Well, let's unpack that a bit.\n        Female host: mhm\n        Male host: Imagine having a research assistant who can not only brew you a perfect cup of coffee, but also write code in multiple languages,...\n        Female host: Yeah.\n        Male host: ...summarize dense academic papers in seconds, and even brainstorm potential downsides to your economic model. That's the promise of LLMs, right?\n        Female host: Yep.\n        Male host: But how do they actually work? Is it really some kind of artificial intelligence magic?\n        Female host: It's not magic, but it's pretty close. Think of LLMs as incredibly complex neural networks, but instead of crunching numbers, they're trained on massive data sets of text. We're talking about everything from academic journals and books to code repositories and even social media posts—they process all of that information, learning patterns, relationships between concepts, and even different writing styles... [Remainder omitted for space reasons.]\n        [Transcription using otter.ai. Full audio version available at https://t.ly/GrC0d.]\n    \n\n\n\n    \n        \n            Analysis: The generated podcast lays out the material in the paper in an engaging conversational format while covering the content in a clear and insightful manner targeted at laypeople. One interesting observation is that the male host mistakenly attributes physical capabilities to the AI research assistant (\"...who can not only brew you a perfect cup of coffee...\").\n        \n    \n\n\nSince October 2024, NotebookLM allows users to customize the generated podcasts with specific instructions. For researchers, a useful prompt may look like this: “Your audience are PhD economists who are eager to learn how to effectively use LLMs in their research work.”"
  },
  {
    "objectID": "subs/promoting.html#social-media-posts",
    "href": "subs/promoting.html#social-media-posts",
    "title": "Applications of LLMs",
    "section": "",
    "text": "For the following exercise, I uploaded the original working paper version of this paper  to GPT-4o and asked it to generate social media posts, in this particular example for X (formerly Twitter):\n\n\n    \n        \n            Prompt: Write a series of X posts to promote the attached paper. Use simple sentences and make them catchy. [Attachment: w30957.pdf]\n        \n    \n\n    \n\n    Response (GPT-4o):\n    [+] click to expand\n    \n        \n            Exciting new possibilities! My latest NBER paper explores 25 ways language models like ChatGPT can boost research in economics. From ideation to coding, LLMs are transforming our workflows! #AI #EconResearch #LLM\n            Did you know? Large language models are now capable of automating micro-tasks like data analysis, writing, and even mathematical derivations in economic research. Check out my paper for more insights! #AIinEconomics #ProductivityBoost\n            Researchers, take note! LLMs aren't just about writing—they can also help with background research, coding, and more. Discover 6 key areas where they can assist in my latest paper. #CognitiveAutomation #AI #Economics\n            What’s the future of cognitive labor? My paper dives into how LLMs could reshape the role of human economists, making us more efficient while raising new questions about the future of work. #FutureOfWork #AIRevolution\n            Want to stay ahead in research? Learn how to incorporate LLMs into your daily tasks and increase productivity. Don’t miss the insights in my NBER paper! #Economics #AItools #GenerativeAI\n        \n    \n\n\n    \n        \n            Analysis: The LLM adapts to the optimal format for different social media platforms. Upon request, it can also incorporate suitable emoticons or links."
  },
  {
    "objectID": "subs/promoting.html#presentation-slides",
    "href": "subs/promoting.html#presentation-slides",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Successful promotion leads to invitations to present your paper. The latest generation of LLMs released in 2024 also have the capability to draft slides based on a research paper. This is a difficult exercise because it requires that the model exhibits detailed recall across a long paper.\n\n    \n        \n            Prompt: Can you create a 20-slide deck for the attached economic research paper?[Attachment: w30957.pdf]\n        \n    \n\n    \n\n    Response (Claude 3):\n    [+] click to expand\n    \n        Here is a 20-slide deck summarizing the key points from the research paper \"Language Models and Cognitive Automation for Economic Research\" by Anton Korinek:\n\n        Slide 1: Title Slide\n        \n            Paper title: \"Language Models and Cognitive Automation for Economic Research\"\n            Author: Anton Korinek\n        \n\n        Slide 2: Introduction\n        \n            Large language models (LLMs) can revolutionize economic research\n            Describes 25 use cases of LLMs across 6 domains\n            Provides instructions and examples for each use case\n            Classifies usefulness of capabilities from experimental to highly useful\n        \n\n        Slide 3: What are LLMs?\n        \n            LLMs are foundation models\n            Large deep learning models pre-trained on lots of data\n            Form abstract representations and world model from training data\n            Capabilities improve according to predictable scaling laws as compute and data increase\n            Many capabilities are emergent, arising suddenly at specific thresholds\n        \n\n        [Slides 4–18 omitted for space reasons]\n\n        Slide 19: Importance of Economic Ideas\n        \n            Economists can translate human concepts to analytic forms for AIs\n            Economic ideas will influence worldview of future AI systems\n            \"Soon or late, it is ideas which are dangerous for good or evil\" (Keynes)\n        \n\n        Slide 20: Conclusion\n        \n            LLMs are becoming useful for automating research tasks\n            Humans still have comparative advantage in generating research for now\n            Important to adopt LLMs to boost productivity\n            Prepare for potentially transformative long-term impacts\n        \n    \n\n\n    \n    \n        Analysis: The generated slides provide an excellent first draft on which to build. Notably impressive in the latest version of Claude used in the example was its ability to recall detailed information from the paper, successfully generating 20 content-rich slides without noticeable memory lapses. Additionally, the LLM effectively segmented the material, distributing it appropriately across the requested number of slides."
  },
  {
    "objectID": "subs/promoting.html#blog-posts",
    "href": "subs/promoting.html#blog-posts",
    "title": "Applications of LLMs",
    "section": "",
    "text": "One of the most effective ways of promoting research papers to a broader audience is to write blog posts that convey their message in simple terms. This is an easy task for modern LLMs---users can upload the underlying paper to provide the content, and the LLM can create a blog post to the user's specifications. The following is an example that builds on the prompt that generated with Anthropic Prompt Generator to draft a summary of the first version of this paper .\n\n\n    \n        \n            Prompt: Your task is to help draft a blog post for the Brookings Institution based on an economics research paper. The full text of the paper is attached. The target audience for this blog post are economic researchers.[Attachment: w30957.pdf]  \n            \n            [continuing with the prompt generated in Chat (reference omitted)]\n        \n    \n\n    \n\n    Response (GPT-4o): How AI Is Reshaping Economic Research: Exploring Language Models for Cognitive Automation\n    [+] click to expand\n    \n        Recent advances in artificial intelligence have brought transformative tools like large language models (LLMs) into the toolkit of economic researchers. These models, such as OpenAI's ChatGPT, are not just conversational agents; they represent a major leap in how cognitive tasks can be automated, promising to significantly alter the landscape of research in economics. In his recent paper, \"Language Models and Cognitive Automation for Economic Research,\" Anton Korinek lays out 25 ways that these models can be leveraged, offering insights that are highly relevant for economic researchers looking to understand the potential impact of AI on their field.\n\n        Six Domains of LLM Utility in Economic Research\n\n        Korinek's paper categorizes the applications of LLMs into six key domains. These applications span from idea generation to coding, offering a comprehensive toolkit for researchers.\n\n        \n            Ideation and Writing: LLMs can assist researchers from the very start of a project, helping brainstorm ideas, generate counterarguments, and refine initial drafts.\n        \n\n        [Remainder omitted for space reasons]\n    \n\n\n    \n        \n            Analysis: The draft blog posts generated by the current generation of frontier LLMs are generally well done and, after some editing, save significant time compared to having to write such a post from scratch."
  },
  {
    "objectID": "subs/promoting.html#conducting-interview",
    "href": "subs/promoting.html#conducting-interview",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Large language models (LLMs) have emerged as powerful tools for conducting and assisting with interviews related to academic research. Their capabilities in this domain can be leveraged in two primary ways: answering interview questions and generating insightful questions for various audiences.\nLLMs can be used to answer interview questions on behalf of researchers, using their published work as a knowledge base. This approach is particularly useful when researchers are preparing responses for written interviews or need assistance in formulating clear and concise answers. For example, using a research paper as a reference, an LLM could provide detailed answers to questions about the impact of AI on economic research.\n\n    \n        \n            Prompt: I received an interview request on the impact of AI on economic research from The Chronicle of Higher Education. Can you help me draft responses based on the attached paper of mine? I am pasting the questions here:\n        \n        \n            \n                You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n                In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n                You mention that LLMs can be used to simulate human subjects for research. What are the ethical considerations and potential pitfalls of this approach, and how might it change the landscape of behavioral economics?\n                The paper touches on the limitations of current LLMs, particularly in areas like mathematical derivations. How do you see these limitations being addressed in future iterations of LLMs, and what implications might this have for theoretical economics?\n                You draw parallels between the rise of LLMs and Garry Kasparov's observations about chess computers. How do you think economists should prepare for a future where AI systems might produce superior economic models? What skills should economists focus on developing?\n            \n            [Attachment: w30957.pdf]\n        \n        [+] click to expand\n    \n\n    \n\n    Response (Claude 3.5 Sonnet):\n    [+] click to expand\n    \n        Certainly! I'd be happy to help you draft responses based on your paper. I'll provide suggested responses for each question, drawing directly from the content and ideas presented in your paper.\n\n        1. You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n\n        Suggested response: \"Based on my analysis, I believe the capabilities related to writing and data analysis have the most potential to revolutionize economic research in the near term. LLMs are particularly adept at tasks like synthesizing text, editing, and generating catchy titles or summaries. These capabilities can significantly streamline the writing process, allowing researchers to focus more on ideas and analysis rather than the mechanics of writing.\n\n        In terms of data analysis, LLMs show great promise in extracting data from text, reformatting data, and classifying and scoring text. These capabilities can automate many time-consuming tasks in data preparation and initial analysis, potentially accelerating the research process.\n\n        It's worth noting that I've rated several capabilities in these domains as 'highly useful' in my paper, indicating that incorporating them into research workflows can already save significant time and boost productivity. As these tools continue to improve, I expect their impact on how we conduct research to grow substantially.\"\n\n        2. In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n\n        Suggested response: \"As LLMs become more advanced, I anticipate a shift in the role of human economists. In the medium term, I expect LLM-based assistants and tutors to become increasingly useful for generating content that makes up research papers. Human researchers will likely focus more on their comparative advantages—posing questions, suggesting directions for obtaining answers, discriminating which parts of the produced content are useful, editing, and providing feedback.\n\n        In essence, the role may evolve to be more akin to that of an advisor or research manager. Economists will likely spend more time organizing research efforts, coordinating teams, and procuring data sources.\n\n        However, in the longer term, as LLMs continue to advance, the need for human inputs, edits, and feedback may diminish. We may find ourselves increasingly just rubber-stamping the output produced by ever-more advanced LLMs. Ultimately, it's possible that sufficiently advanced AI systems may be able to produce and articulate superior economic models, potentially making the cognitive work of human economists redundant.\n\n        This potential future underscores the importance of economists focusing on tasks that leverage uniquely human traits and adapting to work alongside increasingly capable AI systems.\"\n\n        [Remainder omitted for space reasons]\n    \n\n\n    \n        \n            Analysis: The LLM provided well-crafted responses that accurately reflect the perspective provided in the attached background paper from February 2023. In its response to the first question, it even employed the classical human trick of punting the exact question (asking for one specific capability) and focusing on a more general question that summarizes several categories of use cases.\n        \n        \n            \n            This approach works well because the LLM can draw on the paper it was provided to generate insightful and relevant responses that align with the researcher's work and the interviewer's audience. The model maintains consistency with the original research while adapting the language to suit an interview format, making complex ideas more accessible to a broader audience.\n        \n        [+]\n    \n\nLLMs can also be employed to generate thought-provoking and relevant interview questions. This capability can be tailored to different target audiences, enhancing the impact and reach of research promotion efforts. For instance:\n\n    \n        \n            Prompt: I am a journalist working for the Chronicle of Higher Education. I enjoyed reading the attached paper and scheduled an interview with the author. What would be five good questions to ask him based on the content of the paper?\n        \n        \n            [Attachment: w30957.pdf]\n        \n        [+] click to expand\n    \n\n    \n\n    Response (Claude 3.5 Sonnet): Based on the content of the paper, here are five good questions you could ask the author in your interview:\n    [+] click to expand\n    \n        \n            You describe 25 use cases for large language models (LLMs) in economic research across six domains. Which of these capabilities do you think has the most potential to revolutionize how economists conduct research in the near term?\n            In the paper, you speculate on the longer-term implications of cognitive automation via LLMs for economic research. Could you elaborate on how you envision the role of human economists evolving as LLMs become more advanced?\n            You mention that LLMs can be used to simulate human subjects for research. What are the ethical considerations and potential pitfalls of this approach, and how might it change the landscape of behavioral economics?\n            The paper touches on the limitations of current LLMs, particularly in areas like mathematical derivations. How do you see these limitations being addressed in future iterations of LLMs, and what implications might this have for theoretical economics?\n            You draw parallels between the rise of LLMs and Garry Kasparov's observations about chess computers. How do you think economists should prepare for a future where AI systems might produce superior economic models? What skills should economists focus on developing?\n        \n\n        These questions cover a range of topics from the paper, including specific capabilities of LLMs, their potential impact on the field of economics, ethical considerations, current limitations, and future implications for the profession. They should provide a good basis for an in-depth discussion with the author about the key themes of his paper.\n    \n\n\n    \n    \n        Analysis: The questions—coincidentally the ones answered in the previous chat—are thoughtfully selected, effectively covering the most critical components of the paper.\n    \n\n\nThe capability of generating insightful questions is useful not only for journalists but also for economists for two key reasons.\n\n\n    \n    \n        First, economists often find themselves in situations where they are asked to suggest questions that would lead to interesting conversations targeted at specific audiences.\n         Journalists, podcast hosts, and moderators at panel events regularly turn to their interviewees or speakers for such input. LLMs can be an invaluable tool in these scenarios, helping economists quickly generate relevant and engaging questions tailored to different audiences. For instance, the questions generated in the previous example would be markedly different from those aimed at a business newspaper, a policy think tank, or a general interest magazine. By leveraging LLMs, economists can effectively shape the discourse around their research and ensure it resonates with diverse audiences.\n        [+]\n    \n\n\n    \n    \n        Second, LLMs allow researchers to prepare thoroughly for high-stakes interviews.\n         In such cases, the prompt could be modified to generate challenging questions that the researcher might face, for example, by adding a phrase like \"What would be some challenging questions that I may face?\" This approach can help to anticipate difficult questions (especially if the interviewers themselves turn to LLMs) and prepare thoughtful responses in advance.\n        [+]"
  },
  {
    "objectID": "subs/promoting.html#podcasts",
    "href": "subs/promoting.html#podcasts",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Perhaps the most impressive tools when it comes to promoting research papers is the ability of Google’s NotebookLM to generate `deep dive’ podcasts. The system works by first generating an outline of the source material and identifying linkeages, revising that outline, producing a detailed version of the script, performing a round of critique and the associated modifications, and then adding disfluencies to make the conversation sound more natural.\n\n\n    \n    \n        Prompt: Generate deep dive conversation. [Attachment: w30957.pdf]\n    \n\n    \n\n    \n    Response (NotebookLM):\n    [+] click to expand\n    \n        Male host: Okay, so you're interested in the economics of AI...\n        Female host: Yeah.\n        Male host: ...specifically, all the buzz about these large language models, LLMs.\n        Female host: mmhmm\n        Male host: You're in the right place, because we're doing a deep dive into how these things actually work, what they could do for economists like you right now, and what the future might hold.\n        Female host: And it's a future that's changing rapidly. It seems like every day there's some new breakthrough in what these models can do.\n        Male host: Well, let's unpack that a bit.\n        Female host: mhm\n        Male host: Imagine having a research assistant who can not only brew you a perfect cup of coffee, but also write code in multiple languages,...\n        Female host: Yeah.\n        Male host: ...summarize dense academic papers in seconds, and even brainstorm potential downsides to your economic model. That's the promise of LLMs, right?\n        Female host: Yep.\n        Male host: But how do they actually work? Is it really some kind of artificial intelligence magic?\n        Female host: It's not magic, but it's pretty close. Think of LLMs as incredibly complex neural networks, but instead of crunching numbers, they're trained on massive data sets of text. We're talking about everything from academic journals and books to code repositories and even social media posts—they process all of that information, learning patterns, relationships between concepts, and even different writing styles... [Remainder omitted for space reasons.]\n        [Transcription using otter.ai. Full audio version available at https://t.ly/GrC0d.]\n    \n\n\n\n    \n        \n            Analysis: The generated podcast lays out the material in the paper in an engaging conversational format while covering the content in a clear and insightful manner targeted at laypeople. One interesting observation is that the male host mistakenly attributes physical capabilities to the AI research assistant (\"...who can not only brew you a perfect cup of coffee...\").\n        \n    \n\n\nSince October 2024, NotebookLM allows users to customize the generated podcasts with specific instructions. For researchers, a useful prompt may look like this: “Your audience are PhD economists who are eager to learn how to effectively use LLMs in their research work.”"
  },
  {
    "objectID": "subs/practical.html",
    "href": "subs/practical.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Practical Considerations for LLM Usage\nData Confidentiality – An important issue for researchers is how to ensure the confidentiality of the data that they enter into LLMs. OpenAI offers a “Temporary Chat” option in its ChatGPT app as well as a privacy option in the user settings (turn off “Improve the model for everyone”) to let users opt out from their inputs being used for training future LLMs. OpenAI does not use user data that are entered via APIs. Anthropic does not use user data for future training except with an explicit opt-in or, in rare circumstances, if it is flagged for safety review. Google advises users against entering confidential information into its Gemini apps since input data may be used for future training purposes. For highly confidential data, the safest way of using LLMs is to run a cutting-edge open-source model on a local computer.\nIn economics, most AEA journals will soon require authors to declare whether and how they have employed LLMs in their research. Although I usually welcome transparency, my own perspective is that such a requirement is unnecessary and may be potentially counterproductive. LLMs are rapidly becoming essential tools in the research process, akin to word processors, calculators, or econometric software. If used responsibly, they do not inherently compromise the integrity or originality of research any more than these other widely accepted tools. It is crucial to remember that authors remain solely accountable for the content they submit, regardless of the tools used in its creation. While it may be beneficial to remind authors of this responsibility when submitting, a formal declaration requirement could inadvertently create unwarranted skepticism among readers and discourage the use of these powerful productivity-enhancing tools. Moreover, such declarations are difficult to verify conclusively, rendering them at odds with the spirit of the revelation principle, which emphasizes designing mechanisms that naturally encourage truthful disclosure.\nMy own perspective is to be cautious about introducing additional bureaucratic steps that may impede the research process without clear benefits. I advocate for the judicious and responsible use of LLMs in research, always coupled with careful verification of results—a practice no different from how we treat output from human research assistants or other analytical tools. The focus should remain on the quality and integrity of the final research product, rather than the specific tools used in its creation.\n\n Watermarking -- Relatedly, watermarking of LLM outputs has become an important new consideration when using LLMs. Watermarking embeds markers in AI-generated text by introducing a specific fingerprint key in the pseudorandom token selection during the text generation process . This makes it possible to trace back the origin of the text to the LLM for those who know the associated key while remaining undetectable to regular readers. Google has implemented this watermarking method, called SynthID, in the output of its Gemini models, representing the first known large-scale deployment of text watermarking. \n \nWhile watermarking could help establish provenance and potentially address concerns about academic integrity and unauthorized AI use, its implications deserve careful consideration. First, the markers are not reliable since they can be defeated through simple paraphrasing using other LLMs. Secondly, the practice raises privacy concerns since watermarks could theoretically enable tracking of AI-generated content back to individual users. For economic researchers, watermarking has important implications both as a subject of study (for example, regarding information asymmetries and verification mechanisms) and as a practical consideration when using LLMs for research tasks. Users of Google DeepMind’s Gemini models should be aware of the watermarks contained in the generated output. It is unknown whether other labs employ similar mechanism.\n\n     Reproducibility  is a challenge when working with LLMs, for several reasons. First, chatbots are programmed to be random—users typically rate responses more highly when the so-called \"temperature\" parameter of the LLM that controls the degree of randomness introduced into the text generation is greater than zero. Secondly, even at zero temperature, the output of LLMs is not always perfectly reproducible for internal technical \n    For example, OpenAI states that \"setting temperature to 0 will make the outputs mostly deterministic, but a small amount of variability will remain.\" \n    See  \n    \n        https://platform.openai.com/docs/guides/gpt/why-are-model-outputs-inconsistent\n     \n    for further information on the inconsistency of model output at temperature zero, and  \n    \n        https://community.openai.com/t/a-question-on-determinism/8185\n     \n    for a discussion of the inherent indeterminacy of efficiently performing LLM inference.\n\n\n\n    In a nutshell, the efficient execution of LLMs with hundreds of billions of parameters requires that calculations are parallelized. \n    However, given the discrete nature of computers, calculations such as \\( (a\\cdot b)\\cdot c \\) sometimes deliver a slightly different result than \\( a\\cdot(b\\cdot c) \\). \n    When an LLM calculates which word has the top probability to be next, minor differences in the parallelization of the exact same calculations sometimes come to matter, resulting in different word choices. \n    And once one word changes, everything that follows becomes different.\n\n    Third, to the extent that models draw on web search (as described in the page about search), the continually evolving nature of information available on the internet changes the search results that feed into LLMs' responses. \n    Finally, the models offered by companies with proprietary models change over time, and older, less efficient models are regularly\n\n    See, for example,  \n    \n        https://platform.openai.com/docs/deprecations\n     \n    on OpenAI's policy of model deprecations as well as the current timelines for how long existing models are guaranteed to remain available.\n\n\n\nThe examples and use cases in the remainder of this article use the leading publicly available LLMs at the time that each use case was incorporated into this living document. \nThe latest examples employ OpenAI's o1 and GPT-4o as well as Claude 3.5 Sonnet (New). \nThe examples that originate from the Dec. 2023 JEL version of the article used primarily OpenAI's GPT-4, version gpt4-0613. \n\nIn the online materials associated with this article, I provide Python code to reproduce those results by calling OpenAI's API. \n\n\n    Non-programmers can replicate the results (subject to the limitations discussed above) on the web-based experimentation platform \n    https://platform.openai.com/playground, \n    setting the temperature parameter to zero. \n    Both the OpenAI API and the Playground platform require a paid subscription for \n    Executing all of the examples based on OpenAI models in Oct. 2023 cost slightly below 50 cents. \n    Using the updated and more powerful GPT-4o for the same queries in June 2024, the cost had fallen to 10 cents. \n    At the time of writing, the latest version of GPT-4o has halved costs yet again. \n    Up-to-date pricing information for OpenAI's models is available at  \n    https://openai.com/pricing.\n\n\n Additional Resources  -- Let me also point to two additional resources for readers interested in the topic of this paper. \n\nFirst,  provides a survey of how LLMs have transformed text analysis in economic research. \n offers a JEL survey of deep learning for economists, covering classifiers, regression models, generative AI, and embedding models, together with a companion website,  \nEconDL."
  },
  {
    "objectID": "subs/reasoning.html",
    "href": "subs/reasoning.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Advances in Reasoning\n\nOne of the most significant advances in recent months is that LLMs are becoming better at reasoning. Traditional LLMs generate output via token-by-token prediction, as described, e.g., in Section 2 of the originally published version of this paper . Although this basic architecture has proven surprisingly powerful, it makes it hard for basic LLMs to go back in the text that they have already generated to reason about it and iteratively improve it, as humans do when they write. A good analogy is that token generation by LLMs proceeds like a human's stream-of-consciousness. This makes it easy for such systems to emulate what  called system-1 thinking but difficult to perform cognitive tasks that correspond to system-2 thinking and require reasoning. For example, a famous test that poses no problem for fourth-graders but has regularly tripped up even the most advanced LLMs before o1 was the so-called strawberry test: asking an LLM \"How many R's are there in strawberry?\" typically delivers \n\n\n    One of the reasons for this rather basic failure is that LLMs encode text not in letters, as we do in the English language, but in tokens that correspond to syllables or words and that imply that the spelling is not directly observable for LLMs when they process text. This implies that the model needs to reason about the English spelling corresponding to the underlying tokens.  use the term \"jagged frontier\" to observe that LLMs easily perform some tasks but fail at other tasks that are of seemingly similar difficulty for humans. \n\n\n\n\nAware of these limitations, researchers have worked hard on finding ways to enable LLMs to become better at reasoning , . An influential mechanism to obtain better-reasoned results has been chain-of-thought prompting, which instructs LLMs to proceed step-by-step when generating responses to a prompt. This technique has delivered significant performance gains by guiding LLMs to break down complex questions into smaller logical steps that are easier to accomplish—akin to a student who performs better on an exam when asked to report his intermediate steps.  show that chain-of-thought prompting considerably improves LLM performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. \n\nFor example, when given a question like \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\" they show that OpenAI's GPT-3 from 2020 failed (\"The answer is 27.\") but succeeds when guided to reason through the calculation, producing the answer: \"The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.\"\n\n\n\n\nWhen academics reason about a novel research problem, an additional strategy that they employ is to perform a sort of tree search: they generate different hypotheses, evaluate them, pursue the most promising ones, and refine them further. Recent advances in LLM-based reasoning attempt to emulate this process. For example,  propose what they call a tree-of-thoughts technique, which extends chain-of-thought prompting by generating multiple intermediate steps or proverbial \"thoughts\" at each stage of the reasoning process. This allows LLMs to explore different paths of reasoning, evaluate their potential, and select the most promising ones to continue—much like, for example, a chess engine evaluating different moves. This approach has shown particular promise in solving complex reasoning tasks that require planning and strategic thinking. In spring 2024, Anthropic introduced a feature that allows Claude to engage in short episodes of reasoning that are hidden from the user behind a message like \"Thinking deeply...\" or \"Ruminating...\" before generating output. This led to clear performance gains, but with little fanfare.\n\n\n\n\n\nOpenAI's o1 series of models, released on September 12, 2024, is the first that is explicitly designed for LLM-based \n    Originally nicknamed \"Q*\" and later \"strawberry,\" its creators argued that the system's architecture is sufficiently different from its earlier GPT series to merit a new name that is simply an abbreviation of \"OpenAI 1.\"\n .\n\nAlthough an official description of the model's architecture is not publicly available, OpenAI seems to have employed reinforcement learning to hone the model's automated use of the two techniques described in the preceding two paragraphs: it employs a chain-of-thought technique to break down complex steps into simpler ones while also employing a form of tree search to attempt different approaches to solving a problem and to recognize and correct mistakes. \n\nUnlike earlier LLMs, o1 models react to prompts by first generating reasoning tokens that are hidden from the user—akin to a simulated inner monologue—as the model \"thinks\" through the problem at hand. Depending on the question, this may take from a few seconds to several minutes. Once the hidden thinking process is finished, the model generates a response for the user that summarizes the outcome of the reasoning process. \n\nThis mechanism has enabled o1 to achieve significant gains in reasoning compared to GPT-4o, which itself was a leader in this category before o1's release. However,  document that even the reasoning capabilities of o1 still have significant shortcomings, for example, that small changes in numbers or the addition of irrelevant information reduce model performance.\n\n\n\nThe o1 series consists of several models. In Sept. 2024, OpenAI released a preview version of the full model, o1-preview, as well as a smaller and more cost-efficient model, o1-mini, which is particularly well-suited for math and coding applications and better than o1-preview in some of these applications. The full version o1 is the most powerful of the three and expected later in fall 2024.  Figure 2  visualizes the advances compared to GPT-4o on three benchmarks: in the American Invitational Mathematics Examination (AIME), the qualifying exam for the US Mathematical Olympiad, o1 performed at a level corresponding to the top-500 contestants; in the Codeforces programming competition, it performed at the 89th percentile of participants; in the hardest (diamond) category of the Graduate-Level Google-Proof Q&A benchmark, which tests for complex reasoning abilities in biology, chemistry, and physics, it outperformed PhD-level human experts.\n\n    \n        \n        \n            Figure 2: o1's performance on reasoning benchmarks. \n            Source: . Note: Solid bars show one-shot accuracy; shaded regions show performance of a majority vote of 64 responses.\n        \n    \n\n\nInterestingly, o1 also fundamentally changes the economics of operating frontier AI models: Under the traditional LLM paradigm, the computational cost of training models exceeded the cost of generating output (inference) by orders of magnitude. By contrast, o1 relies heavily on generating reasoning tokens during inference, and—in analogy to the scaling laws for training LLMs discussed in Section 2 of the original article—the model's responses improve predictably in the amount of reasoning tokens employed . This implies far greater variable costs compared to traditional LLMs. At present, o1 models are only available to OpenAI's paying customers, with limits on the number of queries that can be performed per week.\n\nThe following reproduces an experience of mine with o1-preview for a task that was far beyond the capabilities of earlier LLMs:\n\n\n\n    \n    \n        Prompt: The following is a no-arbitrage relationship between an interest rate on new long-term debt in period \\( t \\), \\( R_{N,t} \\), and expected future short-term rates, \\( R_{t+s} \\):\n        \n            \n                \\[\n                \\frac{1}{R_{N,t}+\\delta}=E\\sum_{i=0}^{\\infty}\\left[\\frac{\\left(1-\\delta\\right)^{i}}{\\prod_{s=0}^{i}\\left(1+R_{t+s}\\right)}\\right]\n                \\]\n            \n            \n                Can you log-linearize this expression around the steady-state value of the interest rates, which we denote by \\( R^\\ast \\), and which is the same for both interest rates? Denote deviations from the steady state with lower-case variables.\n            \n        \n        [+] click to expand\n    \n\n    \n\n    \n    Response (o1-preview): (Thought for 53 seconds)\n    [+] click to expand\n    \n        Original Equation:\n        \n            \\[\n            \\frac{1}{R_{N,t} + \\delta} = E_t \\left[ \\sum_{i=0}^\\infty \\frac{(1 - \\delta)^i}{\\prod_{s=0}^{i} (1 + R_{t+s})} \\right]\n            \\]\n        \n\n        Steady State Analysis:\n        At steady state, \\( R_{N,t} = R^\\ast \\) and \\( R_{t+s} = R^\\ast \\). The equation simplifies to:\n        \n            \\[\n            \\frac{1}{R^\\ast + \\delta} = \\frac{1}{1 + R^\\ast} \\cdot \\frac{1}{1 - k}\n            \\]\n        \n        where \\( k = \\frac{1 - \\delta}{1 + R^\\ast} \\).\n\n        Log-Linearization Steps:\n        \n            \n                Left-Hand Side (LHS): Expand \\( \\frac{1}{R_{N,t} + \\delta} \\) around \\( R^\\ast \\):\n                \\[\n                \\frac{1}{R_{N,t} + \\delta} \\approx \\frac{1}{R^\\ast + \\delta} \\left(1 - \\frac{r_{N,t}}{R^\\ast + \\delta}\\right)\n                \\]\n            \n            \n                Right-Hand Side (RHS): Approximate numerator and denominator:\n                \n                    Denominator:\n                        \\[\n                        \\prod_{s=0}^{i} (1 + R_{t+s}) \\approx (1 + R^\\ast)^{i+1} \\exp\\left(\\frac{1}{1 + R^\\ast} \\sum_{s=0}^{i} r_{t+s}\\right)\n                        \\]\n                    \n                    Numerator:\n                        \\[\n                        (1 - \\delta)^i \\approx e^{-i\\delta}\n                        \\]\n                    \n                \n            \n            \n                Final Log-Linearized Expression:\n                \\[\n                r_{N,t} = (1 - k) \\sum_{s=0}^\\infty k^s r_{t+s}\n                \\]\n            \n        \n\n        Answer: Yes; the log-linearized expression is:\n        \n            \\[\n            r_{N,t} = (1 - k) \\sum_{s=0}^\\infty k^s r_{t+s}\n            \\]\n        \n        where \\( k = \\frac{1 - \\delta}{1 + R^\\ast} \\).\n    \n\n\n\n\n    \n    \n        Follow-up Prompt: Great. Can you express this as a forward difference equation in the style of \\( r_{N,t} = \\text{coeff1} \\cdot r_{N,t+1} + \\text{coeff2} \\cdot r_{t} \\)?\n    \n\n    \n\n    \n    Response (o1-preview): (Thought for 22 seconds) Yes, we can express the log-linearized relationship as a forward difference equation: \n    [+] click to expand\n    \n        \n            \\[\n            r_{N,t} = k \\, r_{N,t+1} + (1 - k) \\, r_t\n            \\]\n        \n        where \\( k = \\frac{1 - \\delta}{1 + R^\\ast} \\).\n\n        Derivation:\n        (Link to full derivation)\n\n        Final Answer:\n        \n            \\[\n            r_{N,t} = k \\, r_{N,t+1} + (1 - k) \\, r_t\n            \\]\n        \n        where \\( k = \\frac{1 - \\delta}{1 + R^\\ast} \\).\n    \n\n\n    \n    \n        Analysis: This example illustrates that even o1-preview, which is less capable than the ultimate o1, can perform complex mathematical derivations that can save researchers significant amounts of time.\n        \n            I should note that the prompt in the chat contains an important hint for how to efficiently approach the problem, that the steady state of the two interest rate variables will be the same. Without this hint, the system struggled. Even with the hint, the model occasionally produced mistakes in derivations such as the one requested in the chat but was frequently able to correct mistakes when I pointed them out. Moreover, the derivation steps reported in the example appear at times a bit clumsy—it looks like this LLM is still \"in its infancy\".\n        \n        [+]\n    \n\n\nAccording to , o1 has impressed many scientists with its complex problem-solving performance, which is particularly beneficial in disciplines that rely on mathematical modeling. While o1 can reason through problems step by step, they also noted that these chains of thoughts can increase the risk of \"hallucinations.\" \n\nFor complex coding tasks, o1 excels at following, generating, and debugging intricate code structures. Its reasoning capabilities enable it to tackle problems that require deeper contextual understanding and strategic thinking than earlier LLMs, making it particularly valuable for academics working on sophisticated coding projects. The following example documents o1-preview’s response to a request to code a solution ot the Ramsey growth model, which earlier LLMs could not do (as documented in the December 2023 version of the paper):\n\n\n    \n    \n        Prompt: Can you write Python code to solve the Ramsey growth model for standard parameter values?\n        [+] click to expand\n        \n            (o1-preview)\n        \n    \n\n    \n\n    \n    Response (o1-preview): Thought for 34 seconds\n    [+] click to expand\n    \n        Certainly! Below is Python code that solves the Ramsey growth model using standard parameter values. The code sets up the differential equations representing the Ramsey model, computes the steady-state values, and then uses a shooting method to find the optimal initial consumption that leads to convergence to the steady state. It then simulates the model over time and plots the capital and consumption per capita.\n\n        \nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.optimize import root_scalar\nimport matplotlib.pyplot as plt\n\n# Parameters\nalpha = 0.3   # Output elasticity of capital\nrho = 0.04    # Time preference rate\ndelta = 0.05  # Depreciation rate\ntheta = 2.0   # Coefficient of relative risk aversion (CRRA)\nn = 0.01      # Population growth rate\n\n# Steady-state capital per capita\nk_star = (alpha / (rho + delta)) ** (1 / (1 - alpha))\n# Steady-state consumption per capita\nc_star = k_star ** alpha - (n + delta) * k_star\n\nprint(f\"Steady-state capital per capita (k*): {k_star:.4f}\")\nprint(f\"Steady-state consumption per capita (c*): {c_star:.4f}\")\n\n# Initial capital per capita (start below steady state)\nk0 = 0.5 * k_star\n\n# Time span for the simulation\nt_span = [0, 100]  # From t=0 to t=100\nt_eval = np.linspace(t_span[0], t_span[1], 1000)  # Time points for evaluation\n\n# Differential equations of the Ramsey model\ndef ramsey(t, y):\n    k, c = y\n    dkdt = k ** alpha - c - (n + delta) * k\n    dcdt = (1 / theta) * (alpha * k ** (alpha - 1) - rho - delta) * c\n    return [dkdt, dcdt]\n\n# Shooting method to find the optimal initial consumption c0\ndef shooting_function(c0):\n    y0 = [k0, c0]\n    sol = solve_ivp(ramsey, t_span, y0, t_eval=t_eval, method='RK45')\n    k_T = sol.y[0, -1]\n    return k_T - k_star  # We want k(T) to be close to k_star\n\n# Initial guesses for c0\nc0_lower = 0.1 * c_star\nc0_upper = 2.0 * c_star\n\n# Use root_scalar to find the root of the shooting function\nres = root_scalar(shooting_function, bracket=[c0_lower, c0_upper], method='brentq')\nif res.converged:\n    c0 = res.root\n    print(f\"Optimal initial consumption per capita (c0): {c0:.4f}\")\nelse:\n    raise ValueError(\"Root-finding did not converge to a solution.\")\n\n# Simulate the model with the optimal initial consumption\ny0 = [k0, c0]\nsol = solve_ivp(ramsey, t_span, y0, t_eval=t_eval, method='RK45')\nk = sol.y[0]\nc = sol.y[1]\nt = sol.t\n\n# Plotting the results\nplt.figure(figsize=(12, 5))\n\n# Plot for capital per capita over time\nplt.subplot(1, 2, 1)\nplt.plot(t, k, label='Capital per capita (k)')\nplt.axhline(y=k_star, color='r', linestyle='--', label='Steady-state k*')\nplt.xlabel('Time')\nplt.ylabel('Capital per capita (k)')\nplt.title('Capital per Capita Over Time')\nplt.legend()\n\n# Plot for consumption per capita over time\nplt.subplot(1, 2, 2)\nplt.plot(t, c, label='Consumption per capita (c)')\nplt.axhline(y=c_star, color='r', linestyle='--', label='Steady-state c*')\nplt.xlabel('Time')\nplt.ylabel('Consumption per capita (c)')\nplt.title('Consumption per Capita Over Time')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n        \n\n        Explanation:\n        \n            Parameters: The code uses standard parameter values commonly found in the literature.\n            Steady-State Calculation: It computes the steady-state values of capital and consumption per capita.\n            Differential Equations: The ramsey function defines the system of differential equations for capital accumulation and consumption growth.\n            Shooting Method: The shooting_function uses a shooting method to find the optimal initial consumption c0 that ensures convergence to the steady state.\n            Simulation: It simulates the model over the specified time span using solve_ivp.\n            Plotting: The results are plotted to show the paths of capital and consumption per capita over time.\n        \n\n        Output:\n        The code will display the steady-state values and the optimal initial consumption. It will then produce two plots showing how capital per capita and consumption per capita evolve over time, converging to their steady-state values.\n\n        Notes:\n        The shooting method is essential because the Ramsey model is saddle-path stable, meaning there is a unique consumption path that leads to the steady state from a given initial capital stock. If the root-finding does not converge, you may need to adjust the initial guesses for c0 or check the parameter values.\n\n        This code provides a complete solution to the Ramsey growth model using standard parameter values and should serve as a solid foundation for further analysis or extensions of the model.\n    \n\n\n    \n    \n        Analysis: The code is written elegantly and explained well. \n        \n            \n                \n                \n                    Figure 4: Solution to Ramsey model produced by o1\n                \n            \n        \n        [+] click to see figure \n    \n\n\n\n\n\nMeta recently published a paper on an approach called \"Thought Preference Optimization\" that demonstrates that the benefits of LLMs thinking can extend even further . Their method shows that optimizing thought generation before responding improves performance across a broad range of applications, from marketing and content creation to general knowledge tasks. It is likely that this approach will be implemented by future versions of Meta's open-source models.\n\n\n The Road to LLM Agents  -- A key strategic goal of frontier AI labs is to evolve LLMs into autonomous AI agents—systems that can maintain objectives across multiple exchanges, plan sequences of actions, and independently pursue specified goals . While current LLMs primarily react to immediate prompts, agents would proactively gather information, formulate plans, and take actions to accomplish tasks. The advances in reasoning capabilities described above represent a crucial step toward this goal, as autonomous agents require the ability to plan multi-step actions and revise strategies based on outcomes.\n\nTwo other key requirements for agency are already emerging: first, the ability to maintain coherent objectives over time through long-term memory and expanded context windows, as discussed earlier in this section; and second, the capability to interact with external tools and APIs to gather information and take actions in the world. The latter developments will be covered in the next subsection on access modes, particularly in the context of LLMs’ autonomous “computer use” capabilities, and in the ensuing subsection on LLM-powered search, which gives LLMs real-time internet access. As these components come together, we may see LLMs evolve from passive tools into more active research collaborators."
  },
  {
    "objectID": "subs/access.html",
    "href": "subs/access.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Several new access modes to frontier LLMs have emerged over the course of 2024—in addition to the traditional text-based interaction modes. The most notable are workspaces for interactive LLM collaboration, real-time voice assistants, and the emerging autonomous “computer use” capabilities of LLMs.\n\n\nEnabled by longer context windows and greater speeds, LLM providers have introduced innovative workspace environments in recent months that allow users to interactively collaborate with LLMs on content, as summarized in Table 3.\n\n    \n\n\n\n\n\n\n\nWorkspace\nKey Features\n\n\n\n\nAnthropic Claude Artifacts\n• Dedicated output window\n• Supports text, code, flowcharts, SVG graphics, websites, dashboards\n• Real-time refinement and modification\n• Sharing and remixing capabilities\n\n\nChatGPT Canvas\n• Separate collaboration window\n• Text editing and coding capabilities\n• Options for edits, length adjustment, reading level changes\n• Code review and porting features\n\n\nOpenAI Advanced Data Analysis\n• Data upload and analysis\n• Visualization capabilities\n• Python code execution in backend\n• Error correction and refinement\n\n\nClaude Analysis Tool\n• Fast exploratory data analysis\n• Interactive visualizations with real-time adjustments\n\n\nGoogle NotebookLM\n• Document upload for research grounding\n• Quick summarization and questioning\n• Citation and quote provision\n• \"Deep dive conversation\" podcast generation\n\n\nMicrosoft Copilot\n• Integration with Microsoft 365 products\n• Assistance in Word, Excel, PowerPoint, etc.\n• Data analysis, formula construction\n\n\nGoogle Gemini for Workspace\n• Integration with Google's office suite\n• Assistance in Docs, Sheets, Slides, Gmail\n\n\nCursor AI Code Editor\n• AI-assisted coding\n• Code suggestions and queries\n• Optimization recommendations\n• Debugging assistance\n• Real-time collaboration\n\n\n\n\n\n\n\n    \n        \n            Table 3: Overview of interactive workspaces designed for LLM collaboration.  \n            Source: compiled by the author.  \n        \n    \n\n\n\n\n\nAnthropic led the way with the introduction of Artifacts for Claude in June 2024 (left panel in  Figure 4, followed by OpenAI's launch of Canvas for ChatGPT in October 2024 (right panel). Concurrently, developers of office package such as Microsoft and Google have increasingly integrated LLM capabilities into their existing workspaces. The resulting products allow users to move beyond the limitations of traditional chat interfaces and to interact with AI assistants in a more dynamic and collaborative environment for content creation, editing, and interaction. These features represent a significant leap forward in human-AI collaboration, providing dedicated spaces for users to credit, edit, and build upon AI-generated content in real-time. \n\n\n    \n        \n            \n                \n                Claude Artifact\n            \n            \n                \n                ChatGPT Canvas\n            \n        \n        \n            Figure 4: Anthropic's and OpenAI's workspaces for interactive LLM collaboration \n            Source: compiled by author.\n        \n    \n\n\nArtificacts in Claude can be activated by clicking at the user button at the bottom left and choosing “Settings”, which opens a menu that lets the user check the option “Enable artifacts”. When Claude finds it useful, or when the user explicitly asks for an artifact, the chatbot opens a dedicated output window to the right of the chat interface where the user can instantly view and interact with the generated content. This feature supported a range of different outputs, including text (as in  Figure 4,), code snippets, flowcharts, SVG graphics, websites, and interactive dashboards, which are all worth trying out. The user can interact with the artifact by asking the chatbot to refine or modify the output in line with her instructions, allowing for rapid prototyping and iteration. The feature also allows users to publish and share artifacts with other users who can subsequently remix them, enabling easy collaboration.\nCanvas in ChatGPT can be activated for paying users by selecting “GPT-4o with canvas” from the model selection menu at the top left of the screen. It is based on a similar concept as Claude Artifacts, opening in a separate window that allows users and ChatGPT to collaborate on writing and coding projects, but also offers some unique features that make it more powerful. The interface allows users to edit the content in the canvas like in a text editor or to select specific paragraphs and provide instructions on how to change the text or ask questions about it. Moreover, for text, the button at the bottom right of the canvas (Figure 4) includes options to ask the LLM for suggested edits, to adjust the length of the content (shorter or longer) and the reading level (from kindergarten to graduate level), or to add a “final polish” For code, the button includes options to review and comment on the code, to port it to a different language, to fix bugs, and to add comments or logs—all while keeping the entire content in mind.\nAdvanced Data Analysis in ChatGPT has been available in a rudimentary form since mid-2023 (originally named “Code Interpreter”; see later examples with  simulating the Solow model  and  plotting stock prices ) but has been significantly improved after the release of GPT-4o in 2024, turning it into a collaborative workspace where the main focus is on interacting with the data. It allows users to upload data in a variety of formats, for example, spreadsheets, and analyze, visualize and process the data in a multitude of ways. On the backend, ChatGPT writes and executes python code to perform the necessary operations, implying that a wide range of analyses can be performed, limited only by the “intelligence” of the LLM that is writing the code. Simple routine tasks are usually no problem. For more complicated forms of analysis, Advanced Data Analysis may make errors but is frequently able to correct them automatically in response to python error messages or the user’s requests.\nClaude Analysis Tool is Anthropic’s response to ChatGPT’s Advanced Data Analysis, using JavaScript rather than python as its underlying engine. Released in October 2024, it allows Claude to visualize and explore data in an elegant, intuitive, and interactive manner. This makes the tool most valuable for quick data explorations and visualizations. For example, I created Figure 1 using the Claude Analysis tool. However, it is less suitable for specialized econometric analysis than ChatGPT’s data analysis as it lacks the wide range of python libraries offering econometric tools.\nNotebookLM by Google represents a more specialized approach to AI-assisted research, facilitating background research and literature reviews, leveraging the long context window of Google’s Gemini models. Its key feature is to allow users to upload a wide range of relevant research papers or documents that ground the system AI in a specific corner of the literature and enables them to quickly summarize uploaded documents, ask targeted questions about the content, and brainstorm on the materials provided. Importantly for academic work, NotebookLM provides citations and relevant quotes from original sources during exchanges, supporting the rigorous documentation required in research.\nIn September 2024, NotebookLM introduced a groundbreaking feature called Deep dive conversation, which allows users to generate podcasts based on the provided materials. These podcasts feature an insightful conversation between two virtual agents who explain the essence of the material in simple and clear terms for non-experts, narrated in a highly engaging manner. For research use, this is one of the most impressive capabilities that have emerged in recent months. It offers a novel way to disseminate complex economic research to a broader audience, potentially increasing the impact and accessibility of economic studies. The tool is available for free at notebook.google.com.\n\nBelow is the beginning of a sample podcast generated based on uploading\nthe original version of this research paper \n\n\n\n    \n    \n        Prompt: Generate deep dive conversation. [Attachment: w30957.pdf] \n  \n    \n\n    \n\n    \n    Response (NotebookLM):\n    [+] click to expand\n    \n        Male host: Okay, so you're interested in the economics of AI...\n        Female host: Yeah.\n        Male host: ...specifically, all the buzz about these large language models, LLMs.\n        Female host: mmhmm\n        Male host: You're in the right place, because we're doing a deep dive into how these things actually work, what they could do for economists like you right now, and what the future might hold.\n        Female host: And it's a future that's changing rapidly. It seems like every day there's some new breakthrough in what these models can do.\n        Male host: Well, let's unpack that a bit.\n        Female host: mhm\n        Male host: Imagine having a research assistant who can not only brew you a perfect cup of coffee, but also write code in multiple languages, ...\n        Female host: Yeah.\n        Male host: ...summarize dense academic papers in seconds, and even brainstorm potential downsides to your economic model. That's the promise of LLMs, right?\n        Female host: Yep.\n        Male host: But how do they actually work? Is it really some kind of artificial intelligence magic?\n        Female host: It's not magic, but it's pretty close. Think of LLMs as incredibly complex neural networks, but instead of crunching numbers, they're trained on massive data sets of text. We're talking about everything from academic journals and books to code repositories and even social media posts—they process all of that information, learning patterns, relationships between concepts, and even different writing styles...\n        [Remainder omitted for space reasons.]\n\n        Transcription: Using Otter.ai. Full audio version available at  \n            https://t.ly/GrC0d.\n        \n    \n\n\n    \n    \n        Analysis: The generated podcast lays out the material in the paper in an engaging conversational format while covering the content in a clear and insightful manner targeted at laypeople. One interesting observation is that the male host mistakenly attributes physical capabilities to an AI research assistant (\"...who can not only brew you a perfect cup of coffee...\")\n    \n\nSince October 2024, NotebookLM allows users to customize the generated podcasts with specific instructions. For researchers, a useful prompt may look like this: “Your audience are PhD economists who are eager to learn how to effectively use LLMs in their research work”.\nWhereas the workspace tools described so far are based on the strategy of creating a new interface from scratch, like Artifacts or Canvas, in order to facilitate interactions with LLMs, the following tools follow the opposite strategy—they incorporate LLMs or similar systems to automatically perform functions in existing workspaces. Given the wide user base of the associated products, this integration will likely lead to widespread distribution of the benefits of these tools:\nCopilot in Microsoft 365 integrates LLM capabilities into Microsoft Office products for an add-on subscription fee of $20/month. Copilot is based on OpenAI’s latest GPT-4o model (and o1 in a pilot) as well as Microsoft-internal LLMs and can serve as an assistant and tutor for a wide range of office tasks. Use cases in Microsoft Word include creating drafts, including by brainstorming or referencing existing files; transforming text according to criteria like length, tone, formality, or intended reader; and summarizing and asking questions about content. In Microsoft Excel, use cases including extracting, converting, or reformatting data (use cases in data analysis); constructing, editing, and explaining formulas, even complicated ones; creating tables and charts to analyze and visualize data. Use cases in Microsoft PowerPoint include brainstorming, outlining and creating slides; enhancing content with images, design elements, and interactivity; summarizing and organizing presentations to highlight key points and action items; and even anticipating the most likely audience questions. Copilot is also available for all other programs that are part of the Microsoft 365 package, including Outlook, Teams, OneNote, as well as for Microsoft Edge.\nGemini for Google Workspace uses Google DeepMind’s Gemini series to offer a set of similar capabilities for Google’s office suite, including in Google Docs for writing documents, Google Spreadsheets, and Google Slides for presentations, as well as in the Gmail service.\n\n Cursor -- The AI Code Editor  is a tool that is specialized in AI-assisted coding, making it particularly relevant for researchers engaged in computational work, data analysis, and econometric modeling. Cursor takes advantage of the long context windows and greater speeds of the latest LLMs to take the code suggestions pioneered by Github Copilot to new heights. It integrates AI assistance into all aspects of the coding process, including code suggestions, queries about code, edits to selected code according to instructions, recommendations for code optimization, and help for debugging---all while keeping the entire code base of a project in its context window to recognize interdependencies. It also offers support real-time collaboration, facilitating teamwork on large-scale projects. Cursor is built on (or, more specifically, forked from) the popular VS Code environment and can employ multiple different LLMs, including GPT-4o, o1, and Claude 3.5 Sonnet.  report that GitHub Copilot delivered productivity gains of 126% for coding back in 2023. Based on user reports, the gains from Cursor may be even larger.\n\nIn a similar vein, the LaTeX editor Overleaf offers a tool called Writefull that is specialized in producing and editing LaTeX code, including tables and equations.\nAdditional Tools for Providing LLMs with Content – One of the challenges in using the current generation of frontier LLMs is that they are excellent at processing content, but it is difficult or time-intensive for the user to supply the most relevant context for a work task. Anthropic and OpenAI have developed two slightly different solutions to this problem:\n\nAnthropic introduced  Projects for Claude  in June 2024, which allow users to upload background documents that are relevant for multiple chat interactions and to organize and bring together related chats and artifacts in one place. For example, I have created a project on \"Generative AI for Economic Research\", to which I added the earlier versions of this paper  and the project-specific custom instructions \"Help me draft content for my research project on 'Generative AI for Economic Research' in a similar style to the earlier versions and in a format that is helpful for economic researchers\". When I use Claude to work on content related to this paper, I start a new chat that is part of this project, automatically providing Claude with all the relevant content. Projects help ground the LLM's outputs in relevant context and background knowledge to effectively mitigate the \"cold start\" \"problem when opening a new chat. They can also be shared across teams, enabling more collaborative workflows.\n\nOpenAI allows users to create Custom GPTs that enhance GPT-4o’s functionality by adding specialized background knowledge, interactive tools, and customized instructions tailored to specific instructions, ranging from writing to economic analysis tools. Users can also create their own custom GPTs by clicking “Explore GPTs” at the top left and the “Create” button, and going through the ensuing process step by step. The resulting custom GPTs can be used privately or shared publicly in a GPT Store. Custom GPTs created by others can also be located in the “Explore GPTs” menu at the top left, which offers users the ability to browse, install, and use a wide range of extensions and applications that are developed by third-party creators. Two custom GPTs that economists may find useful are (1) Wolfram, which provides access to computation, math, curated knowledge and real-time data from Wolfram Alpha, the maker of Mathematica, and (2) Consensus, which offers an AI-based research assistant that searches 200m academic papers to provide science-based answers with citations to the underlying articles.\n\n\n\nA significant innovation in access modes is a new generation of real-time voice assistants. Earlier voice assistants transcribed a user’s spoken language into text that was fed into an LLM; after processing the request, the LLM’s response was translated into audio again. By contrast, the new generation natively processes spoken text with all its nuances in tone and emotional expression and responds accordingly. Moreover, it also allows users to jump in and interrupt the flow mid-sentence in a way that allows for a more natural and fluid conversation. Some users report that they keep the ChatGPT app open on their phone in voice mode throughout certain work tasks, or even throughout the day, so that they can easily draw on the their digital assistant at any point without raising a finger.\nThe following are the leading interactive voice assistants of this new generation:\n\n\n    \n        OpenAI's Advanced Voice Mode is a feature of its ChatGPT mobile app that offers perhaps the most natural interaction, using the GPT-4o  \n        \n            At the time of writing, Advanced Voice Mode is not yet available to ChatGPT Plus or Free users in the European Union.\n         \n        In a version that is not yet publicly released, the model can also use the mobile phone's camera to include a video view of the user or their surroundings in its interactions. A desktop app to use Advanced Voice Mode that can see and respond to the information on a user's desktop is also in the works.\n    \n    \n    \n        Google's Gemini Live also allows for fluid voice conversations with users based on the Gemini series of models. Google is working on integrating Gemini Live with apps across the Google ecosystem, including Gmail, Calendar, Docs, YouTube, and Maps, to turn it into a powerful productivity assistant. \n        Moreover, it is also working on a \"Project Astra\" (Advanced Seeing and Talking Responsive Agent) that will incorporate vision features in Gemini Live.\n    \n\n    \n        Apple Intelligence voice assistant is part of the latest round of operating system updates across all Apple devices. It introduces an assistant that integrates seamlessly with Apple's ecosystem, handling general queries, managing tasks, and interacting fluidly across apps like Mail, Calendar, and Notes. \n        For more complex or nuanced inquiries, Apple Intelligence selectively leverages ChatGPT, adding depth to its responses when necessary. Although Apple's proprietary AI system provides a smooth, integrated experience, some users report that it lacks the advanced capabilities of standalone ChatGPT, particularly in handling complex, multi-layered questions.\n    \n\n    \n        Standard Intelligence's Hertz-dev is an open-source voice assistant solution, accessible at \n        https://si.inc/hertz-dev/. \n        Their models provide a versatile, real-time voice assistant that facilitates natural spoken interactions with LLMs. \n        Its efficient compression and ultra-low latency make it ideal for real-time applications, while its audio generation capabilities enable nuanced, responsive conversations. \n        As an open-source platform, Hertz-dev offers high customizability, allowing researchers to tailor it to their specific needs, such as automated interviews or integration with other research tools for a seamless, interactive experience.\n    \n\n\nTo combine voice interactions and traditional text-based interactions, both OpenAI’s and Google’s models provide users with transcripts of their voice interactions which can be copied and pasted for further processing and for written research products.\n\n\n\nThe perhaps most breathtaking recent advance has been an autonomous desktop assistant, simply labeled “Computer use,” which was released by Anthropic in beta mode in October 2024. The system enables Anthropic’s most cutting-edge model, Claude 3.5 Sonnet, to directly interact with your computer’s interface, allowing it to see your computer screen and giving it access to virtually any software application that can be installed on a computer.\nThis implies that the model can control your cursor, click buttons, type into text fields, and even navigate through software interfaces—as if another intelligent being were sitting at your computer. Although still preliminary, Computer Use gives LLMs the ability to automate a wide range of tasks that require multiple applications or complex workflows on a computer, ranging from organizing files and updating software to conducting online research. In effect, this development gives LLMs nearly unlimited access to external tools, enabling them to seamlessly interact across platforms and applications without manual intervention. Anthropic’s Claude with “Computer use” can currently be accessed through Anthropic’s API, which enables users to programmatically direct Claude to perform any desired operations on a computer. An instructive demo video is available at https://www.youtube.com/watch?v=ODaHJzOyVCQ.\nGoogle's Project JARVIS (acronym for \"Just A Rather Very Intelligent System,\" which is inspired by the AI assistant in the Iron Man franchise) is an experimental AI assistant that operates within Google's Chrome browser environment, where it can perform web-based tasks such as filling out forms, navigating websites, and making online purchases. Currently, Jarvis is in the experimental phase and expected to be available more broadly in December 2024. Its functions are limited to browser-based tasks, unlike Anthropic's Claude, which can interact with any software installed on a computer. This makes Jarvis highly useful for automating tasks online but less versatile for complex workflows that require access to local applications.\n\nFor researchers, autonomous desktop assistants offer significant potential. They can automate standard research workflows, such as organizing datasets, managing references, and conducting data analyses in econometric packages. Additionally, for bulk operations like systematically collecting information from multiple sources, running batch simulations, or automating data entry, an LLM with desktop control can handle repetitive tasks with ease and efficiency. However, these capabilities also introduce risks, including grave security risks and privacy concerns, as such systems obtain full control over the user's device or \n    For example, Anthropic notes that Claude with computer use sometimes erroneously follows instructions that it happens to read on open webpages or in images, thereby overriding the instructions that it has been given by its user. \n    For this reason, they recommend that computer use is run on a dedicated virtual machine or container with minimal access privileges to prevent system attacks or accidents.\n Researchers must weigh these risks carefully, ensuring that sensitive data and systems are protected when taking advantage of the automation benefits these tools can offer.\n\n\n\n\nThere are also a growing number of dedicated research tools that are based on LLMs and facilitate or automate research tasks. I will highlight two:\n\n develop an open-source Python package to facilitate research on LLM-based simulations and surveys. In a dig at the term \"stochastic parrot,\" which was used to critique LLMs, they have developed Expected Parrot Domain-Specific Language (EDSL), which takes advantage of LLMs' ability to generate a wide range of context-specific data that closely mirror human behavior and social dynamics. \n\nEDSL allows researchers to define a set of Questions that are answered by AI Agents simulated by defined Models to produce a set of Results, which can be grouped into Surveys and contextualized with Scenarios (capitalization used to refer to specific objects in EDSL).\n\nThis approach enables economists to efficiently manage large-scale tasks with intricate dependencies, agent behaviors, and model parameters without getting bogged down in programming details. As a result, EDSL offers a powerful toolkit to conduct LLM-based simulations of detailed surveys and experiments, label large datasets, augment existing data, and generate synthetic data. \n\nResearchers can design AI agents with specific traits, utilize multiple language models simultaneously, and incorporate complex logic and agent memory into their surveys. EDSL's built-in analysis and visualization tools, integrated into the Python ecosystem, allow for both seamless execution and interpretation of research outcomes.\n\n\n\n at the Japanese startup sakana.ai introduce an automated framework for end-to-end scientific paper generation in computer science based on LLMs. The AI Scientist, as they call it, is designed to autonomously generate research ideas, implement experiments by running code, analyze results, and produce complete academic papers. While currently limited to a specific area within computer science in which progress can be made simply by writing code (machine learning algorithms and architectures), this approach demonstrates the potential for LLMs to assist across the research process.\n\nThe AI Scientist operates by generating novel research ideas, writing code to implement experiments, executing those experiments, and then drafting a full scientific paper based on the results. The system incorporates an automated reviewing process to evaluate the generated papers, mimicking the peer review system in academic publishing. Sample papers are available at https://sakana.ai/ai-scientist/.\nAlthough the current quality of the generated papers is mediocre, lacking the full originality, depth and rigor of research authored by human experts, the framework points towards the potential future capabilities of LLMs in scientific research. It serves as a proof of concept for how LLMs could be leveraged to augment and accelerate the scientific process in the future. As LLM capabilities continue to advance, especially as they make breakthroughs in reasoning (see the reasoning page), systems like the AI Scientist may evolve into powerful tools for idea generation and the execution of research even in fields like economics.\n\n\n\nThe following summarizes the more traditional access modes for LLMs that have been available for the past two years:\n\n    \n        Web-based Chatbots: The models in See Summary Table\n are all accessible as chatbots under the URLs listed in the last column. \n        The chatbot interface, pioneered by Anthropic but first publicly released by OpenAI in the form of ChatGPT in Nov. 2022, allows users to prompt LLMs as assistants or tutors. \n        Most of the examples documented in the use cases below illustrate this mode of interaction, which has been the most popular way of accessing LLMs over the past two years. \n        However, I anticipate that LLM use will gradually shift towards the interactive workspaces described in the access model page. The free versions of the listed chatbots typically come with usage restrictions or provide access to less powerful model versions. \n        In my experience, this makes it worthwhile to pay the $20 monthly subscription fee that is typically required for full access to the frontier models listed in the table. All of these chatbots are also available via apps on Apple and Android mobile phones. \n        Moreover, OpenAI and Anthropic have also developed desktop apps for their chatbots that are available for download at \n        https://openai.com/chatgpt/download/ \n        and https://claude.ai/download respectively, \n        and, once installed, can be conveniently accessed via the keyboard shortcuts Ctrl+Space and Ctrl+Alt+Space.\n    \n    \n    \n        Web-based Experimentation Platforms: All major LLM providers also offer web-based interfaces that offer greater functionality and flexibility than chatbots but do not require programming knowledge.\n        These platforms, such as \n        OpenAI Playground, \n        Google AI Studio, and \n        Anthropic Console, \n        allow users to experiment with different model settings, like temperature and top-p sampling, and provide more control over the input and output formats compared to chatbots. \n        Such experimentation platforms are particularly useful for exploring the capabilities of LLMs, testing prompts, and fine-tuning models for specific tasks.\n    \n\n    \n        Application Programming Interfaces (APIs): For the maximum level of customization and integration, the listed models are also accessible through APIs, \n        which allow programmers to integrate LLMs directly into their own software applications. \n        This enables a wide range of more advanced and customized use cases, such as automating repetitive tasks or analyzing large datasets using natural language processing techniques. \n        APIs provide more flexibility and control compared to the above two options and can be employed on a pay-per-use basis, \n        but they also require a higher level of technical expertise to use effectively. \n        \n        Accessing LLMs through APIs typically involves signing up for an API key from the model provider \n        (which can be thought of as a credit card for LLM tokens), installing a client library in the programming language of choice, \n        and writing code to interact with the API endpoints. \n        \n        While this process may be more complex than using a chatbot, it unlocks the full potential of LLMs for those with the necessary programming skills. \n        The replication package for this paper demonstrates how to use APIs to automatically query LLMs.\n    \n\n    \n        Locally Operating LLMs: Open-source models allow researchers to run LLMs on their own computers, \n        offering advantages such as data privacy, cost-effectiveness, customization, and offline accessibility.\n        The computational resource requirements imply that only small models can be executed at a reasonable speed on desktop computers. \n        However, advances in computational capacity as well as rapid efficiency gains of LLMs that allow greater capabilities of smaller models \n        are rapidly making the local use of LLMs more attractive. Two solutions that make it particularly easy to deploy LLMs locally are:\n        \n        \n            \n                LM Studio \n                allows users to download and run a range of open-source LLMs, including VLMs, on their personal computer or server.\n            \n            \n                llamafile \n                makes it possible to download LLMs in a single file and run them on a wide range of computer systems.\n            \n        \n    \n\n\nCentralized Hubs for LLM Interaction and Experimentation– A useful website with a user-friendly chat interface that offers access to all leading LLMs is\nhttps://poe.com.\nSimilarly, a website that offers users a web-based experimentation platform with access to a wide range of different models is\nhttps://nat.dev/.\nPrompting Guides for Text-based Access – Although it is useful for everyone to gain experience interacting with LLMs through their own experimentation and learning-by-doing, most leading model providers now also offer public documents that describes strategies for how to prompt LLMs. The following is a list of such guides:\n\n    \n        \n            https://platform.openai.com/docs/guides/prompt-engineering\n        \n    \n    \n        \n            https://ai.google.dev/gemini-api/docs/prompting-intro\n         \n        and an example of a research assistant at \n        \n            https://aistudio.google.com/app/prompts/research-assistant\n        \n    \n    \n        \n            https://docs.anthropic.com/claude/docs/intro-to-prompting\n         \n        and an associated prompt library at \n        \n            https://docs.anthropic.com/en/prompt-library/library\n        \n    \n    \n        \n            https://llama.meta.com/get-started/#prompting\n        \n    \n\n\n\n    Anthropic also offers a \"prompt generator\" that helps users to optimize the prompts that they employ for querying LLMs through the \n    Anthropic Console Dashboard \n    (click \"Generate a Prompt\"). This tool converts basic instructions in written language describing a user's intent into a more complex \n    and specific set of instructions that induce LLMs to generate higher-quality output. Naturally, the user can edit and adjust the \n    generated instructions before use to ensure that they capture their intent as well as possible.\n\n\n\n    I illustrate this using the following example. Throughout the remainder of this section, I will present all examples generated by \n    LLMs in boxes, with the prompt in the header and the LLM's generated response in the body of the box.\n\n\n\n    \n    \n        Prompt (Anthropic Prompt Generator): I have written an economics paper and would like to create a draft of a blog for Brookings.\n    \n\n    \n\n    \n    Response:\n    [+] click to expand\n    \n        Your task is to help draft a blog post for the Brookings Institution based on an economics research paper. Here is the full text of the paper:\n\n        &lt;paper&gt;\n{{PAPER}}\n&lt;/paper&gt;\n        \n\n        The target audience for this blog post is:\n\n        &lt;audience&gt;\n{{AUDIENCE}}\n&lt;/audience&gt;\n        \n\n        First, carefully read through the entire paper, taking notes on the key points, main findings, and implications in a &lt;scratchpad&gt; section.\n\n        Next, write a short outline for the blog post in a &lt;outline&gt; section.\n           Keep the target audience in mind as you decide what to focus on and how to present the information.\n\n        Then, using your outline as a guide, write out the full draft of the blog post in a &lt;blog_post_draft&gt; section. Remember to:\n\n        \n            Use clear, engaging language that will be easily understood by the target audience.\n            Incorporate relevant examples, anecdotes, or analogies where appropriate to make the post more relatable and interesting.\n            Avoid copying word-for-word from the original paper. Put the key concepts into your own words.\n            Focus on the implications and \"so what\" of the research rather than getting too in-the-weeds with technical details.\n        \n\n        After you finish the draft, review it to make sure it covers the most important and interesting points from the paper in a way that will resonate with the target Brookings audience. Make any final tweaks before submitting your draft.\n    \n\n\n    \n    \n        Analysis: The generated prompt provides a remarkable level of detail that employs several cutting-edge prompting techniques to obtain the best possible results.\n        \n            It asks the model to start by taking notes in a \"scratchpad\" section, which induces the model to synthesize the main lessons of the text. Then it asks the model to prepare an outline, which induces the model to generate a plan. Only after these steps does the prompt ask the model to write a draft of the text. \n\n            The prompt also leaves two locations for users to insert the paper in question and to define the audience. I simply substituted these by writing \"The full text of the paper is attached\" and inserting \"policymakers\" as the target audience. \n\n            The prompt generated useful results on all three of the leading LLMs that would save considerable time in such a project, although the generated blog post was not quite up to the depth and quality of a think tank like Brookings.\n            \n                I asked Anthropic Prompt Generator to create prompts for blog posts for several different outlets. For some reason, asking for a blog targeted at Brookings gave rise to a higher-quality prompt than asking for any other outlet I attempted. My best explanation is that the model internalizes that Brookings is known for its high-quality analysis. (Disclaimer: The author is a non-resident fellow at Brookings.)\n            \n        \n        [+]\n    \n\n systematically study 26 different guiding principles for prompting leading LLMs and offer prompting advice based on a systematic evaluation of their effectiveness. Curiously, they find that strategies such as (fictitiously) offering LLMs a tip or threatening a penalty improve performance."
  },
  {
    "objectID": "subs/access.html#workspaces-for-interactive-llm-collaboration",
    "href": "subs/access.html#workspaces-for-interactive-llm-collaboration",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Enabled by longer context windows and greater speeds, LLM providers have introduced innovative workspace environments in recent months that allow users to interactively collaborate with LLMs on content, as summarized in Table 3.\n\n    \n\n\n\n\n\n\n\nWorkspace\nKey Features\n\n\n\n\nAnthropic Claude Artifacts\n• Dedicated output window\n• Supports text, code, flowcharts, SVG graphics, websites, dashboards\n• Real-time refinement and modification\n• Sharing and remixing capabilities\n\n\nChatGPT Canvas\n• Separate collaboration window\n• Text editing and coding capabilities\n• Options for edits, length adjustment, reading level changes\n• Code review and porting features\n\n\nOpenAI Advanced Data Analysis\n• Data upload and analysis\n• Visualization capabilities\n• Python code execution in backend\n• Error correction and refinement\n\n\nClaude Analysis Tool\n• Fast exploratory data analysis\n• Interactive visualizations with real-time adjustments\n\n\nGoogle NotebookLM\n• Document upload for research grounding\n• Quick summarization and questioning\n• Citation and quote provision\n• \"Deep dive conversation\" podcast generation\n\n\nMicrosoft Copilot\n• Integration with Microsoft 365 products\n• Assistance in Word, Excel, PowerPoint, etc.\n• Data analysis, formula construction\n\n\nGoogle Gemini for Workspace\n• Integration with Google's office suite\n• Assistance in Docs, Sheets, Slides, Gmail\n\n\nCursor AI Code Editor\n• AI-assisted coding\n• Code suggestions and queries\n• Optimization recommendations\n• Debugging assistance\n• Real-time collaboration\n\n\n\n\n\n\n\n    \n        \n            Table 3: Overview of interactive workspaces designed for LLM collaboration.  \n            Source: compiled by the author.  \n        \n    \n\n\n\n\n\nAnthropic led the way with the introduction of Artifacts for Claude in June 2024 (left panel in  Figure 4, followed by OpenAI's launch of Canvas for ChatGPT in October 2024 (right panel). Concurrently, developers of office package such as Microsoft and Google have increasingly integrated LLM capabilities into their existing workspaces. The resulting products allow users to move beyond the limitations of traditional chat interfaces and to interact with AI assistants in a more dynamic and collaborative environment for content creation, editing, and interaction. These features represent a significant leap forward in human-AI collaboration, providing dedicated spaces for users to credit, edit, and build upon AI-generated content in real-time. \n\n\n    \n        \n            \n                \n                Claude Artifact\n            \n            \n                \n                ChatGPT Canvas\n            \n        \n        \n            Figure 4: Anthropic's and OpenAI's workspaces for interactive LLM collaboration \n            Source: compiled by author.\n        \n    \n\n\nArtificacts in Claude can be activated by clicking at the user button at the bottom left and choosing “Settings”, which opens a menu that lets the user check the option “Enable artifacts”. When Claude finds it useful, or when the user explicitly asks for an artifact, the chatbot opens a dedicated output window to the right of the chat interface where the user can instantly view and interact with the generated content. This feature supported a range of different outputs, including text (as in  Figure 4,), code snippets, flowcharts, SVG graphics, websites, and interactive dashboards, which are all worth trying out. The user can interact with the artifact by asking the chatbot to refine or modify the output in line with her instructions, allowing for rapid prototyping and iteration. The feature also allows users to publish and share artifacts with other users who can subsequently remix them, enabling easy collaboration.\nCanvas in ChatGPT can be activated for paying users by selecting “GPT-4o with canvas” from the model selection menu at the top left of the screen. It is based on a similar concept as Claude Artifacts, opening in a separate window that allows users and ChatGPT to collaborate on writing and coding projects, but also offers some unique features that make it more powerful. The interface allows users to edit the content in the canvas like in a text editor or to select specific paragraphs and provide instructions on how to change the text or ask questions about it. Moreover, for text, the button at the bottom right of the canvas (Figure 4) includes options to ask the LLM for suggested edits, to adjust the length of the content (shorter or longer) and the reading level (from kindergarten to graduate level), or to add a “final polish” For code, the button includes options to review and comment on the code, to port it to a different language, to fix bugs, and to add comments or logs—all while keeping the entire content in mind.\nAdvanced Data Analysis in ChatGPT has been available in a rudimentary form since mid-2023 (originally named “Code Interpreter”; see later examples with  simulating the Solow model  and  plotting stock prices ) but has been significantly improved after the release of GPT-4o in 2024, turning it into a collaborative workspace where the main focus is on interacting with the data. It allows users to upload data in a variety of formats, for example, spreadsheets, and analyze, visualize and process the data in a multitude of ways. On the backend, ChatGPT writes and executes python code to perform the necessary operations, implying that a wide range of analyses can be performed, limited only by the “intelligence” of the LLM that is writing the code. Simple routine tasks are usually no problem. For more complicated forms of analysis, Advanced Data Analysis may make errors but is frequently able to correct them automatically in response to python error messages or the user’s requests.\nClaude Analysis Tool is Anthropic’s response to ChatGPT’s Advanced Data Analysis, using JavaScript rather than python as its underlying engine. Released in October 2024, it allows Claude to visualize and explore data in an elegant, intuitive, and interactive manner. This makes the tool most valuable for quick data explorations and visualizations. For example, I created Figure 1 using the Claude Analysis tool. However, it is less suitable for specialized econometric analysis than ChatGPT’s data analysis as it lacks the wide range of python libraries offering econometric tools.\nNotebookLM by Google represents a more specialized approach to AI-assisted research, facilitating background research and literature reviews, leveraging the long context window of Google’s Gemini models. Its key feature is to allow users to upload a wide range of relevant research papers or documents that ground the system AI in a specific corner of the literature and enables them to quickly summarize uploaded documents, ask targeted questions about the content, and brainstorm on the materials provided. Importantly for academic work, NotebookLM provides citations and relevant quotes from original sources during exchanges, supporting the rigorous documentation required in research.\nIn September 2024, NotebookLM introduced a groundbreaking feature called Deep dive conversation, which allows users to generate podcasts based on the provided materials. These podcasts feature an insightful conversation between two virtual agents who explain the essence of the material in simple and clear terms for non-experts, narrated in a highly engaging manner. For research use, this is one of the most impressive capabilities that have emerged in recent months. It offers a novel way to disseminate complex economic research to a broader audience, potentially increasing the impact and accessibility of economic studies. The tool is available for free at notebook.google.com.\n\nBelow is the beginning of a sample podcast generated based on uploading\nthe original version of this research paper \n\n\n\n    \n    \n        Prompt: Generate deep dive conversation. [Attachment: w30957.pdf] \n  \n    \n\n    \n\n    \n    Response (NotebookLM):\n    [+] click to expand\n    \n        Male host: Okay, so you're interested in the economics of AI...\n        Female host: Yeah.\n        Male host: ...specifically, all the buzz about these large language models, LLMs.\n        Female host: mmhmm\n        Male host: You're in the right place, because we're doing a deep dive into how these things actually work, what they could do for economists like you right now, and what the future might hold.\n        Female host: And it's a future that's changing rapidly. It seems like every day there's some new breakthrough in what these models can do.\n        Male host: Well, let's unpack that a bit.\n        Female host: mhm\n        Male host: Imagine having a research assistant who can not only brew you a perfect cup of coffee, but also write code in multiple languages, ...\n        Female host: Yeah.\n        Male host: ...summarize dense academic papers in seconds, and even brainstorm potential downsides to your economic model. That's the promise of LLMs, right?\n        Female host: Yep.\n        Male host: But how do they actually work? Is it really some kind of artificial intelligence magic?\n        Female host: It's not magic, but it's pretty close. Think of LLMs as incredibly complex neural networks, but instead of crunching numbers, they're trained on massive data sets of text. We're talking about everything from academic journals and books to code repositories and even social media posts—they process all of that information, learning patterns, relationships between concepts, and even different writing styles...\n        [Remainder omitted for space reasons.]\n\n        Transcription: Using Otter.ai. Full audio version available at  \n            https://t.ly/GrC0d.\n        \n    \n\n\n    \n    \n        Analysis: The generated podcast lays out the material in the paper in an engaging conversational format while covering the content in a clear and insightful manner targeted at laypeople. One interesting observation is that the male host mistakenly attributes physical capabilities to an AI research assistant (\"...who can not only brew you a perfect cup of coffee...\")\n    \n\nSince October 2024, NotebookLM allows users to customize the generated podcasts with specific instructions. For researchers, a useful prompt may look like this: “Your audience are PhD economists who are eager to learn how to effectively use LLMs in their research work”.\nWhereas the workspace tools described so far are based on the strategy of creating a new interface from scratch, like Artifacts or Canvas, in order to facilitate interactions with LLMs, the following tools follow the opposite strategy—they incorporate LLMs or similar systems to automatically perform functions in existing workspaces. Given the wide user base of the associated products, this integration will likely lead to widespread distribution of the benefits of these tools:\nCopilot in Microsoft 365 integrates LLM capabilities into Microsoft Office products for an add-on subscription fee of $20/month. Copilot is based on OpenAI’s latest GPT-4o model (and o1 in a pilot) as well as Microsoft-internal LLMs and can serve as an assistant and tutor for a wide range of office tasks. Use cases in Microsoft Word include creating drafts, including by brainstorming or referencing existing files; transforming text according to criteria like length, tone, formality, or intended reader; and summarizing and asking questions about content. In Microsoft Excel, use cases including extracting, converting, or reformatting data (use cases in data analysis); constructing, editing, and explaining formulas, even complicated ones; creating tables and charts to analyze and visualize data. Use cases in Microsoft PowerPoint include brainstorming, outlining and creating slides; enhancing content with images, design elements, and interactivity; summarizing and organizing presentations to highlight key points and action items; and even anticipating the most likely audience questions. Copilot is also available for all other programs that are part of the Microsoft 365 package, including Outlook, Teams, OneNote, as well as for Microsoft Edge.\nGemini for Google Workspace uses Google DeepMind’s Gemini series to offer a set of similar capabilities for Google’s office suite, including in Google Docs for writing documents, Google Spreadsheets, and Google Slides for presentations, as well as in the Gmail service.\n\n Cursor -- The AI Code Editor  is a tool that is specialized in AI-assisted coding, making it particularly relevant for researchers engaged in computational work, data analysis, and econometric modeling. Cursor takes advantage of the long context windows and greater speeds of the latest LLMs to take the code suggestions pioneered by Github Copilot to new heights. It integrates AI assistance into all aspects of the coding process, including code suggestions, queries about code, edits to selected code according to instructions, recommendations for code optimization, and help for debugging---all while keeping the entire code base of a project in its context window to recognize interdependencies. It also offers support real-time collaboration, facilitating teamwork on large-scale projects. Cursor is built on (or, more specifically, forked from) the popular VS Code environment and can employ multiple different LLMs, including GPT-4o, o1, and Claude 3.5 Sonnet.  report that GitHub Copilot delivered productivity gains of 126% for coding back in 2023. Based on user reports, the gains from Cursor may be even larger.\n\nIn a similar vein, the LaTeX editor Overleaf offers a tool called Writefull that is specialized in producing and editing LaTeX code, including tables and equations.\nAdditional Tools for Providing LLMs with Content – One of the challenges in using the current generation of frontier LLMs is that they are excellent at processing content, but it is difficult or time-intensive for the user to supply the most relevant context for a work task. Anthropic and OpenAI have developed two slightly different solutions to this problem:\n\nAnthropic introduced  Projects for Claude  in June 2024, which allow users to upload background documents that are relevant for multiple chat interactions and to organize and bring together related chats and artifacts in one place. For example, I have created a project on \"Generative AI for Economic Research\", to which I added the earlier versions of this paper  and the project-specific custom instructions \"Help me draft content for my research project on 'Generative AI for Economic Research' in a similar style to the earlier versions and in a format that is helpful for economic researchers\". When I use Claude to work on content related to this paper, I start a new chat that is part of this project, automatically providing Claude with all the relevant content. Projects help ground the LLM's outputs in relevant context and background knowledge to effectively mitigate the \"cold start\" \"problem when opening a new chat. They can also be shared across teams, enabling more collaborative workflows.\n\nOpenAI allows users to create Custom GPTs that enhance GPT-4o’s functionality by adding specialized background knowledge, interactive tools, and customized instructions tailored to specific instructions, ranging from writing to economic analysis tools. Users can also create their own custom GPTs by clicking “Explore GPTs” at the top left and the “Create” button, and going through the ensuing process step by step. The resulting custom GPTs can be used privately or shared publicly in a GPT Store. Custom GPTs created by others can also be located in the “Explore GPTs” menu at the top left, which offers users the ability to browse, install, and use a wide range of extensions and applications that are developed by third-party creators. Two custom GPTs that economists may find useful are (1) Wolfram, which provides access to computation, math, curated knowledge and real-time data from Wolfram Alpha, the maker of Mathematica, and (2) Consensus, which offers an AI-based research assistant that searches 200m academic papers to provide science-based answers with citations to the underlying articles."
  },
  {
    "objectID": "subs/access.html#real-time-voice-assistants",
    "href": "subs/access.html#real-time-voice-assistants",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "A significant innovation in access modes is a new generation of real-time voice assistants. Earlier voice assistants transcribed a user’s spoken language into text that was fed into an LLM; after processing the request, the LLM’s response was translated into audio again. By contrast, the new generation natively processes spoken text with all its nuances in tone and emotional expression and responds accordingly. Moreover, it also allows users to jump in and interrupt the flow mid-sentence in a way that allows for a more natural and fluid conversation. Some users report that they keep the ChatGPT app open on their phone in voice mode throughout certain work tasks, or even throughout the day, so that they can easily draw on the their digital assistant at any point without raising a finger.\nThe following are the leading interactive voice assistants of this new generation:\n\n\n    \n        OpenAI's Advanced Voice Mode is a feature of its ChatGPT mobile app that offers perhaps the most natural interaction, using the GPT-4o  \n        \n            At the time of writing, Advanced Voice Mode is not yet available to ChatGPT Plus or Free users in the European Union.\n         \n        In a version that is not yet publicly released, the model can also use the mobile phone's camera to include a video view of the user or their surroundings in its interactions. A desktop app to use Advanced Voice Mode that can see and respond to the information on a user's desktop is also in the works.\n    \n    \n    \n        Google's Gemini Live also allows for fluid voice conversations with users based on the Gemini series of models. Google is working on integrating Gemini Live with apps across the Google ecosystem, including Gmail, Calendar, Docs, YouTube, and Maps, to turn it into a powerful productivity assistant. \n        Moreover, it is also working on a \"Project Astra\" (Advanced Seeing and Talking Responsive Agent) that will incorporate vision features in Gemini Live.\n    \n\n    \n        Apple Intelligence voice assistant is part of the latest round of operating system updates across all Apple devices. It introduces an assistant that integrates seamlessly with Apple's ecosystem, handling general queries, managing tasks, and interacting fluidly across apps like Mail, Calendar, and Notes. \n        For more complex or nuanced inquiries, Apple Intelligence selectively leverages ChatGPT, adding depth to its responses when necessary. Although Apple's proprietary AI system provides a smooth, integrated experience, some users report that it lacks the advanced capabilities of standalone ChatGPT, particularly in handling complex, multi-layered questions.\n    \n\n    \n        Standard Intelligence's Hertz-dev is an open-source voice assistant solution, accessible at \n        https://si.inc/hertz-dev/. \n        Their models provide a versatile, real-time voice assistant that facilitates natural spoken interactions with LLMs. \n        Its efficient compression and ultra-low latency make it ideal for real-time applications, while its audio generation capabilities enable nuanced, responsive conversations. \n        As an open-source platform, Hertz-dev offers high customizability, allowing researchers to tailor it to their specific needs, such as automated interviews or integration with other research tools for a seamless, interactive experience.\n    \n\n\nTo combine voice interactions and traditional text-based interactions, both OpenAI’s and Google’s models provide users with transcripts of their voice interactions which can be copied and pasted for further processing and for written research products."
  },
  {
    "objectID": "subs/access.html#autonomous-computer-use",
    "href": "subs/access.html#autonomous-computer-use",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "The perhaps most breathtaking recent advance has been an autonomous desktop assistant, simply labeled “Computer use,” which was released by Anthropic in beta mode in October 2024. The system enables Anthropic’s most cutting-edge model, Claude 3.5 Sonnet, to directly interact with your computer’s interface, allowing it to see your computer screen and giving it access to virtually any software application that can be installed on a computer.\nThis implies that the model can control your cursor, click buttons, type into text fields, and even navigate through software interfaces—as if another intelligent being were sitting at your computer. Although still preliminary, Computer Use gives LLMs the ability to automate a wide range of tasks that require multiple applications or complex workflows on a computer, ranging from organizing files and updating software to conducting online research. In effect, this development gives LLMs nearly unlimited access to external tools, enabling them to seamlessly interact across platforms and applications without manual intervention. Anthropic’s Claude with “Computer use” can currently be accessed through Anthropic’s API, which enables users to programmatically direct Claude to perform any desired operations on a computer. An instructive demo video is available at https://www.youtube.com/watch?v=ODaHJzOyVCQ.\nGoogle's Project JARVIS (acronym for \"Just A Rather Very Intelligent System,\" which is inspired by the AI assistant in the Iron Man franchise) is an experimental AI assistant that operates within Google's Chrome browser environment, where it can perform web-based tasks such as filling out forms, navigating websites, and making online purchases. Currently, Jarvis is in the experimental phase and expected to be available more broadly in December 2024. Its functions are limited to browser-based tasks, unlike Anthropic's Claude, which can interact with any software installed on a computer. This makes Jarvis highly useful for automating tasks online but less versatile for complex workflows that require access to local applications.\n\nFor researchers, autonomous desktop assistants offer significant potential. They can automate standard research workflows, such as organizing datasets, managing references, and conducting data analyses in econometric packages. Additionally, for bulk operations like systematically collecting information from multiple sources, running batch simulations, or automating data entry, an LLM with desktop control can handle repetitive tasks with ease and efficiency. However, these capabilities also introduce risks, including grave security risks and privacy concerns, as such systems obtain full control over the user's device or \n    For example, Anthropic notes that Claude with computer use sometimes erroneously follows instructions that it happens to read on open webpages or in images, thereby overriding the instructions that it has been given by its user. \n    For this reason, they recommend that computer use is run on a dedicated virtual machine or container with minimal access privileges to prevent system attacks or accidents.\n Researchers must weigh these risks carefully, ensuring that sensitive data and systems are protected when taking advantage of the automation benefits these tools can offer."
  },
  {
    "objectID": "subs/access.html#llm-based-research-tools",
    "href": "subs/access.html#llm-based-research-tools",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "There are also a growing number of dedicated research tools that are based on LLMs and facilitate or automate research tasks. I will highlight two:\n\n develop an open-source Python package to facilitate research on LLM-based simulations and surveys. In a dig at the term \"stochastic parrot,\" which was used to critique LLMs, they have developed Expected Parrot Domain-Specific Language (EDSL), which takes advantage of LLMs' ability to generate a wide range of context-specific data that closely mirror human behavior and social dynamics. \n\nEDSL allows researchers to define a set of Questions that are answered by AI Agents simulated by defined Models to produce a set of Results, which can be grouped into Surveys and contextualized with Scenarios (capitalization used to refer to specific objects in EDSL).\n\nThis approach enables economists to efficiently manage large-scale tasks with intricate dependencies, agent behaviors, and model parameters without getting bogged down in programming details. As a result, EDSL offers a powerful toolkit to conduct LLM-based simulations of detailed surveys and experiments, label large datasets, augment existing data, and generate synthetic data. \n\nResearchers can design AI agents with specific traits, utilize multiple language models simultaneously, and incorporate complex logic and agent memory into their surveys. EDSL's built-in analysis and visualization tools, integrated into the Python ecosystem, allow for both seamless execution and interpretation of research outcomes.\n\n\n\n at the Japanese startup sakana.ai introduce an automated framework for end-to-end scientific paper generation in computer science based on LLMs. The AI Scientist, as they call it, is designed to autonomously generate research ideas, implement experiments by running code, analyze results, and produce complete academic papers. While currently limited to a specific area within computer science in which progress can be made simply by writing code (machine learning algorithms and architectures), this approach demonstrates the potential for LLMs to assist across the research process.\n\nThe AI Scientist operates by generating novel research ideas, writing code to implement experiments, executing those experiments, and then drafting a full scientific paper based on the results. The system incorporates an automated reviewing process to evaluate the generated papers, mimicking the peer review system in academic publishing. Sample papers are available at https://sakana.ai/ai-scientist/.\nAlthough the current quality of the generated papers is mediocre, lacking the full originality, depth and rigor of research authored by human experts, the framework points towards the potential future capabilities of LLMs in scientific research. It serves as a proof of concept for how LLMs could be leveraged to augment and accelerate the scientific process in the future. As LLM capabilities continue to advance, especially as they make breakthroughs in reasoning (see the reasoning page), systems like the AI Scientist may evolve into powerful tools for idea generation and the execution of research even in fields like economics."
  },
  {
    "objectID": "subs/access.html#traditional-text-based-interaction",
    "href": "subs/access.html#traditional-text-based-interaction",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "The following summarizes the more traditional access modes for LLMs that have been available for the past two years:\n\n    \n        Web-based Chatbots: The models in See Summary Table\n are all accessible as chatbots under the URLs listed in the last column. \n        The chatbot interface, pioneered by Anthropic but first publicly released by OpenAI in the form of ChatGPT in Nov. 2022, allows users to prompt LLMs as assistants or tutors. \n        Most of the examples documented in the use cases below illustrate this mode of interaction, which has been the most popular way of accessing LLMs over the past two years. \n        However, I anticipate that LLM use will gradually shift towards the interactive workspaces described in the access model page. The free versions of the listed chatbots typically come with usage restrictions or provide access to less powerful model versions. \n        In my experience, this makes it worthwhile to pay the $20 monthly subscription fee that is typically required for full access to the frontier models listed in the table. All of these chatbots are also available via apps on Apple and Android mobile phones. \n        Moreover, OpenAI and Anthropic have also developed desktop apps for their chatbots that are available for download at \n        https://openai.com/chatgpt/download/ \n        and https://claude.ai/download respectively, \n        and, once installed, can be conveniently accessed via the keyboard shortcuts Ctrl+Space and Ctrl+Alt+Space.\n    \n    \n    \n        Web-based Experimentation Platforms: All major LLM providers also offer web-based interfaces that offer greater functionality and flexibility than chatbots but do not require programming knowledge.\n        These platforms, such as \n        OpenAI Playground, \n        Google AI Studio, and \n        Anthropic Console, \n        allow users to experiment with different model settings, like temperature and top-p sampling, and provide more control over the input and output formats compared to chatbots. \n        Such experimentation platforms are particularly useful for exploring the capabilities of LLMs, testing prompts, and fine-tuning models for specific tasks.\n    \n\n    \n        Application Programming Interfaces (APIs): For the maximum level of customization and integration, the listed models are also accessible through APIs, \n        which allow programmers to integrate LLMs directly into their own software applications. \n        This enables a wide range of more advanced and customized use cases, such as automating repetitive tasks or analyzing large datasets using natural language processing techniques. \n        APIs provide more flexibility and control compared to the above two options and can be employed on a pay-per-use basis, \n        but they also require a higher level of technical expertise to use effectively. \n        \n        Accessing LLMs through APIs typically involves signing up for an API key from the model provider \n        (which can be thought of as a credit card for LLM tokens), installing a client library in the programming language of choice, \n        and writing code to interact with the API endpoints. \n        \n        While this process may be more complex than using a chatbot, it unlocks the full potential of LLMs for those with the necessary programming skills. \n        The replication package for this paper demonstrates how to use APIs to automatically query LLMs.\n    \n\n    \n        Locally Operating LLMs: Open-source models allow researchers to run LLMs on their own computers, \n        offering advantages such as data privacy, cost-effectiveness, customization, and offline accessibility.\n        The computational resource requirements imply that only small models can be executed at a reasonable speed on desktop computers. \n        However, advances in computational capacity as well as rapid efficiency gains of LLMs that allow greater capabilities of smaller models \n        are rapidly making the local use of LLMs more attractive. Two solutions that make it particularly easy to deploy LLMs locally are:\n        \n        \n            \n                LM Studio \n                allows users to download and run a range of open-source LLMs, including VLMs, on their personal computer or server.\n            \n            \n                llamafile \n                makes it possible to download LLMs in a single file and run them on a wide range of computer systems.\n            \n        \n    \n\n\nCentralized Hubs for LLM Interaction and Experimentation– A useful website with a user-friendly chat interface that offers access to all leading LLMs is\nhttps://poe.com.\nSimilarly, a website that offers users a web-based experimentation platform with access to a wide range of different models is\nhttps://nat.dev/.\nPrompting Guides for Text-based Access – Although it is useful for everyone to gain experience interacting with LLMs through their own experimentation and learning-by-doing, most leading model providers now also offer public documents that describes strategies for how to prompt LLMs. The following is a list of such guides:\n\n    \n        \n            https://platform.openai.com/docs/guides/prompt-engineering\n        \n    \n    \n        \n            https://ai.google.dev/gemini-api/docs/prompting-intro\n         \n        and an example of a research assistant at \n        \n            https://aistudio.google.com/app/prompts/research-assistant\n        \n    \n    \n        \n            https://docs.anthropic.com/claude/docs/intro-to-prompting\n         \n        and an associated prompt library at \n        \n            https://docs.anthropic.com/en/prompt-library/library\n        \n    \n    \n        \n            https://llama.meta.com/get-started/#prompting\n        \n    \n\n\n\n    Anthropic also offers a \"prompt generator\" that helps users to optimize the prompts that they employ for querying LLMs through the \n    Anthropic Console Dashboard \n    (click \"Generate a Prompt\"). This tool converts basic instructions in written language describing a user's intent into a more complex \n    and specific set of instructions that induce LLMs to generate higher-quality output. Naturally, the user can edit and adjust the \n    generated instructions before use to ensure that they capture their intent as well as possible.\n\n\n\n    I illustrate this using the following example. Throughout the remainder of this section, I will present all examples generated by \n    LLMs in boxes, with the prompt in the header and the LLM's generated response in the body of the box.\n\n\n\n    \n    \n        Prompt (Anthropic Prompt Generator): I have written an economics paper and would like to create a draft of a blog for Brookings.\n    \n\n    \n\n    \n    Response:\n    [+] click to expand\n    \n        Your task is to help draft a blog post for the Brookings Institution based on an economics research paper. Here is the full text of the paper:\n\n        &lt;paper&gt;\n{{PAPER}}\n&lt;/paper&gt;\n        \n\n        The target audience for this blog post is:\n\n        &lt;audience&gt;\n{{AUDIENCE}}\n&lt;/audience&gt;\n        \n\n        First, carefully read through the entire paper, taking notes on the key points, main findings, and implications in a &lt;scratchpad&gt; section.\n\n        Next, write a short outline for the blog post in a &lt;outline&gt; section.\n           Keep the target audience in mind as you decide what to focus on and how to present the information.\n\n        Then, using your outline as a guide, write out the full draft of the blog post in a &lt;blog_post_draft&gt; section. Remember to:\n\n        \n            Use clear, engaging language that will be easily understood by the target audience.\n            Incorporate relevant examples, anecdotes, or analogies where appropriate to make the post more relatable and interesting.\n            Avoid copying word-for-word from the original paper. Put the key concepts into your own words.\n            Focus on the implications and \"so what\" of the research rather than getting too in-the-weeds with technical details.\n        \n\n        After you finish the draft, review it to make sure it covers the most important and interesting points from the paper in a way that will resonate with the target Brookings audience. Make any final tweaks before submitting your draft.\n    \n\n\n    \n    \n        Analysis: The generated prompt provides a remarkable level of detail that employs several cutting-edge prompting techniques to obtain the best possible results.\n        \n            It asks the model to start by taking notes in a \"scratchpad\" section, which induces the model to synthesize the main lessons of the text. Then it asks the model to prepare an outline, which induces the model to generate a plan. Only after these steps does the prompt ask the model to write a draft of the text. \n\n            The prompt also leaves two locations for users to insert the paper in question and to define the audience. I simply substituted these by writing \"The full text of the paper is attached\" and inserting \"policymakers\" as the target audience. \n\n            The prompt generated useful results on all three of the leading LLMs that would save considerable time in such a project, although the generated blog post was not quite up to the depth and quality of a think tank like Brookings.\n            \n                I asked Anthropic Prompt Generator to create prompts for blog posts for several different outlets. For some reason, asking for a blog targeted at Brookings gave rise to a higher-quality prompt than asking for any other outlet I attempted. My best explanation is that the model internalizes that Brookings is known for its high-quality analysis. (Disclaimer: The author is a non-resident fellow at Brookings.)\n            \n        \n        [+]\n    \n\n systematically study 26 different guiding principles for prompting leading LLMs and offer prompting advice based on a systematic evaluation of their effectiveness. Curiously, they find that strategies such as (fictitiously) offering LLMs a tip or threatening a penalty improve performance."
  },
  {
    "objectID": "applications.html",
    "href": "applications.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Summary\n Table 4 summarizes all the sample tasks illustrated in this paper, categorized by the seven different domains of application of LLMs. In the Fall 2024 version of this paper, I created a new category, “Promotion”, in which there are several new impressive use cases, described in Section \\(\\ref{ssec:promotion}\\). Readers who are familiar with earlier versions of this paper may want to focus on that section to check out these new use cases. In the third column, I report how useful I found the described LLM capabilities as of November 2024. In my most recent update, remarkably the lowest rating is “useful” (◖), which indicates there are productivity gains to be had but oversight is still required. There are also an abundance of the highest rating (⬤), which means that incorporating these capabilities into your workflow will definitely save time with little accuracy cost.\nThe other subsections of the site will go into detail of each of these categories and their corresponding tasks.\n\nIdeation & Feedback\nWriting\nBackground Research\nCoding\nData Analysis\n\n\n\n\n\n\nCategory\nTask\nUsefulness\n\n\n\n\nIdeation & Feedback\nBrainstorming\n⬤\n\n\nFeedback\n◖\n\n\nProviding counterarguments\n◖\n\n\nWriting\nSynthesizing text\n⬤\n\n\nEditing text\n⬤\n\n\nEvaluating text\n⬤\n\n\nConverting hand-written equations24/6\n⬤+\n\n\nGenerating titles & headlines\n⬤\n\n\nBackground Research\nSummarization\n⬤\n\n\nCondensing YouTube videos24/6\n⬤\n\n\nLiterature Research\n◖*\n\n\nLLM-Powered Search24/6\n◖\n\n\nFormatting References\n⬤\n\n\nTranslating Text\n⬤\n\n\nExplaining Concepts\n◖\n\n\nCoding\nWriting code\n⬤+\n\n\nExplaining code\n⬤+\n\n\nTranslating code\n⬤\n\n\nDebugging code\n⬤+\n\n\nData Analysis\nLocating data sources24/6\n◖\n\n\nCreating figures\n◖\n\n\nExtracting data from text\n⬤\n\n\nReformatting data\n⬤\n\n\nClassifying and scoring text\n⬤+\n\n\nExtracting sentiment\n⬤+\n\n\nSimulating human subjects\n◖\n\n\nMath\nSetting up models\n◖\n\n\nDeriving equations\n◖+\n\n\nExplaining models\n◖\n\n\nResearch Promotion\nSocial media posts\n⬤\n\n\nPresentation slides24/11\n⬤\n\n\nBlog posts24/11\n⬤\n\n\nConducting interviews24/11\n⬤\n\n\nPodcasts24/11\n⬤\n\n\n\n\n\nThe third column reports my subjective rating of LLM capabilities as of November 2024:\n\n    ⚪: experimental; results are inconsistent and require significant human oversight\n    ◖: useful; requires oversight but will likely save you time\n    ⬤: highly useful; incorporating this into your workflow will save you time\n\nSuperscripts 24/6 or 24/11 in the second column represent the year and month of new inclusions.\nSuperscripts in the last column denote upgraded ratings in 2024/06 (*) and 2024/11 (+)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Generative AI for Economic Research",
    "section": "",
    "text": "Welcome\n\nThis companion site to my JEL paper illustrates the growing number of ways in which generative AI can automate research tasks and help as a tutor, from assisting in ideation, feedback, and writing to data analysis, coding, and math. Check out how to get started or browse through the sample use cases to get inspired.\n\nDownload the published December 2024 Update of the paper here\nDownload the published June 2024 Update of the paper here\nDownload the original Journal of Economic Literature version of the paper here\nSee below to get notified when the next version is released"
  },
  {
    "objectID": "get-started.html",
    "href": "get-started.html",
    "title": "Getting Started with Generative AI",
    "section": "",
    "text": "Sign up for an account at https://chat.openai.com.\nA free account allows access to ChatGPT with an underlying GPT-3.5 model, while a paid account, ChatGPT Plus, expands access to GPT-4 and other tools, including plugins.\nTo sign up for the Plus version of ChatGPT, click “Sign up” on the right window to create an account and subscribe to the paid version of ChatGPT Plus, which automatically includes Advanced Data Analysis. As of January 2024, a subscription costs $20/month. Once logged in, the user can select to use GPT-4 in the upper left corner of the chat interface.\nThe model will automatically decide when to utilize Advanced Data Analysis based on your prompt; however, you can explicitly ask the model in your prompt to use the tool if you desire. Files can be uploaded by clicking on the “+” button in the chat box. Chats 17 and 21 in the paper were produced by entering the described prompts in ChatGPT Advanced Data Analysis.\nGPT-4 notably has a usage cap (currently 40 messages every 3 hours).\n\n\n\nAn image of the ChatGPT interface. In the upper left-hand corner, there is a drop-down for GPT-4, GPT-3.5, and Plugins options\n\n\nYou can also select to use GPT-3.5, which may be desirable for certain prompts or to avoid reaching the time-based limit of GPT-4 messages. Lastly, you can select to use the Plugins version of ChatGPT, which allows access to third-party tools. Popular plugins include Wolfram Alpha, which enhances ChatGPT’s ability to perform advanced calculations.\n\n\n\nRefining your prompt can help improve output. Spending time using GPT-4 or GPT-3.5 can build intuition for effectively interacting with the model. Repetition is also a powerful way to achieve the desired output.\nAdditionally, don’t hesitate to ask ChatGPT to modify responses. It can refer back to previous messages, making the process iterative. The best outputs often come from tweaking responses, much like reviewing a peer’s paper."
  },
  {
    "objectID": "get-started.html#using-chatgpt",
    "href": "get-started.html#using-chatgpt",
    "title": "Getting Started with Generative AI",
    "section": "",
    "text": "Sign up for an account at https://chat.openai.com.\nA free account allows access to ChatGPT with an underlying GPT-3.5 model, while a paid account, ChatGPT Plus, expands access to GPT-4 and other tools, including plugins.\nTo sign up for the Plus version of ChatGPT, click “Sign up” on the right window to create an account and subscribe to the paid version of ChatGPT Plus, which automatically includes Advanced Data Analysis. As of January 2024, a subscription costs $20/month. Once logged in, the user can select to use GPT-4 in the upper left corner of the chat interface.\nThe model will automatically decide when to utilize Advanced Data Analysis based on your prompt; however, you can explicitly ask the model in your prompt to use the tool if you desire. Files can be uploaded by clicking on the “+” button in the chat box. Chats 17 and 21 in the paper were produced by entering the described prompts in ChatGPT Advanced Data Analysis.\nGPT-4 notably has a usage cap (currently 40 messages every 3 hours).\n\n\n\nAn image of the ChatGPT interface. In the upper left-hand corner, there is a drop-down for GPT-4, GPT-3.5, and Plugins options\n\n\nYou can also select to use GPT-3.5, which may be desirable for certain prompts or to avoid reaching the time-based limit of GPT-4 messages. Lastly, you can select to use the Plugins version of ChatGPT, which allows access to third-party tools. Popular plugins include Wolfram Alpha, which enhances ChatGPT’s ability to perform advanced calculations.\n\n\n\nRefining your prompt can help improve output. Spending time using GPT-4 or GPT-3.5 can build intuition for effectively interacting with the model. Repetition is also a powerful way to achieve the desired output.\nAdditionally, don’t hesitate to ask ChatGPT to modify responses. It can refer back to previous messages, making the process iterative. The best outputs often come from tweaking responses, much like reviewing a peer’s paper."
  },
  {
    "objectID": "get-started.html#using-claude",
    "href": "get-started.html#using-claude",
    "title": "Getting Started with Generative AI",
    "section": "Using Claude",
    "text": "Using Claude\n\nSetting Up a Claude 2 Account\nA Claude 2 account can be created by visiting https://claude.ai and following the sign-up instructions. Claude 2 offers both a free version and a $20/month Pro version, which provides more and faster usage.\nAfter registering, user queries can be entered in the chat box. Files can be uploaded by clicking the paperclip 📎 button in the chat box. Chats 3, 11, and A.1 in the paper were produced by entering the described prompts in Claude 2.\n\n\n\nAn image of the Claude 2 chat interface\n\n\nClaude 2 is known for handling longer context prompts. If a file exceeds the token limit, it will provide an error message. In general, prompting strategies are similar to ChatGPT."
  },
  {
    "objectID": "get-started.html#using-poe.com",
    "href": "get-started.html#using-poe.com",
    "title": "Getting Started with Generative AI",
    "section": "Using Poe.com",
    "text": "Using Poe.com\nPoe is unique in that, rather than providing a proprietary model, it offers a variety of customized generative AI models, including language models (bots) and image generators.\nTo access all features, including GPT-4, a subscription fee of $19.99/month is required.\nTo use the site, visit Poe.com. On the homepage, you can explore various bots. You can use the “Explore” option on the left to search through a vast list of models, or select “Create a Bot”.\n\n\n\nAn image of the Poe.com chat interface\n\n\n\nCreating a Bot on Poe\nCreating a bot requires selecting:\n- A name\n- A base model\n- A system prompt (which determines how the bot behaves)\nAdditionally, you can adjust the temperature:\n- Lower values → More predictable answers\n- Higher values → More randomness (“creative” responses)\nFor advanced users, Poe allows access to privately hosted bots as well."
  },
  {
    "objectID": "subs/overview.html",
    "href": "subs/overview.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Table 1 provides an overview of the top proprietary and open-source LLM providers as of November 4, 2024.\n\n    \n\n\n\nAI Lab\nBest Model\nReleased\nLMSYS\nTokens\nData Cutoff\nURL\n\n\n\n\nOpenAI\ngpt-4o-latest\nSep 2024\n1340\n128k\nOct 2023\nchat.com*\n\n\nGoogleDM\nGemini 1.5 Pro 002\nSep 2024\n1303\n~2m\nNov 2023\ngemini.google*\n\n\nxAI\nGrok-2\nAug 2024\n1290\n128k\nMar 2024\nx.ai / x.com*\n\n\nAnthropic\nClaude 3.5 Opus\nOct 2024\n1286\n200k\nApr 2024\nclaude.ai\n\n\nMeta\nLlama 3.1-405b\nJul 2024\n1267\n128k\nDec 2023\nmeta.ai (OS)\n\n\nAlibaba\nQwen 2.5-72b\nSep 2024\n1263\n128k\nSep 2024\nGitHub (OS)\n\n\n\n\n    \n        \n    \n          Table 1 : Overview of top proprietary and open-source LLM providers according to their best model score in the LMSYS leaderboard. \n        Source: https://lmarena.ai/?leaderboard. \n        See . Last accessed on Nov. 4th, 2024.\n        * Denotes chatbots that can also access real-time information on the internet.\n    \n\n\n\n    \n\n The table is ranked by the score of each provider's leading models in the LMSYS leaderboard (column 4), which pits randomly-selected pairs of LLMs against each other and employs user ratings to compile an \n    The Elo-system was designed by the physicist Arpad Elo to rank chess players by their relative skills. It is designed so that a score difference of \\( D \\) points between two players (or LLMs) corresponds to the higher-ranked one having a probability of \\( \\frac{1}{1+10^{D/400}} \\) of winning in a direct match-up.\n for \n    Like all ranking systems that condense the capabilities of candidates who differ across many dimensions into a single dimension, the LMSYS score offers only a partial and imperfect snapshot of LLM capabilities. I chose to use it for the overview table here because it has almost universal coverage of LLMs, it is updated in close to real-time, and it aggregates many different types of use cases when evaluating models. The LMSYS score is also highly correlated with other benchmarks of general LLM performance such as the MMLU.Columns 5 and 6 of the table list how many tokens (or syllables of text) the models can process simultaneously, and the date on which their training data cuts off. Models generally do not have knowledge of facts that occurred past this date, except if they have the capacity to access the internet. The last column lists the URLs under which the models can be accessed. The designation \"OS\" reflects that the model is available on an open-source basis, i.e., that it can be freely downloaded, run, and modified by researchers.\n\n\nSeveral observations stand out from the table:\n\nThe field is moving fast— all six of the listed models have been released or updated in the past four months. In fact, older models quickly fall in the rankings. For example, if OpenAI had not released any model updates since April 2024, it would currently rank at the bottom of Table 1.\nOpenAI continues to be the clear leader in the space with the latest update to its GPT-4o model.\nThe gap between the LMSYS scores of the top models is, however, relatively small. For example, using the Elo formula (see Table 1 footnote), OpenAI’s GPT-4o would win against the next-ranked Google DeepMind Gemini 1.5 Pro in 55.3% of match-ups—hardly a decisive victory. In the words of Microsoft CEO Satya Nadella, LLMs are becoming “more of a commodity.”\nThe open-source models by Meta and Alibaba, listed in the bottom two rows of the table, have caught up and are now close to the frontier—a very different situation from a year ago, when open-source models were significantly behind proprietary models.\nChinese-made LLMs have ascended particularly rapidly, as reflected in the last row. Since LMSYS rankings are based on mostly Western user preferences, they may in fact understate the capabilities of Qwen 2.5. What is notable is that the model ranks so close to the best Llama 3.1 model, even though its parameter count (72bn) is just a fraction of the latter’s (405bn).\n\nSpeed of Progress\n\nTo provide data on the speed of progress, I list a few quantitative indicators from OpenAI's series of GPT-4 models as an example. Since the initial release of GPT-4 in March 2023---less than two years ago---the models' context window size has increased 16-fold, allowing it to process far more content at once, the quality of the model\\textquoteright s responses has significantly improved (the current LMSYS score of the original GPT-4 is only 1186), and the speed of output generation has increased 3-fold. Figure 1 illustrates the steep decline in the cost of reading and generating text (input and output tokens) of GPT-4 level models since March 2023---by 92% and 83% respectively---even though their LMSYS score steadily improved. See  for a detailed examination of algorithmic progress in LLMs.   \n\n\nIn the following, I describe the leading LLM products of the frontier labs listed in Table 1. Readers who are most interested in the conceptual advances may want to skip to the page on reasoning.\n\n\nEach of the labs listed in Table 1 families of models of different sizes that reflect different trade-offs between model performance, speed, and cost. Larger models are more \"intelligent\" and generally offer better performance and greater capabilities, but they also require more computational resources and take longer to process requests, making them more expensive. Smaller models, on the other hand, are faster and more cost-effective, but may not provide the same level of quality in their outputs. This allows users to consider their specific needs and budget when choosing the appropriate model size for their applications.\n\n\n\nThe first four labs listed in the table offer proprietary models, which means that their models can only be accessed via the labs’ computer servers. They do not share the source code, architecture, and model weights of their LLMs but allow users to access them via chatbots, web-based experimentation platforms, or APIs, subject to the certain conditions and controls.\n\n    \n    \n          Open AI's GPT-4o model, last updated in September 2024, continues to lead the market for LLMs in terms of both general capabilities and popularity. (OpenAI's o1 model, also released in September 2024, demonstrates new advances in LLM-based reasoning that are extremely valuable for research, as described in the reasoning page , but less valuable for general use, resulting in a lower LMSYS score than GPT-4o.)\n         GPT-4o is an evolution of the original GPT-4 model of March 2023 that is considerably smaller, faster, cheaper, and more capable, as shown in Figure 1 . The suffix \"o\" stands for \"omni\" to reflect that the model can process text, images, and sound. GPT-4o also offers workspace extensions that make it easy to interact collaboratively with the model, including Canvas and Advanced Data Analysis (described in the access mode page  and the data analysis page  below), and the ability to search the web (described in the  page about search). GPT-4o is subject to usage limits in the free version of ChatGPT. The model's smaller sibling, GPT-4o-mini, is faster and 94% cheaper but would still rank in the number 5 spot in Table 1, making it an attractive choice for bulk data processing. \n        \n        [+]\n    \n\n\n\n    \n        \n        \n            Figure 1: Decline in operating costs and quality improvement of GPT-4 models \n            Source: compiled by author.\n        \n    \n\n\n\n\n\n    \n    \n        Google DeepMind's Gemini series of LLMs carries the distinction of having a 2m token context window—the longest of all publicly available LLMs, which allows it to simultaneously process a few dozen books or several hundred papers.\n         This offers new use cases—for example, it allows researchers to upload a significant body of their work all at once and process queries based on it, or to simultaneously process videos or large corpora of images. The most powerful version is currently Gemini 1.5 Pro 002, updated September 2024, and is only available to paying subscribers. It also comes with a smaller sibling, Gemini 1.5 Flash, which offers greater speeds at lower cost but slightly lower performance. Gemini is also accessible via an eponymous chatbot that can access the internet to include real-time information in its responses and allows users to cross-check results and follow links to its sources.  \n        \n        [+]\n    \n\n\nxAI’s Grok-2 is a relative newcomer in the LLM space. xAI was founded by Elon Musk in March 2023, and its Grok-2 model has ascended into the top-3 a bit over a year after the labs founding, offering state-of-the-art peformance in most tasks. xAI benefits from its close relationship with X, formerly Twitter, which Elon Musk took over in 2022 and uses for training data. This allows Grok-2 to be up-to-date on news. Moreover, it distinguishes itself by not imposing any limits on user queries, following instructions and generating controversial content that many may consider unethical, reflecting Elon Musk’s “free-speech absolutism”.\n\n    \n    \n        Anthropic's Claude 3.5 Sonnet, by contrast, brands itself as being a helpful, honest, and harmless assistant, employing a process called constitutional AI to train the LLM to follow a set of high-level ethical principles  .\n         Claude is the model I use most for writing as I like its succinct, elegant, and insightful writing style. The latest update, released in October 2024, ranks the model in the top spot of several technical benchmarks. Claude 3.5 has a context window of 200k tokens, which makes it able to process about 150,000 words in one go—for example, several academic papers. Anthropic pioneered many LLM applications and access modes, for example, the chatbot format before ChatGPT or, more recently, interactive collaboration in workspaces called Artifacts  and autonomous computer use (the access mode page). Another recent update, PDF support (beta), allows Claude to visually process PDF documents uploaded in its chat interface or via its API so that it can read figures and graphs in PDFs, which is highly valuable in processing academic papers or other documents that contain visual information such as charts or figures.\n        \n        [+]\n    \n\n\nTable Table 2  compares the cost of the models listed above---it has become industry practice for leading labs to offer two main models: a more expensive frontier model and a cheaper model well-suited for bulk data processing. xAI is only offering beta access to its models as of November 2024. OpenAI and Anthropic offer a 50% discount for batch processing that may be executed at a delay when their servers face a lower load; all three labs offer discounts for cached content. For Google DeepMind, the first 50 requests per day for its Pro model and 1500 requests per day for its Flash model are free, and using more than 128k tokens incurs double the cost displayed in the \n        Up-to-date pricing information for the three labs is available at \n        \n            OpenAI Pricing\n        , \n        \n            Google AI Pricing\n        , and \n        \n            Anthropic Pricing\n        .\n    \n\n\n    \n\n\n\nModel (cost per 1M tokens)\nInput Cost\nOutput Cost\n\n\n\n\nOpenAI GPT-4o\n$2.5\n$10\n\n\nOpenAI GPT-4o-mini\n$0.15\n$0.60\n\n\nGoogle DeepMind Gemini 1.5 Pro\n$1.25\n$5\n\n\nGoogle DeepMind Gemini 1.5 Flash\n$0.075\n$0.30\n\n\nAnthropic Claude 3.5 Sonnet\n$3\n$15\n\n\nAnthropic Claude 3.5 Haiku\n$1\n$5\n\n\n\n\n\n\n\n    \n        \n            Table 2: Price comparison for input and output tokens across leading models. \n            Source: compiled by author. \n        \n    \n\n\n\n\nThe top LLM providers that release their models open source are listed in the last two rows of Table 1 Their models are freely available to download, use, modify, and distribute. This offers several benefits for economic research. Firstly, the transparency of open-source models allows researchers to examine the underlying architecture, enabling them to better understand the model’s structure. Secondly, open-source projects allow anybody to innovate upon the model. This can help accelerate the development of LLMs tailored to specific needs. Thirdly, if researchers have access to low-cost computing resources, they can leverage open-source models for their work without incurring financial costs. Fourthly, open-source models that are operated locally offer significant privacy benefits as sensitive data does not need to be channeled over the internet to be processed on the servers of proprietary model providers. Finally, open-source models allow for greater reproducibility, which is helpful for ensuring scientific integrity in research as it enables other researchers to verify and build upon the reported results. These benefits make open-source language models an attractive choice for researchers seeking to harness the power of natural language processing in their work.\n\nFrom an economic perspective, open-source models are highly beneficial as they freely distribute the economic social surplus created by LLMs and stimulate innovation . On the downside, as open-source LLMs become more capable, they also pose growing safety \n    For example, LlaMA has already allowed researchers to construct adversarial attacks that circumvent the safety restrictions of all the LLMs listed above .  discuss the pros and cons of open-sourcing LLMs as well as intermediate solutions between proprietary and fully open-source models that may be desirable as LLMs become more capable and pose growing safety risks.\n\n.  \n\n\n\nMeta's LlaMA 3.1 is currently the most powerful series of open source models, which have been downloaded more than 350,000 times so far. The most powerful publicly available model is currently Llama 3.1-405B which features 405B parameters. However, as of November 2024, LlaMA is transitioning to version 3.2, offering multi-modal versions with 11B and 90B parameters as well as text-only versions with 3B and 1B parameters, which can be operated on many devices. All available Llama models are also accessible on leading cloud computing platforms, including Microsoft Azure, AWS, and Hugging Face. NVIDIA released a fine-tuned version of Meta's 70B parameter model as Llama-3.1-Nemotron-70B-Instruct, which has obtained an LMSYS score of 1271 despite its smaller size.\n\n\n\nAlibaba's Qwen 2.5 (short for Tongyi Qianwen, which translates to \"Unified Thousand Questions\") has made rapid progress and reached a spot in Table 1  in Sept 2024, even though Alibaba, being located in China, is subject to export controls on cutting-edge GPU chips that are crucial for training LLMs. The Qwen 2.5 series consists of 100 open-source models with parameter sizes ranging from 0.5B to 72B, including multimodal models and excellent LLMs specialized in math and coding that reach state-of-the-art performance."
  },
  {
    "objectID": "subs/overview.html#leading-proprietary-models",
    "href": "subs/overview.html#leading-proprietary-models",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "The first four labs listed in the table offer proprietary models, which means that their models can only be accessed via the labs’ computer servers. They do not share the source code, architecture, and model weights of their LLMs but allow users to access them via chatbots, web-based experimentation platforms, or APIs, subject to the certain conditions and controls.\n\n    \n    \n          Open AI's GPT-4o model, last updated in September 2024, continues to lead the market for LLMs in terms of both general capabilities and popularity. (OpenAI's o1 model, also released in September 2024, demonstrates new advances in LLM-based reasoning that are extremely valuable for research, as described in the reasoning page , but less valuable for general use, resulting in a lower LMSYS score than GPT-4o.)\n         GPT-4o is an evolution of the original GPT-4 model of March 2023 that is considerably smaller, faster, cheaper, and more capable, as shown in Figure 1 . The suffix \"o\" stands for \"omni\" to reflect that the model can process text, images, and sound. GPT-4o also offers workspace extensions that make it easy to interact collaboratively with the model, including Canvas and Advanced Data Analysis (described in the access mode page  and the data analysis page  below), and the ability to search the web (described in the  page about search). GPT-4o is subject to usage limits in the free version of ChatGPT. The model's smaller sibling, GPT-4o-mini, is faster and 94% cheaper but would still rank in the number 5 spot in Table 1, making it an attractive choice for bulk data processing. \n        \n        [+]\n    \n\n\n\n    \n        \n        \n            Figure 1: Decline in operating costs and quality improvement of GPT-4 models \n            Source: compiled by author.\n        \n    \n\n\n\n\n\n    \n    \n        Google DeepMind's Gemini series of LLMs carries the distinction of having a 2m token context window—the longest of all publicly available LLMs, which allows it to simultaneously process a few dozen books or several hundred papers.\n         This offers new use cases—for example, it allows researchers to upload a significant body of their work all at once and process queries based on it, or to simultaneously process videos or large corpora of images. The most powerful version is currently Gemini 1.5 Pro 002, updated September 2024, and is only available to paying subscribers. It also comes with a smaller sibling, Gemini 1.5 Flash, which offers greater speeds at lower cost but slightly lower performance. Gemini is also accessible via an eponymous chatbot that can access the internet to include real-time information in its responses and allows users to cross-check results and follow links to its sources.  \n        \n        [+]\n    \n\n\nxAI’s Grok-2 is a relative newcomer in the LLM space. xAI was founded by Elon Musk in March 2023, and its Grok-2 model has ascended into the top-3 a bit over a year after the labs founding, offering state-of-the-art peformance in most tasks. xAI benefits from its close relationship with X, formerly Twitter, which Elon Musk took over in 2022 and uses for training data. This allows Grok-2 to be up-to-date on news. Moreover, it distinguishes itself by not imposing any limits on user queries, following instructions and generating controversial content that many may consider unethical, reflecting Elon Musk’s “free-speech absolutism”.\n\n    \n    \n        Anthropic's Claude 3.5 Sonnet, by contrast, brands itself as being a helpful, honest, and harmless assistant, employing a process called constitutional AI to train the LLM to follow a set of high-level ethical principles  .\n         Claude is the model I use most for writing as I like its succinct, elegant, and insightful writing style. The latest update, released in October 2024, ranks the model in the top spot of several technical benchmarks. Claude 3.5 has a context window of 200k tokens, which makes it able to process about 150,000 words in one go—for example, several academic papers. Anthropic pioneered many LLM applications and access modes, for example, the chatbot format before ChatGPT or, more recently, interactive collaboration in workspaces called Artifacts  and autonomous computer use (the access mode page). Another recent update, PDF support (beta), allows Claude to visually process PDF documents uploaded in its chat interface or via its API so that it can read figures and graphs in PDFs, which is highly valuable in processing academic papers or other documents that contain visual information such as charts or figures.\n        \n        [+]\n    \n\n\nTable Table 2  compares the cost of the models listed above---it has become industry practice for leading labs to offer two main models: a more expensive frontier model and a cheaper model well-suited for bulk data processing. xAI is only offering beta access to its models as of November 2024. OpenAI and Anthropic offer a 50% discount for batch processing that may be executed at a delay when their servers face a lower load; all three labs offer discounts for cached content. For Google DeepMind, the first 50 requests per day for its Pro model and 1500 requests per day for its Flash model are free, and using more than 128k tokens incurs double the cost displayed in the \n        Up-to-date pricing information for the three labs is available at \n        \n            OpenAI Pricing\n        , \n        \n            Google AI Pricing\n        , and \n        \n            Anthropic Pricing\n        .\n    \n\n\n    \n\n\n\nModel (cost per 1M tokens)\nInput Cost\nOutput Cost\n\n\n\n\nOpenAI GPT-4o\n$2.5\n$10\n\n\nOpenAI GPT-4o-mini\n$0.15\n$0.60\n\n\nGoogle DeepMind Gemini 1.5 Pro\n$1.25\n$5\n\n\nGoogle DeepMind Gemini 1.5 Flash\n$0.075\n$0.30\n\n\nAnthropic Claude 3.5 Sonnet\n$3\n$15\n\n\nAnthropic Claude 3.5 Haiku\n$1\n$5\n\n\n\n\n\n\n\n    \n        \n            Table 2: Price comparison for input and output tokens across leading models. \n            Source: compiled by author."
  },
  {
    "objectID": "subs/overview.html#leading-open-source-models",
    "href": "subs/overview.html#leading-open-source-models",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "The top LLM providers that release their models open source are listed in the last two rows of Table 1 Their models are freely available to download, use, modify, and distribute. This offers several benefits for economic research. Firstly, the transparency of open-source models allows researchers to examine the underlying architecture, enabling them to better understand the model’s structure. Secondly, open-source projects allow anybody to innovate upon the model. This can help accelerate the development of LLMs tailored to specific needs. Thirdly, if researchers have access to low-cost computing resources, they can leverage open-source models for their work without incurring financial costs. Fourthly, open-source models that are operated locally offer significant privacy benefits as sensitive data does not need to be channeled over the internet to be processed on the servers of proprietary model providers. Finally, open-source models allow for greater reproducibility, which is helpful for ensuring scientific integrity in research as it enables other researchers to verify and build upon the reported results. These benefits make open-source language models an attractive choice for researchers seeking to harness the power of natural language processing in their work.\n\nFrom an economic perspective, open-source models are highly beneficial as they freely distribute the economic social surplus created by LLMs and stimulate innovation . On the downside, as open-source LLMs become more capable, they also pose growing safety \n    For example, LlaMA has already allowed researchers to construct adversarial attacks that circumvent the safety restrictions of all the LLMs listed above .  discuss the pros and cons of open-sourcing LLMs as well as intermediate solutions between proprietary and fully open-source models that may be desirable as LLMs become more capable and pose growing safety risks.\n\n.  \n\n\n\nMeta's LlaMA 3.1 is currently the most powerful series of open source models, which have been downloaded more than 350,000 times so far. The most powerful publicly available model is currently Llama 3.1-405B which features 405B parameters. However, as of November 2024, LlaMA is transitioning to version 3.2, offering multi-modal versions with 11B and 90B parameters as well as text-only versions with 3B and 1B parameters, which can be operated on many devices. All available Llama models are also accessible on leading cloud computing platforms, including Microsoft Azure, AWS, and Hugging Face. NVIDIA released a fine-tuned version of Meta's 70B parameter model as Llama-3.1-Nemotron-70B-Instruct, which has obtained an LMSYS score of 1271 despite its smaller size.\n\n\n\nAlibaba's Qwen 2.5 (short for Tongyi Qianwen, which translates to \"Unified Thousand Questions\") has made rapid progress and reached a spot in Table 1  in Sept 2024, even though Alibaba, being located in China, is subject to export controls on cutting-edge GPU chips that are crucial for training LLMs. The Qwen 2.5 series consists of 100 open-source models with parameter sizes ranging from 0.5B to 72B, including multimodal models and excellent LLMs specialized in math and coding that reach state-of-the-art performance."
  },
  {
    "objectID": "subs/search.html",
    "href": "subs/search.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "LLM-Powered Search\nIn recent months, Perplexity AI and OpenAI’s ChatGPT Search have become increasingly capable at combining the strengths of traditional search engines with those of generative AI. Like search engines, these systems have access to real-time information via the web, which overcomes the shortcoming of earlier generations of LLMs that their world knowledge was confined to their increasingly outdated training data. However, like LLMs, they can process the results using the sophisticated synthesis capabilities of generative AI. While traditional search engines provide lists of links that users must manually browse and evaluate, LLM-powered search tools can perform this for the user and synthesize information from multiple sources into coherent, direct responses that can be formatted in any desired way, for example, in table format. They maintain all the powerful features of LLMs, including the ability to understand conversation context and support follow-up questions, but now enhanced with real-time knowledge such as the latest economic research, current market data, and emerging policy debates.\nThe following two chats provide examples, for which I uploaded an earlier version of this article:\n\n\n    \n    \n        Prompt (ChatGPT-4o with Search): Can you draft a new subsection on LLM-powered search for my paper on \"Generative AI for Economic Research,\" focusing on ChatGPT Search and Perplexity? Search the web to find out what people find most useful about these search tools. Then draft four concise paragraphs in an engaging academic style that fits well with the paper:\n        \n            \n                Introduce LLM-powered search as one of the recent innovations - what's the benefit of combining LLMs with search?\n                Overview and comparison of ChatGPT Search and Perplexity AI\n                Applications for academic research\n                Risks (but emphasize that search greatly reduces hallucinations)\n            \n            [Attachment: LLMs_2024h2.pdf]\n        \n        [+] click to expand\n    \n\n    \n\n    \n    Response:\n    [+] click to expand\n    \n        LLM-Powered Search: Enhancing Information Retrieval in Economic Research\n\n        The integration of Large Language Models (LLMs) with search functionalities represents a significant advancement in information retrieval, particularly beneficial for economic research. By combining the extensive language understanding capabilities of LLMs with real-time data access, researchers can obtain synthesized, contextually relevant information efficiently. This fusion facilitates the extraction of nuanced insights from vast datasets, streamlining the research process and enabling more informed analyses.\n\n        Two prominent LLM-powered search tools are ChatGPT Search and Perplexity AI. ChatGPT Search, developed by OpenAI, extends the conversational abilities of ChatGPT by incorporating real-time web search capabilities, providing users with up-to-date information and direct citations. Perplexity AI, on the other hand, functions as an AI-driven search engine that delivers concise answers with source attributions, emphasizing accuracy and transparency. While both tools aim to enhance information accessibility, ChatGPT Search offers a more interactive experience, whereas Perplexity AI focuses on precise, citation-backed responses.\n\n        In academic research, particularly within economics, these tools offer substantial advantages. They enable scholars to swiftly access current data, literature, and analyses, thereby expediting the research process. The ability to retrieve information with source citations ensures the credibility of the data, which is crucial for rigorous academic work. Moreover, the conversational interfaces of these tools allow for iterative querying, facilitating deeper exploration of complex economic topics.\n\n        Despite their benefits, it is important to acknowledge potential risks associated with LLM-powered search tools. One concern is the possibility of generating inaccurate or misleading information, known as \"hallucinations.\" However, the integration of search functionalities significantly mitigates this issue by grounding responses in real-time data and providing source citations. This enhancement not only improves the reliability of the information retrieved but also fosters transparency, allowing researchers to verify and cross-reference data effectively.\n    \n\n\n\n    \n    \n        Prompt (Perplexity AI Pro): (same prompt as above)\n    \n\n    \n\n    \n    Response:\n    [+] click to expand\n    \n        LLM-Powered Search: Enhancing Information Retrieval\n\n        The integration of Large Language Models (LLMs) with traditional search engines represents a significant leap forward in information retrieval. \n        By combining the vast knowledge base and natural language understanding capabilities of LLMs with real-time web search, these tools offer a more intuitive \n        and comprehensive search experience. LLM-powered search can interpret complex queries, synthesize information from multiple sources, and present coherent, \n        contextually relevant responses, effectively bridging the gap between raw data retrieval and insightful analysis.\n\n        Two prominent examples of LLM-powered search are ChatGPT Search and Perplexity AI. ChatGPT Search, integrated into OpenAI's ChatGPT Plus, \n        leverages the GPT-4 model to provide up-to-date information and web browsing capabilities. It excels in offering detailed, conversational responses and \n        can follow up on complex queries. Perplexity AI, on the other hand, is designed as a standalone search engine that combines web search with AI-generated \n        summaries. It distinguishes itself by providing source citations for its responses, allowing users to verify information easily. While both tools offer \n        similar core functionalities, Perplexity AI's emphasis on transparency and its dedicated search interface may appeal more to researchers seeking clear \n        attribution of sources.\n\n        For academic research, these tools offer several advantages. They can rapidly summarize the state of knowledge on a given topic, potentially accelerating \n        literature reviews. Researchers can use them to explore interdisciplinary connections, generate research questions, or find relevant datasets and publications. \n        The ability to ask follow-up questions and receive clarifications in natural language can be particularly useful when delving into unfamiliar fields or complex \n        topics. Additionally, these tools can assist in identifying research gaps by synthesizing information across multiple studies and highlighting areas where \n        consensus is lacking or evidence is sparse.\n\n        While LLM-powered search tools significantly reduce the risk of hallucinations compared to standalone LLMs by grounding responses in current web data, some \n        risks remain. The potential for bias in search results and AI interpretations persists, and the recency and reliability of sources can vary. Researchers must \n        maintain critical thinking and verify important information through traditional academic channels. Despite these considerations, the integration of LLMs with \n        search functionality represents a powerful tool for enhancing research efficiency and exploration, offering a valuable complement to traditional research \n        methodologies.\n    \n\n\n    \n    \n        Analysis: Both of these summaries are actually quite good and free of hallucinations, although perhaps a bit sterile for my taste. However, they illustrate that LLM-powered search represents a useful step in the direction of future AI models that will be capable of autonomously writing future updates of this article. But for now, let me also point out that the prompt that I employed provided the LLM with a lot of structure that was based on my understanding of how LLM-powered search fits into the overall landscape of generative AI for economic research.\n        \n    \n\n\nPerplexity AI is accessible at https://www.perplexity.ai and offers a chat interface much like ChatGPT but is specialized in searching the web to compile responses to user prompts based on the sources it identifies. What is most useful is that it provides links supporting the statements that it makes. After submitting a query, the site first shows the keywords it searches for and then a preliminary list of the materials that it evaluates as preliminary readings. Based on these, it generates a response that starts with a clickable list of final sources, continues with a synthesis of the materials found, and ends with a conclusion that summarizes everything. The user can follow the sources provided to judge their reliability and verify the model’s output. Perplexity has several different “Focus” options, including “Academic”, which focuses its search on published academic papers, or “Math”. It also offers a “Pro Search” option that dives deeper into topics and allows users to fine-tune the results but requires a subscription for frequent use. Another example of Perplexity AI in background research is provided in Chat .\nOpenAI released ChatGPT Search only recently, in October 2024, but the model represents the new state of the art in LLM-powered web search. It can be activated by explicitly instructing ChatGPT to search the web or by clicking a globe button at the bottom of the prompt window. It largely replicates the functionality of Perplexity AI but integrates this with the other capabilities of ChatGPT, making it better at multi-turn conversations and integration with applications that require data analysis. Google’s Gemini chatbot also draws on an internet search for questions for which this is relevant."
  },
  {
    "objectID": "subs/improvements.html",
    "href": "subs/improvements.html",
    "title": "Advances at the LLM Frontier",
    "section": "",
    "text": "Technical Improvements\nThe following two technical advances have been particularly useful for programming when using LLMs via API:\nStructured Outputs – The ability of leading LLMs to reliably produce structured outputs has advanced enormously over the past year. Traditionally, LLMs used to produce unstructured, free-text responses that could not directly be fed into other computer applications. By contrast, structured outputs enable LLMs to take in raw, unstructured, qualitative information and convert it to machine-readable data that seamlessly integrates with other more traditional computer programs, such as econometric packages. Structured outputs therefore bridge the gap between LLMs and traditional computer applications.\nJSON (JavaScript Object Notation) is one of the most common formats for structured data. It organizes information into key-value pairs, which makes it both flexible and easy for computers to interpret. JSON can store everything from simple numerical values and text to complex hierarchical data, such as nested lists or objects.\nFor example, a JSON output might look like this:\n\n\n{\n    \"country\": \"United States\",\n    \"population\": 332915073\n}\n\nXML (Extensible Markup Language) serves similar purposes, with data represented in tagged structures, such as:\n\n\n    United States\n    332915073\n\n\nHowever, XML is a bit more verbose. Both formats are compatible with many programming environments, making them widely applicable across research and data-driven applications.\n\n\n    \n    \n        Prompt: List the world's three largest economies as [{\"country\", \"population\", \"GDP_per_capita\"}] in JSON.\n    \n\n    \n\n    \n    Response (Claude 3.5 Sonnet API):\n    [+] click to expand\n    \n        \n[\n    {\n        \"country\": \"United States\",\n        \"population\": 332915073,\n        \"GDP_per_capita\": 69288\n    },\n    {\n        \"country\": \"China\",\n        \"population\": 1411750000,\n        \"GDP_per_capita\": 12556\n    },\n    {\n        \"country\": \"Japan\",\n        \"population\": 125507472,\n        \"GDP_per_capita\": 39285\n    }\n]\n        \n    \n\n\n    \n    \n        Analysis: To illustrate the benefits of this, assume this JSON was obtained from an LLM by a Python program via API and is stored in the variable country_data. Then individual entries, say for the first country (the index starts at 0), can simply be accessed by referring to country_data[0]['country'] or country_data[0]['population'] in the Python code. This type of structured output was difficult to obtain reliably from LLMs just two years ago but is now readily available, allowing LLMs to be integrated into programmatic workflows.\n        \n\n    \n\n\n\n introduced the benchmark StructuredRAG to evaluate LLMs on their ability to produce structured outputs consistently and accurately, assessing tasks such as generating structured responses in JSON based on criteria like precision, adherence to format, and reliability. \n\nOn their benchmark, Anthropic's Claude 3.5 ranked first with an almost perfect score, followed by Google Gemini 1.5 Pro and OpenAI GPT-4o, which delivered less consistent results in August 2024. However, in a September 2024 update, OpenAI included new functionality to allow users to specify any JSON format for the LLM to adhere to, greatly improving GPT-4o's capabilities to produce structured\n\n    For further details, see \n    \n        https://platform.openai.com/docs/guides/structured-outputs/\n    .\n\n\nFor economists, structured outputs are useful in a variety of applications, from organizing country-level economic indicators as in the example above, to managing survey data, financial data, sentiment data, or a wide range of other data sources.\n\nPrompt Catching is a technique to enhance LLM performance by storing and reusing previously processed text. This can reduce computational redundancy, resulting in higher speed and lower costs. For example, if a user repeatedly requests similar analyses based on a long introductory prompt, caching of the prompt instead of processing it again and again multiple times can save costs and speed up processing.\nBoth OpenAI and Anthropic have implemented prompt caching systems in their APIs. OpenAI’s implementation automatically activates when prompts exceed 1,024 tokens, caching the longest previously computed segment for reuse, which incurs only half of the usual cost of API use. Anthropic has developed a system that charges users 25% extra to write prompts into a cache but then allowing the reuse of cached information at a cost of only 10% of the regular price of text processing. For researchers, prompt caching is particularly appealing when performing text analysis in bulk as prompts can be cached and redundant computations be avoided, saving both time and money."
  },
  {
    "objectID": "subs/ideation.html",
    "href": "subs/ideation.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Research starts with the process of ideation, i.e., generating, developing, and selecting ideas. I start my exploration of LLMs with use cases that involve ideation and feedback for two reasons. First, starting with ideas follows the natural sequence of research. Second, ideation and feedback showcase a new set of capabilities that starkly distinguish LLMs from earlier applications of deep learning in research -- they display a form of creativity that had long been reserved for humans. Ideation and feedback are areas where it pays off to use the most advanced LLMs available.\n          A model of idea generation by  observes that creative performance depends on (i) the quantity of ideas, (ii) the average quality of ideas and (iii) the variance which determines how many exceptional ideas are generated.  find that GPT-4 outperforms MBA students at a top US business school on all three dimensions in a contest to develop innovative new product ideas. As a result, they argue that the bottleneck in ideation is increasingly shifting from generating to evaluating ideas.  find that Claude 3.5 Sonnet is better at identifying interesting questions in NLP research, although its questions are ranked as slighly less feasible.  \n          \n        As we will see in the following, although the current capabilities of cutting-edge LLMs in the areas of ideation and feedback are impressive, they also have limitations. There are also broader potential pitfalls. Any researcher who uses LLMs for ideation and feedback must of course be careful about which points they use and which points they reject in a given use case -- just as we do when we discuss ideas with colleagues. There may also be subtle downsides that materialize over time. The reliance on LLM-generated ideas may make individual researchers rely more on automation and practice less critical thinking of their own. Moreover, if more and more economists rely on the same one or two cutting-edge LLMs to generate ideas and obtain feedback, there is a risk that the ideas that economists work on will become more and more homogeneous and include fewer truly novel ideas. This risk of homogenization is also discussed in . Moreover, when using LLMs for brainstorming or feedback, it is important to keep in mind when their training data cuts off (see Table 1).\n        [+]\n    \n  \n\n\nCutting-edge LLMs are quite useful for brainstorming (or, perhaps more aptly, neural-net-storming) ideas and examples related to a defined theme. Having been trained on a vast amount of data that represents a cross-section of all human knowledge, the breadth of the representation of the world that cutting-edge LLMs have developed from their training data includes a fair bit of knowledge of economics. However, at present, human experts still have an edge when it comes to depth, and so LLMs are best suited for brainstorming in areas in which one is not an expert.\nThe following prompt illustrates a simple example using GPT-4. Notice that I added an instruction to limit the response to 10 words for each point – otherwise the LLM produced a whole paragraph on each point, which may be useful in general but would be too lengthy for our illustrative purposes here:\n\n\n    \n    \n        Prompt: Can you brainstorm 20 channels through which AI may increase inequality? Limit your response to 10 words for each point.\n    \n\n    \n\n    \n  Response (GPT 4):  \n[+] click to expand\n\n    1. Job loss due to automation in lower-skilled industries.\n  2. AI-driven wealth concentration in tech-savvy organizations.\n  3. Digital literacy gap leading to economic disparity.\n  4. Lack of universal access to AI technology.\n  5. AI-driven bias in hiring and selection processes.\n  6. Imbalance in job market due to AI specializations.\n  7. Data privacy issues affecting vulnerable populations.\n  8. AI-driven services predominantly targeting wealthy consumers.\n  9. Algorithms exacerbating social inequality through bias.\n  10. Inclusive AI product development lacking.\n  11. Higher prices due to AI-enhanced products/services.\n  12. AI-fueled gentrification in tech-centered cities.\n  13. Anticompetitive practices bolstered by AI applications.\n  14. Lack of labor rights for jobs displaced by AI.\n  15. Educational imbalance due to AI-learning tools.\n  16. AI in healthcare excluding lower socioeconomic groups.\n  17. Disproportionate influence of AI in political campaigns.\n  18. Undervaluing of human skills in favor of AI.\n  19. Biased AI systems perpetuating discrimination.\n  20. AI reinforcing societal hierarchies via data analysis.\n\n\n\n\n\n    \n    \n          Analysis:  The channels listed by the model are on-topic, largely reasonable, and span a wide range of what I could think of plus some more. However, some of the bullet points are a bit repetitive. \n    \n  \n\n\n   \n\nA noteworthy aspect to underscore is the remarkable speed and volume of responses generated by LLMs during activities like brainstorming, which generates its own distinct form of usefulness. Even if only a single suggestion out of 20 in examples like this proves beneficial, it may make our research significantly more productive.\n\n    \n    \n        Other brainstorming prompts that I found useful include the following:\n         \n    I am an economist working on AI and inequality. Can you brainstorm an outline on {insert topic}?\n    I am an economist working on AI and inequality. Can you brainstorm 5 potential paper topics and describe each in one sentence?\n    I am an economist working on an academic paper on {insert topic}. Can you brainstorm a research plan for me?\n\n        [+] click to expand\n    \n  \n\n\n\n\n\nLLMs can also evaluate ideas, highlighting, for example, the pros and cons of different hypotheses or research plans. The following example asks the LLM to list the pros and cons of working on a specific area of research. This shows that LLMs can provide useful input on different research directions.\n\n\n    \n    \n        Prompt: What are the top-3 pros and cons of working on the\neconomics of AGI? \n    \n\n    \n\n    \n  Response (GPT-4):\n[+] click to expand\n\n    Pros of Working on the Economics of AGI:\n\n1. High Impact: The development of AGI (Artificial General Intelligence) \nhas the potential to revolutionize many sectors of the economy, from \nhealthcare to finance to transportation. Working on the economics \nof AGI allows you to be at the forefront of this transformation and \npotentially shape its direction.\n\n2. Interdisciplinary Approach: The economics of AGI involves a combination \nof economics, computer science, and philosophy, among other disciplines. \nThis interdisciplinary approach can be intellectually stimulating \nand rewarding.\n\n3. Potential for Innovation: Given that AGI is a relatively new and \nrapidly evolving field, there is a lot of room for innovative thinking \nand novel approaches. This can be exciting and fulfilling for those \nwho enjoy problem-solving and creative thinking.\n\nCons of Working on the Economics of AGI:\n\n1. Uncertainty: The future of AGI is highly uncertain, making it difficult \nto make accurate predictions or develop robust economic models. This \nuncertainty can make the work challenging and sometimes frustrating.\n\n2. Ethical and Societal Implications: The development and deployment \nof AGI raise a host of ethical and societal issues, from job displacement \nto privacy concerns to potential misuse. Working on the economics \nof AGI means grappling with these complex and often contentious issues.\n\n3. Limited Data: Given that AGI is still in its early stages, there \nis limited data available for economic analysis. This lack of data \ncan make it difficult to test hypotheses or draw definitive conclusions.\n\n\n\n\n\n\n   \n\nWhat is particularly useful is to iterate between brainstorming and evaluation. Similar to how a researcher comes up with ideas, selects the most promising ones, and refines them, LLMs can be prompted to brainstorm, select which ideas it rates as the most promising, and brainstorm further on them.\nThe long context window of Claude 2 makes it possible to upload entire research papers into the LLM and ask for feedback. I fed the Feb.~2023 NBER working paper version of this paper  into Claude 2 and asked it the following:\n\n\n    \n    \n          Prompt:  Can you suggest ways to improve this paper? [Attachment: w30957.pdf] \n    \n\n    \n\n    \n  Response (Claude 2):  Here are some suggestions for improving the paper on large language models and cognitive automation: \n[+] click to expand\n\n\n    Provide more specific details and examples when describing the different use cases. For some of them, the explanations are a bit vague. Adding more concrete illustrations would strengthen those sections.\n    Expand the discussion of the limitations and potential downsides of over-relying on LLMs. The paper focuses mostly on the benefits, but more balance discussing the risks would be helpful.\n    Strengthen the analysis of the long-term implications. The outlook section is thought-provoking but remains speculative. Adding more rigorous analysis to back up the predictions could make it more convincing.\n    Consider testing the use cases on multiple LLMs and comparing their capabilities. The examples all seem to use a single LLM, but testing different ones could reveal variation in strengths/weaknesses.\n    Provide guidance on how to properly evaluate LLM outputs before using them. Since LLMs can make mistakes, some tips on double-checking the results would be useful.\n    (Additional suggestions omitted for space reasons)\n\nIn general, providing more specifics, analysis, examples, and structure could take the paper from a promising start to a more polished and convincing final product. Let me know if you would like me to elaborate on any of these suggestions!\n\n\n\n\n\n    \n    \n          Analysis:  All of the listed bullet points are good suggestions, and I have incorporated several of them in the paper during the revision process.  \n    \n  \n\n\n   \n\nSince Claude 2 can hold the content of the entire paper in its memory, it can offer comments on any parts of it if requested.\n\n    \n    \n        The following are additional examples of useful prompts:\n         \n    What are the main strengths and weaknesses of this paper?\n    What are the main novel ideas in the paper that are not sufficiently emphasized?\n    Can you identify any instances of bias in this paper?\n    How could I improve section {insert number}?\n    Can you draft a referee report for this paper for the Journal of Economic Literature?\n\n\n        [+] click to expand"
  },
  {
    "objectID": "subs/ideation.html#brainstorming",
    "href": "subs/ideation.html#brainstorming",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Cutting-edge LLMs are quite useful for brainstorming (or, perhaps more aptly, neural-net-storming) ideas and examples related to a defined theme. Having been trained on a vast amount of data that represents a cross-section of all human knowledge, the breadth of the representation of the world that cutting-edge LLMs have developed from their training data includes a fair bit of knowledge of economics. However, at present, human experts still have an edge when it comes to depth, and so LLMs are best suited for brainstorming in areas in which one is not an expert.\nThe following prompt illustrates a simple example using GPT-4. Notice that I added an instruction to limit the response to 10 words for each point – otherwise the LLM produced a whole paragraph on each point, which may be useful in general but would be too lengthy for our illustrative purposes here:\n\n\n    \n    \n        Prompt: Can you brainstorm 20 channels through which AI may increase inequality? Limit your response to 10 words for each point.\n    \n\n    \n\n    \n  Response (GPT 4):  \n[+] click to expand\n\n    1. Job loss due to automation in lower-skilled industries.\n  2. AI-driven wealth concentration in tech-savvy organizations.\n  3. Digital literacy gap leading to economic disparity.\n  4. Lack of universal access to AI technology.\n  5. AI-driven bias in hiring and selection processes.\n  6. Imbalance in job market due to AI specializations.\n  7. Data privacy issues affecting vulnerable populations.\n  8. AI-driven services predominantly targeting wealthy consumers.\n  9. Algorithms exacerbating social inequality through bias.\n  10. Inclusive AI product development lacking.\n  11. Higher prices due to AI-enhanced products/services.\n  12. AI-fueled gentrification in tech-centered cities.\n  13. Anticompetitive practices bolstered by AI applications.\n  14. Lack of labor rights for jobs displaced by AI.\n  15. Educational imbalance due to AI-learning tools.\n  16. AI in healthcare excluding lower socioeconomic groups.\n  17. Disproportionate influence of AI in political campaigns.\n  18. Undervaluing of human skills in favor of AI.\n  19. Biased AI systems perpetuating discrimination.\n  20. AI reinforcing societal hierarchies via data analysis.\n\n\n\n\n\n    \n    \n          Analysis:  The channels listed by the model are on-topic, largely reasonable, and span a wide range of what I could think of plus some more. However, some of the bullet points are a bit repetitive. \n    \n  \n\n\n   \n\nA noteworthy aspect to underscore is the remarkable speed and volume of responses generated by LLMs during activities like brainstorming, which generates its own distinct form of usefulness. Even if only a single suggestion out of 20 in examples like this proves beneficial, it may make our research significantly more productive.\n\n    \n    \n        Other brainstorming prompts that I found useful include the following:\n         \n    I am an economist working on AI and inequality. Can you brainstorm an outline on {insert topic}?\n    I am an economist working on AI and inequality. Can you brainstorm 5 potential paper topics and describe each in one sentence?\n    I am an economist working on an academic paper on {insert topic}. Can you brainstorm a research plan for me?\n\n        [+] click to expand"
  },
  {
    "objectID": "subs/ideation.html#feedback",
    "href": "subs/ideation.html#feedback",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can also evaluate ideas, highlighting, for example, the pros and cons of different hypotheses or research plans. The following example asks the LLM to list the pros and cons of working on a specific area of research. This shows that LLMs can provide useful input on different research directions.\n\n\n    \n    \n        Prompt: What are the top-3 pros and cons of working on the\neconomics of AGI? \n    \n\n    \n\n    \n  Response (GPT-4):\n[+] click to expand\n\n    Pros of Working on the Economics of AGI:\n\n1. High Impact: The development of AGI (Artificial General Intelligence) \nhas the potential to revolutionize many sectors of the economy, from \nhealthcare to finance to transportation. Working on the economics \nof AGI allows you to be at the forefront of this transformation and \npotentially shape its direction.\n\n2. Interdisciplinary Approach: The economics of AGI involves a combination \nof economics, computer science, and philosophy, among other disciplines. \nThis interdisciplinary approach can be intellectually stimulating \nand rewarding.\n\n3. Potential for Innovation: Given that AGI is a relatively new and \nrapidly evolving field, there is a lot of room for innovative thinking \nand novel approaches. This can be exciting and fulfilling for those \nwho enjoy problem-solving and creative thinking.\n\nCons of Working on the Economics of AGI:\n\n1. Uncertainty: The future of AGI is highly uncertain, making it difficult \nto make accurate predictions or develop robust economic models. This \nuncertainty can make the work challenging and sometimes frustrating.\n\n2. Ethical and Societal Implications: The development and deployment \nof AGI raise a host of ethical and societal issues, from job displacement \nto privacy concerns to potential misuse. Working on the economics \nof AGI means grappling with these complex and often contentious issues.\n\n3. Limited Data: Given that AGI is still in its early stages, there \nis limited data available for economic analysis. This lack of data \ncan make it difficult to test hypotheses or draw definitive conclusions.\n\n\n\n\n\n\n   \n\nWhat is particularly useful is to iterate between brainstorming and evaluation. Similar to how a researcher comes up with ideas, selects the most promising ones, and refines them, LLMs can be prompted to brainstorm, select which ideas it rates as the most promising, and brainstorm further on them.\nThe long context window of Claude 2 makes it possible to upload entire research papers into the LLM and ask for feedback. I fed the Feb.~2023 NBER working paper version of this paper  into Claude 2 and asked it the following:\n\n\n    \n    \n          Prompt:  Can you suggest ways to improve this paper? [Attachment: w30957.pdf] \n    \n\n    \n\n    \n  Response (Claude 2):  Here are some suggestions for improving the paper on large language models and cognitive automation: \n[+] click to expand\n\n\n    Provide more specific details and examples when describing the different use cases. For some of them, the explanations are a bit vague. Adding more concrete illustrations would strengthen those sections.\n    Expand the discussion of the limitations and potential downsides of over-relying on LLMs. The paper focuses mostly on the benefits, but more balance discussing the risks would be helpful.\n    Strengthen the analysis of the long-term implications. The outlook section is thought-provoking but remains speculative. Adding more rigorous analysis to back up the predictions could make it more convincing.\n    Consider testing the use cases on multiple LLMs and comparing their capabilities. The examples all seem to use a single LLM, but testing different ones could reveal variation in strengths/weaknesses.\n    Provide guidance on how to properly evaluate LLM outputs before using them. Since LLMs can make mistakes, some tips on double-checking the results would be useful.\n    (Additional suggestions omitted for space reasons)\n\nIn general, providing more specifics, analysis, examples, and structure could take the paper from a promising start to a more polished and convincing final product. Let me know if you would like me to elaborate on any of these suggestions!\n\n\n\n\n\n    \n    \n          Analysis:  All of the listed bullet points are good suggestions, and I have incorporated several of them in the paper during the revision process.  \n    \n  \n\n\n   \n\nSince Claude 2 can hold the content of the entire paper in its memory, it can offer comments on any parts of it if requested.\n\n    \n    \n        The following are additional examples of useful prompts:\n         \n    What are the main strengths and weaknesses of this paper?\n    What are the main novel ideas in the paper that are not sufficiently emphasized?\n    Can you identify any instances of bias in this paper?\n    How could I improve section {insert number}?\n    Can you draft a referee report for this paper for the Journal of Economic Literature?\n\n\n        [+] click to expand"
  },
  {
    "objectID": "subs/math.html",
    "href": "subs/math.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "The ability of general-purpose LLMs to perform mathematical derivations are growing but still limited at this point.\n        \n        \n            The reasons for the relatively poor performance include that the training data for current LLMs is mostly text-based and includes comparatively little math, and that math requires high-level abstractions that are still difficult for current systems. \n             develop a dataset of graduate-level mathematical questions and show that GPT3.5’s mathematical abilities are significantly below those of an average mathematics graduate student—perhaps providing some solace for the short term. However, \n             show that LLMs can also be fine-tuned for mathematical tasks. Moreover, there have been noticeable performance gains in math going from GPT-3.5 to GPT-4, as documented, e.g., by \n            . Moreover, datasets like the one created by \n             will certainly be useful for making future LLMs better at math. This is an area in which further progress would be very valuable for researchers.\n        \n        [+]\n    \n\n\n    \n        \n            OpenAI's o1 model marks a breakthrough in this sphere. The mistakes of older LLMs that are illustrated in the text below are no longer a challenge for this cutting-edge model. The ongoing advances in reasoning suggest that LLMs will continue to become better at math.\n        \n    \n\n\n\n\nThe following prompt is an example of how LLMs can be useful for setting up economic models. I prompted the LLM to generate LaTeX code that I could directly paste into my editor, generating the results shown below.\n\n    \n        Prompt (GPT-4): Set up the optimization problem of a consumer with CES preferences over two goods in LaTeX code.\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        The optimization problem of a consumer with CES (Constant Elasticity of Substitution) preferences over two goods can be set up as follows in LaTeX code:\n        $$\n        \\begin{aligned} \n        & \\underset{x_{1},x_{2}}{\\text{maximize}} & & \\left(\\alpha x_{1}^{\\rho}+(1-\\alpha)x_{2}^{\\rho}\\right)^{\\frac{1}{\\rho}} \\\\[8pt]\n        & \\text{subject to} & & p_{1}x_{1}+p_{2}x_{2}\\leq M,\n        \\end{aligned}\n        $$\n        \n            In this problem, the consumer is trying to maximize their utility function, which is represented by a CES function. The variables \\( x_{1} \\) and \\( x_{2} \\) represent the quantities of the two goods that the consumer chooses. The parameters \\( \\alpha \\) and \\( \\rho \\) are the CES preference parameters, \\( p_{1} \\) and \\( p_{2} \\) are the prices of the two goods, and \\( M \\) is the consumer's income. The constraint represents the consumer's budget constraint.\n        \n    \n\n\n    \n        \n            Analysis: At the time of writing, cutting-edge LLMs were capable of generating the type of model setups that are commonly used in, for example, undergraduate problem sets. This is useful because the results appear in seconds and save time typing.\n        \n    \n\n\n\n\n\nLLMs also have some limited ability to derive equations. Continuing on the example above, I asked the LLM to solve the optimization problem that it set up:\n\n    \n        \n            Follup-up Prompt (GPT-4): Solve the optimization problem.\n        \n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        To solve this optimization problem, we need to use the Lagrangian method. The Lagrangian function is:\n        $$\n        \\mathcal{L}(x_1, x_2, \\lambda) = \\left( \\alpha x_1^\\rho + (1-\\alpha) x_2^\\rho \\right)^{\\frac{1}{\\rho}} + \\lambda(M - p_1x_1 - p_2x_2)\n        $$\n        We then take the first order conditions by differentiating the Lagrangian with respect to \\(x_1\\), \\(x_2\\), and \\(\\lambda\\) and setting the derivatives equal to zero:\n        $$\n        \\begin{aligned} \n        \\frac{\\partial \\mathcal{L}}{\\partial x_1} &= \\alpha x_1^{\\rho-1}\\left(\\alpha x_1^\\rho + (1-\\alpha)x_2^\\rho\\right)^{\\frac{1}{\\rho}-1} - \\lambda p_1 = 0, \\\\[8pt]\n        \\frac{\\partial \\mathcal{L}}{\\partial x_2} &= (1-\\alpha)x_2^{\\rho-1}\\left(\\alpha x_1^\\rho + (1-\\alpha)x_2^\\rho\\right)^{\\frac{1}{\\rho}-1} - \\lambda p_2 = 0, \\\\[8pt]\n        \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &= M - p_1x_1 - p_2x_2 = 0.\n        \\end{aligned}\n        $$\n        Solving these equations simultaneously will give the optimal quantities of \\(x_1\\) and \\(x_2\\) that maximize the consumer's utility subject to their budget constraint.\n\n        The solution will depend on the specific values of the parameters and the income and prices.\n    \n\n\nSo far, the first-order conditions obtained are correct.\n\n    \n        Follow-up Prompt (GPT-4): Derive the demand functions.\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        To derive the demand functions, we can use the first-order conditions. Divide the first equation by the second to get:\n        $$\n        \\frac{x_1^{\\rho-1}}{x_2^{\\rho-1}} = \\frac{p_1}{p_2}\n        $$\n        (Author's note: the term \\( \\frac{\\alpha}{1-\\alpha} \\) is omitted here.)\n        Rearranging gives:\n        $$\n        \\frac{x_1}{x_2} = \\left(\\frac{p_1}{p_2}\\right)^{\\frac{1}{\\rho-1}}\n        $$\n        Substitute this into the budget constraint \\( M = p_1x_1 + p_2x_2 \\) to get:\n        $$\n        M = p_1x_1 + p_2x_1\\left(\\frac{p_2}{p_1}\\right)^{\\frac{1}{\\rho-1}}\n        $$\n        Solving for \\( x_1 \\) gives the demand function for good 1:\n        $$\n        x_1 = \\frac{M}{p_1 + p_2\\left(\\frac{p_2}{p_1}\\right)^{\\frac{1}{\\rho-1}}}\n        $$\n        Similarly, we can derive the demand function for good 2:\n        $$\n        x_2 = \\frac{M}{p_2 + p_1\\left(\\frac{p_1}{p_2}\\right)^{\\frac{1}{\\rho-1}}}\n        $$\n        These are the Marshallian demand functions for goods 1 and 2.\n    \n\n\n    \n        \n            Analysis: As the example illustrates, LLMs still routinely make mistakes in mathematical derivations. I entered \"When you divided the two equations, you forgot the alpha terms.\" The LLM proceeded to re-derive the results, corrected the mistake, but made a mistake in the following line. This underlines that current LLMs do not possess the high-level abstract representations necessary to perform math at a consistent level. They can serve, at best, as a writing assistant that quickly types lots of math but needs very careful oversight and potential editing.\n        \n    \n\n\n\n\n\nCurrent LLMs also have some ability to explain simple models. This may be useful – but also risky – for students. In the following example, I pasted LaTeX code into the LLM and asked it to explain the underlying model and the steps in deriving a solution:\n\n    \n        \n            Prompt (GPT-4): Can you explain what this model is, how to get from one step to the next, and what the intuition for each step is?\n        \n        \n            [Equations pasted in LaTeX format]\n            $$\n            \\begin{aligned} \n            & \\underset{{C(t), K(t)}}{max} & & \\int_0^\\infty e^{-\\rho t} U(C(t)) dt \\\\[6pt] \n            & \\text{s.t.} & & \\dot{K}(t) = F(K(t), L) - \\delta K(t) - C(t) \\\\[6pt]\n            & & & K(0)\\text{ given} \\\\[6pt]\n            & & & \\lim_{t \\to \\infty} K(t) e^{-\\rho t} \\geq 0 \n            \\end{aligned}\n            $$\n            $$\n            \\mathcal{H}(t,K(t), C(t), \\lambda(t)) = e^{-\\rho t} U(C(t)) + \\lambda(t)[F(K(t), L) - \\delta K(t) - C(t)]\n            $$\n            $$\n            \\begin{aligned} \n            & \\frac{\\partial \\mathcal{H}}{\\partial C(t)} = 0 \\Rightarrow U'(C(t)) = \\lambda(t)  \\\\[6pt] \n            & \\frac{\\partial \\mathcal{H}}{\\partial K(t)} + \\dot{\\lambda}(t) = 0 \\Rightarrow \\dot{\\lambda}(t) = -\\lambda(t)[F'(K(t), L) - \\delta] \\\\[6pt] \n            & \\lim_{t \\to \\infty} \\lambda(t) K(t) = 0 \n            \\end{aligned}\n            $$\n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        This is a model of optimal consumption and capital accumulation, often referred to as the Ramsey-Cass-Koopmans model in economics. It is a continuous-time version of the neoclassical growth model, where a representative agent chooses consumption and capital accumulation paths to maximize lifetime utility.\n\n        The agent's utility is discounted over time at rate \\( \\rho \\), and depends on consumption \\( C(t) \\) according to the utility function \\( U(C(t)) \\). The agent's capital stock \\( K(t) \\) evolves according to the law of motion given by the differential equation, where \\( F(K(t),L) \\) is the production function, \\( \\delta \\) is the depreciation rate of capital, and \\( C(t) \\) is consumption.\n\n        The Hamiltonian function, denoted by \\( \\mathcal{H}(t,K(t),C(t),\\lambda(t)) \\), is a tool used in optimal control theory to solve this kind of dynamic optimization problem. It is a function of time \\( t \\), state variable \\( K(t) \\), control variable \\( C(t) \\), and costate variable \\( \\lambda(t) \\), which is the shadow price of capital.\n\n        The first-order conditions for the optimal control problem are derived by taking derivatives of the Hamiltonian with respect to the control and state variables, and setting them equal to zero. These conditions characterize the optimal paths of consumption and capital over time.\n\n        The first condition \\( U'(C(t))=\\lambda(t) \\) implies that the marginal utility of consumption is equal to the shadow price of capital. This means that the agent is indifferent between consuming an additional unit of output and saving it to increase the capital stock.\n\n        The second condition, the costate equation, describes the evolution of the shadow price of capital over time. It says that the rate of change of the shadow price is equal to the negative of the shadow price times the marginal product of capital net of depreciation. This reflects the trade-off between consuming today and saving for future consumption.\n\n        The transversality condition, \\( \\lim_{t \\to \\infty} \\lambda(t)K(t)=0 \\), ensures that the agent does not accumulate an infinite amount of capital, which would not be optimal because of the assumption of diminishing marginal utility of consumption. This condition rules out paths where the agent accumulates capital indefinitely and never consumes it.\n    \n\n\n\n    \n    \n        Analysis: The LLM correctly identified the model described in the math and explained the derivations mostly correctly, except for one small point, highlighted in bold: the LLM incorrectly suggested that the derivative of the Hamiltonian with respect to state variables be set to zero. While most of the explanation is useful, it is likely that many students will resort to LLMs for tutoring on examples like this. However, this approach carries the risk of encountering incorrect information—the LLM is not an infallible tutor."
  },
  {
    "objectID": "subs/math.html#setting-up-models",
    "href": "subs/math.html#setting-up-models",
    "title": "Applications of LLMs",
    "section": "",
    "text": "The following prompt is an example of how LLMs can be useful for setting up economic models. I prompted the LLM to generate LaTeX code that I could directly paste into my editor, generating the results shown below.\n\n    \n        Prompt (GPT-4): Set up the optimization problem of a consumer with CES preferences over two goods in LaTeX code.\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        The optimization problem of a consumer with CES (Constant Elasticity of Substitution) preferences over two goods can be set up as follows in LaTeX code:\n        $$\n        \\begin{aligned} \n        & \\underset{x_{1},x_{2}}{\\text{maximize}} & & \\left(\\alpha x_{1}^{\\rho}+(1-\\alpha)x_{2}^{\\rho}\\right)^{\\frac{1}{\\rho}} \\\\[8pt]\n        & \\text{subject to} & & p_{1}x_{1}+p_{2}x_{2}\\leq M,\n        \\end{aligned}\n        $$\n        \n            In this problem, the consumer is trying to maximize their utility function, which is represented by a CES function. The variables \\( x_{1} \\) and \\( x_{2} \\) represent the quantities of the two goods that the consumer chooses. The parameters \\( \\alpha \\) and \\( \\rho \\) are the CES preference parameters, \\( p_{1} \\) and \\( p_{2} \\) are the prices of the two goods, and \\( M \\) is the consumer's income. The constraint represents the consumer's budget constraint.\n        \n    \n\n\n    \n        \n            Analysis: At the time of writing, cutting-edge LLMs were capable of generating the type of model setups that are commonly used in, for example, undergraduate problem sets. This is useful because the results appear in seconds and save time typing."
  },
  {
    "objectID": "subs/math.html#deriving-equations",
    "href": "subs/math.html#deriving-equations",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs also have some limited ability to derive equations. Continuing on the example above, I asked the LLM to solve the optimization problem that it set up:\n\n    \n        \n            Follup-up Prompt (GPT-4): Solve the optimization problem.\n        \n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        To solve this optimization problem, we need to use the Lagrangian method. The Lagrangian function is:\n        $$\n        \\mathcal{L}(x_1, x_2, \\lambda) = \\left( \\alpha x_1^\\rho + (1-\\alpha) x_2^\\rho \\right)^{\\frac{1}{\\rho}} + \\lambda(M - p_1x_1 - p_2x_2)\n        $$\n        We then take the first order conditions by differentiating the Lagrangian with respect to \\(x_1\\), \\(x_2\\), and \\(\\lambda\\) and setting the derivatives equal to zero:\n        $$\n        \\begin{aligned} \n        \\frac{\\partial \\mathcal{L}}{\\partial x_1} &= \\alpha x_1^{\\rho-1}\\left(\\alpha x_1^\\rho + (1-\\alpha)x_2^\\rho\\right)^{\\frac{1}{\\rho}-1} - \\lambda p_1 = 0, \\\\[8pt]\n        \\frac{\\partial \\mathcal{L}}{\\partial x_2} &= (1-\\alpha)x_2^{\\rho-1}\\left(\\alpha x_1^\\rho + (1-\\alpha)x_2^\\rho\\right)^{\\frac{1}{\\rho}-1} - \\lambda p_2 = 0, \\\\[8pt]\n        \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &= M - p_1x_1 - p_2x_2 = 0.\n        \\end{aligned}\n        $$\n        Solving these equations simultaneously will give the optimal quantities of \\(x_1\\) and \\(x_2\\) that maximize the consumer's utility subject to their budget constraint.\n\n        The solution will depend on the specific values of the parameters and the income and prices.\n    \n\n\nSo far, the first-order conditions obtained are correct.\n\n    \n        Follow-up Prompt (GPT-4): Derive the demand functions.\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        To derive the demand functions, we can use the first-order conditions. Divide the first equation by the second to get:\n        $$\n        \\frac{x_1^{\\rho-1}}{x_2^{\\rho-1}} = \\frac{p_1}{p_2}\n        $$\n        (Author's note: the term \\( \\frac{\\alpha}{1-\\alpha} \\) is omitted here.)\n        Rearranging gives:\n        $$\n        \\frac{x_1}{x_2} = \\left(\\frac{p_1}{p_2}\\right)^{\\frac{1}{\\rho-1}}\n        $$\n        Substitute this into the budget constraint \\( M = p_1x_1 + p_2x_2 \\) to get:\n        $$\n        M = p_1x_1 + p_2x_1\\left(\\frac{p_2}{p_1}\\right)^{\\frac{1}{\\rho-1}}\n        $$\n        Solving for \\( x_1 \\) gives the demand function for good 1:\n        $$\n        x_1 = \\frac{M}{p_1 + p_2\\left(\\frac{p_2}{p_1}\\right)^{\\frac{1}{\\rho-1}}}\n        $$\n        Similarly, we can derive the demand function for good 2:\n        $$\n        x_2 = \\frac{M}{p_2 + p_1\\left(\\frac{p_1}{p_2}\\right)^{\\frac{1}{\\rho-1}}}\n        $$\n        These are the Marshallian demand functions for goods 1 and 2.\n    \n\n\n    \n        \n            Analysis: As the example illustrates, LLMs still routinely make mistakes in mathematical derivations. I entered \"When you divided the two equations, you forgot the alpha terms.\" The LLM proceeded to re-derive the results, corrected the mistake, but made a mistake in the following line. This underlines that current LLMs do not possess the high-level abstract representations necessary to perform math at a consistent level. They can serve, at best, as a writing assistant that quickly types lots of math but needs very careful oversight and potential editing."
  },
  {
    "objectID": "subs/math.html#explaining-models",
    "href": "subs/math.html#explaining-models",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Current LLMs also have some ability to explain simple models. This may be useful – but also risky – for students. In the following example, I pasted LaTeX code into the LLM and asked it to explain the underlying model and the steps in deriving a solution:\n\n    \n        \n            Prompt (GPT-4): Can you explain what this model is, how to get from one step to the next, and what the intuition for each step is?\n        \n        \n            [Equations pasted in LaTeX format]\n            $$\n            \\begin{aligned} \n            & \\underset{{C(t), K(t)}}{max} & & \\int_0^\\infty e^{-\\rho t} U(C(t)) dt \\\\[6pt] \n            & \\text{s.t.} & & \\dot{K}(t) = F(K(t), L) - \\delta K(t) - C(t) \\\\[6pt]\n            & & & K(0)\\text{ given} \\\\[6pt]\n            & & & \\lim_{t \\to \\infty} K(t) e^{-\\rho t} \\geq 0 \n            \\end{aligned}\n            $$\n            $$\n            \\mathcal{H}(t,K(t), C(t), \\lambda(t)) = e^{-\\rho t} U(C(t)) + \\lambda(t)[F(K(t), L) - \\delta K(t) - C(t)]\n            $$\n            $$\n            \\begin{aligned} \n            & \\frac{\\partial \\mathcal{H}}{\\partial C(t)} = 0 \\Rightarrow U'(C(t)) = \\lambda(t)  \\\\[6pt] \n            & \\frac{\\partial \\mathcal{H}}{\\partial K(t)} + \\dot{\\lambda}(t) = 0 \\Rightarrow \\dot{\\lambda}(t) = -\\lambda(t)[F'(K(t), L) - \\delta] \\\\[6pt] \n            & \\lim_{t \\to \\infty} \\lambda(t) K(t) = 0 \n            \\end{aligned}\n            $$\n        \n        [+] click to expand\n    \n\n    \n\n    Response (GPT-4):\n    [+] click to expand\n    \n        This is a model of optimal consumption and capital accumulation, often referred to as the Ramsey-Cass-Koopmans model in economics. It is a continuous-time version of the neoclassical growth model, where a representative agent chooses consumption and capital accumulation paths to maximize lifetime utility.\n\n        The agent's utility is discounted over time at rate \\( \\rho \\), and depends on consumption \\( C(t) \\) according to the utility function \\( U(C(t)) \\). The agent's capital stock \\( K(t) \\) evolves according to the law of motion given by the differential equation, where \\( F(K(t),L) \\) is the production function, \\( \\delta \\) is the depreciation rate of capital, and \\( C(t) \\) is consumption.\n\n        The Hamiltonian function, denoted by \\( \\mathcal{H}(t,K(t),C(t),\\lambda(t)) \\), is a tool used in optimal control theory to solve this kind of dynamic optimization problem. It is a function of time \\( t \\), state variable \\( K(t) \\), control variable \\( C(t) \\), and costate variable \\( \\lambda(t) \\), which is the shadow price of capital.\n\n        The first-order conditions for the optimal control problem are derived by taking derivatives of the Hamiltonian with respect to the control and state variables, and setting them equal to zero. These conditions characterize the optimal paths of consumption and capital over time.\n\n        The first condition \\( U'(C(t))=\\lambda(t) \\) implies that the marginal utility of consumption is equal to the shadow price of capital. This means that the agent is indifferent between consuming an additional unit of output and saving it to increase the capital stock.\n\n        The second condition, the costate equation, describes the evolution of the shadow price of capital over time. It says that the rate of change of the shadow price is equal to the negative of the shadow price times the marginal product of capital net of depreciation. This reflects the trade-off between consuming today and saving for future consumption.\n\n        The transversality condition, \\( \\lim_{t \\to \\infty} \\lambda(t)K(t)=0 \\), ensures that the agent does not accumulate an infinite amount of capital, which would not be optimal because of the assumption of diminishing marginal utility of consumption. This condition rules out paths where the agent accumulates capital indefinitely and never consumes it.\n    \n\n\n\n    \n    \n        Analysis: The LLM correctly identified the model described in the math and explained the derivations mostly correctly, except for one small point, highlighted in bold: the LLM incorrectly suggested that the derivative of the Hamiltonian with respect to state variables be set to zero. While most of the explanation is useful, it is likely that many students will resort to LLMs for tutoring on examples like this. However, this approach carries the risk of encountering incorrect information—the LLM is not an infallible tutor."
  },
  {
    "objectID": "subs/coding.html",
    "href": "subs/coding.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs are quite capable at coding tasks, especially in the languages Python and R, for which the most online resources are available. LLMs can write, edit, modify, translate, or debug snippets of code based on instructions in plain English (or other natural languages). Moreover, they can act as tutors when using new libraries, functions, or even programming languages that the user is not very familiar with\n        \n        \n            by quickly generating output that shows what libraries and functions are needed for specific types of operations or what syntactic structures to use in a given programming language. This allows the human programmer to consult the LLM and weave together code from many different snippets generated by it.\n        \n        [+]\n    \n\n\nThe reasons why LLMs are so proficient at coding include the following: There are vast repositories of code available online that are included in their training data, for example from GitHub. The syntax of computer code seems to be relatively easy to learn for these systems. Moreover, the AI labs producing cutting-edge LLMs themselves benefit from the code generation abilities of these systems, which provides them with strong incentives for improving these capabilities.\n\n    \n    \n        \n            On ChatGPT Plus, Advanced Data Analysis has made coding tasks in Python very convenient, as it can write code, execute it, learn from it, write follow-up code, and display the requested results.\n        \n        \n            While writing this paper, I used ChatGPT Plus to write LaTeX code. I asked it how to define the boxes around the sample prompts throughout the paper in a way that they are visually appealing and break across pages, and I asked it to produce Table 1 in LaTeX based on the table of contents for section 3. I used GitHub Copilot when working on the replication code for this section. \n        \n        [+]\n    \n\n\nCoding is perhaps the category of research that has derived the greatest productivity gains from the advances of the past year. Tools like Copilot or Cursor (described in the access models page) can increasingly leverage LLMs to collaborate with researchers in quickly producing high-quality code. One of the breakthroughs in recent months was OpenAI’s o1 series of models, described in the reasoning page, which can reason through a coding problem before writing up the code.\n\n\nLLMs are very useful for writing a wide variety of code, including for standard programming tasks, data manipulation and repetitive tasks. For the purposes of this paper, I prompted ChatGPT Advanced Data Analysis to simulate a classic model in economics. The model occasionally asks the user for confirmation and feedback. The following reports my exchange:\n\n\n    \n    \n         Prompt:  Simulate the Solow growth model and plot the results in four charts. \n    \n\n    \n\n    \n     Response (ChatGPT Advanced Data Analysis):   Alright, let's simulate the Solow growth model. \n    [+] click to expand\n    \n        To simplify things, let's consider the Solow-Swan model without technological progress. The model describes the evolution of capital \\( K \\), labor \\( L \\), and output \\( Y \\) in an economy. The basic equation for the change in capital stock over time is given by:\n\n$$\n\\frac{dK}{dt} = sY - \\delta K\n$$\n\nwhere:\n\n    \\( s \\) is the savings rate\n    \\( Y \\) is the total output, which is given by a production function, usually a Cobb-Douglas type: \n        $$\n        Y = K^\\alpha L^{1-\\alpha}\n        $$\n    \n    \\( \\delta \\) is the depreciation rate.\n\n\nAssumptions for the model:\n\n    Labor grows at a constant rate \\( n \\), i.e., \\( L(t) = L(0)e^{nt} \\).\n    The savings rate \\( s \\), the depreciation rate \\( \\delta \\), and the labor growth rate \\( n \\) are all constants.\n\n\nTo get started, we need to specify the values of these parameters. For example, we can use the following:\n\n    \\( s = 0.4 \\)\n    \\( \\delta = 0.1 \\)\n    \\( n = 0.02 \\)\n    \\( \\alpha = 0.33 \\)\n    Initial capital stock \\( K(0) = 1 \\)\n    Initial labor \\( L(0) = 1 \\)\n\n\nTo simulate the model, we'll use the Euler method for integrating the differential equations. This method approximates the value of the function at a future time as the value at the current time plus the derivative of the function at the current time multiplied by the time step.\n\nThen, we will plot the following four charts:\n\n    Capital over time\n    Labor over time\n    Output over time\n    Capital per worker over time\n\n\nDoes that sound good?\n\n    \n\n\nI just provided a short “Go ahead” to continue the generation of the program:\n\n\n    \n    \n         Follow-up Prompt:  Go ahead. \n    \n\n    \n\n    \n     Response (ChatGPT Advanced Data Analysis): \n    [+] click to expand\n    \n        import numpy as np\nimport matplotlib.pyplot as plt\n\n# Model parameters\ns = 0.4\ndelta = 0.1\nn = 0.02\nalpha = 0.33\nK0 = 1\nL0 = 1\nT = 100  # Total simulation time\n\n# Time grid\ndt = 0.01\ntimes = np.arange(0, T, dt)\n\n# Initialize arrays to store values of K, L, Y over time\nK = np.zeros(len(times))\nL = np.zeros(len(times))\nY = np.zeros(len(times))\n\n# Initial values\nK[0] = K0\nL[0] = L0\nY[0] = K0**alpha * L0**(1-alpha)\n\n# Euler method\nfor t in range(len(times)-1):\n    dK = s * Y[t] - delta * K[t]\n    dL = n * L[t]\n    K[t+1] = K[t] + dK * dt\n    L[t+1] = L[t] + dL * dt\n    Y[t+1] = K[t+1]**alpha * L[t+1]**(1-alpha)\n\n# Capital per worker\nK_L = K / L\n\n# Create plots\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot capital over time\naxs[0, 0].plot(times, K)\naxs[0, 0].set_title('Capital over time')\naxs[0, 0].set_xlabel('Time')\naxs[0, 0].set_ylabel('Capital')\n\n# Plot labor over time\naxs[0, 1].plot(times, L)\naxs[0, 1].set_title('Labor over time')\naxs[0, 1].set_xlabel('Time')\naxs[0, 1].set_ylabel('Labor')\n\n# Plot output over time\naxs[1, 0].plot(times, Y)\naxs[1, 0].set_title('Output over time')\naxs[1, 0].set_xlabel('Time')\naxs[1, 0].set_ylabel('Output')\n\n# Plot capital per worker over time\naxs[1, 1].plot(times, K_L)\naxs[1, 1].set_title('Capital per worker over time')\naxs[1, 1].set_xlabel('Time')\naxs[1, 1].set_ylabel('Capital per worker')\n\n# Make the layout tight\nplt.tight_layout()\nplt.show()\n        \n\n        Here are the four plots for the Solow growth model:\n        \n            Capital over time: The capital stock increases over time and approaches a steady state. (Author's note: Although the numerical simulation is correct, this point of the description is clearly wrong.)\n            Labor over time: Labor grows exponentially at a constant rate, reflecting the assumption of constant population growth in the Solow model.\n            Output over time: Output also increases over time and approaches a steady state. However, due to diminishing returns to capital, the growth of output slows down over time.\n            Capital per worker over time: Capital per worker also increases over time and approaches a steady state. In this simplified version of the model without technological progress, this growth rate is zero, so output per worker and capital per worker are constant at the steady state.\n        \n\n        These results illustrate the key predictions of the Solow growth model: in the long run, an economy approaches a steady state level of capital (both total and per worker), determined by the savings rate, depreciation rate, and population growth rate. Changes in these parameters can shift the steady state but cannot sustain long-run economic growth, which according to the model requires technological progress.\n    \n\n\n    \n    \n        \n             Analysis:  The model performed the simulation task as requested. It started with a detailed description of the Solow model, introduced parameter assumptions, asked for user approval, and wrote and executed the correct Python code. However, it also volunteered to interpret the results and incorrectly described the path of capital over time as \"approaching a steady state.\" Since it assumed positive population growth, this is clearly wrong and also contradicts the simulation displayed in the top left panel of the figure. (Advanced Data Analysis can generate figures but cannot actually \"see\" them, so it simply generated what seemed like a plausible description of the figure, thereby introducing an error.) Moreover, in a concluding paragraph, the LLM wrote: \"These results illustrate the key predictions of the Solow growth model: in the long run, an economy approaches a steady state level of capital (both total and per worker),\" which—under positive population growth—is clearly impossible.\n        \n    \n\n\nI also attempted to simulate the Ramsey model. The LLM correctly generated code to simulate the path of consumption and capital for given initial conditions, but it did not manage to solve for the correct starting point for consumption, even after I added a reminder to my prompt that initial consumption needs to lie on the stable arm of a saddle-path stable system.\n\n    \n    \n        \n            This is representative of the state of LLM coding capabilities at the time of writing—LLMs are useful assistants to automate many of the mundane parts of programming, but they require human oversight for the more difficult parts. Moreover, LLMs can also act as powerful tutors that help users find the packages and functions they need for specific use cases.\n        \n    \n\n\nCutting-edge LLMs, in particular Claude 3.5 Sonnet, also have the ability to outline a plan for how to approach coding projects. In the spirit of chain-of-thought prompting, they frequently deliver better results if first asked to outline a plan on how to code a programming task and then executing the plan.\n\n\n\nWhereas the previous example wrote code based on English language instructions, LLMs can also do the reverse and explain what a given piece of code does in plain English, akin to a tutor. The following examples demonstrates this use case:\n\n\n    \n    \n         Prompt:  What does the following function do?\n        \n            def regression(X, y):   \n    X = np.hstack((np.ones((X.shape[0], 1)), X))   \n    XtXinv = np.linalg.inv(np.dot(X.T, X))   \n    beta1 = np.dot(np.dot(XtXinv, X.T), y)   \n    residuals = y - np.dot(X, beta1)    \n    V = np.diag(residuals**2)   \n    Vinv = np.linalg.inv(V)   \n    XtVinvXinv = np.linalg.inv(np.dot(X.T, np.dot(Vinv, X)))   \n    beta2 = np.dot(np.dot(XtVinvXinv, X.T), np.dot(Vinv, y))   \n    return beta1, beta2\n            \n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  This function performs a two-step generalized least squares regression. \n    [+] click to expand\n    \n        In the first step, it performs an ordinary least squares regression to estimate the parameters (beta1) of the model.\n\n        In the second step, it uses the residuals from the first step to estimate the variance of the errors, and then performs a weighted least squares regression to estimate the parameters (beta2) of the model, taking into account the heteroscedasticity (non-constant variance) of the errors.\n\n        The function returns the estimated parameters from both steps.\n    \n\n\n    \n    \n        \n             Analysis:  This functionality is particularly useful when using sources that have not documented their code well.\n        \n    \n\n\n\n\n\nLLMs can also convert code in one programming language into another language, for example to port a project to another platform or to integrate code snippets found in an online coding forum such as StackExchange that is in the wrong language.\nThe following prompt, building on the preceding conversation, provides an example:\n\n\n    \n    \n         Follow-up Prompt:  Can you translate the function into MATLAB? \n    \n\n    \n\n    \n     Response (GPT-4):  Sure, here is the equivalent MATLAB code for the function: \n    [+] click to expand\n    \n        function [beta1, beta2] = regression(X, y)\n    X = [ones(size(X, 1), 1), X];\n    XtXinv = inv(X' * X);\n    beta1 = XtXinv * X' * y;\n    residuals = y - X * beta1;\n    V = diag(residuals.^2);\n    Vinv = inv(V);\n    XtVinvXinv = inv(X' * (Vinv * X));\n    beta2 = XtVinvXinv * X' * (Vinv * y);\nend\n        \n\n        Note: In MATLAB, the operator for matrix multiplication is *, not np.dot(). Also, the operator for element-wise power is .^, not **.\n    \n\n\n\n    \n    \n        \n             Analysis:  Current LLMs are quite reliable in translating short pieces of code across common programming languages. For longer sequences, human assistance is still required.\n        \n    \n\n\n\n\nOne of the most frustrating parts of programming is to debug code. LLMs also exhibit useful capabilities in this domain. They can not only help to interpret error messages but also verify code.\nIn my first example, I simply pasted a typical error message from python that is obtained when the user forgets to import a library, without any further instructions:\n\n\n    \n    \n         Prompt:  Traceback (most recent call last):\n        \n            File \"C:/.../test.py\", line 20, in \n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\nNameError: name 'np' is not defined\n            \n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  The error message is telling you that the name 'np' is not defined. This usually happens when you try to use a library that you haven't imported yet. \n    [+] click to expand\n    \n        In your case, 'np' is a common alias for the numpy library. You can fix the error by importing numpy at the beginning of your script. Here's how you do it:\n\n        import numpy as np\n        \n\n        After adding this line, your script will know what 'np' is and it should work as expected.\n    \n\n\n\n    \n    \n        \n             Analysis:  The LLM correctly interpreted my prompt as a request for help to debug the error. It recognized the source of the error, explained it, and provided the code needed to rectify it.\n        \n    \n\n\nThe next example, building on the python function two examples earlier but with an error introduced, illustrates how LLMs can help to catch mistakes such as typos in code:\n\n\n    \n    \n         Prompt:  Can you debug the following function? \n        \n            [Code from preceding example, with a spelling mistake introduced by changing the definition of the variable Vinv to V_inv.]\n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  The function seems to be implementing a form of weighted least squares regression, but there are a few issues with it: \n    [+] click to expand\n    \n        \n            The function uses NumPy functions and methods, but NumPy is not imported. You need to import NumPy at the beginning of your script.\n            The variable Vinv is not defined. It seems like it should be V_inv.\n        \n\n        Here is the corrected function:\n        import numpy as np\n\ndef regression(X, y):   \n    X = np.hstack((np.ones((X.shape[0], 1)), X))   \n    XtXinv = np.linalg.inv(np.dot(X.T, X))   \n    beta1 = np.dot(np.dot(XtXinv, X.T), y)   \n    residuals = y - np.dot(X, beta1)    \n    V = np.diag(residuals**2)   \n    V_inv = np.linalg.inv(V)  # Corrected variable name\n    XtVinvXinv = np.linalg.inv(np.dot(X.T, np.dot(V_inv, X)))   \n    beta2 = np.dot(np.dot(XtVinvXinv, X.T), np.dot(V_inv, y))   \n    return beta1, beta2\n        \n    \n\n\n\n    \n    \n        \n             Analysis:  The first point observes that the code does not run unless the NumPy package is imported (as in the previous example); the second point correctly caught the spelling mistake that I introduced.\n        \n    \n\n\nMore generally, LLMs are also sometimes able to detect when indices are mixed up, and to provide advice when one describes the ways in which a program malfunctions. They are less capable at detecting high-level mistakes in the algorithms underlying code – for this, human debugging is usually still required."
  },
  {
    "objectID": "subs/coding.html#writing-code",
    "href": "subs/coding.html#writing-code",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs are very useful for writing a wide variety of code, including for standard programming tasks, data manipulation and repetitive tasks. For the purposes of this paper, I prompted ChatGPT Advanced Data Analysis to simulate a classic model in economics. The model occasionally asks the user for confirmation and feedback. The following reports my exchange:\n\n\n    \n    \n         Prompt:  Simulate the Solow growth model and plot the results in four charts. \n    \n\n    \n\n    \n     Response (ChatGPT Advanced Data Analysis):   Alright, let's simulate the Solow growth model. \n    [+] click to expand\n    \n        To simplify things, let's consider the Solow-Swan model without technological progress. The model describes the evolution of capital \\( K \\), labor \\( L \\), and output \\( Y \\) in an economy. The basic equation for the change in capital stock over time is given by:\n\n$$\n\\frac{dK}{dt} = sY - \\delta K\n$$\n\nwhere:\n\n    \\( s \\) is the savings rate\n    \\( Y \\) is the total output, which is given by a production function, usually a Cobb-Douglas type: \n        $$\n        Y = K^\\alpha L^{1-\\alpha}\n        $$\n    \n    \\( \\delta \\) is the depreciation rate.\n\n\nAssumptions for the model:\n\n    Labor grows at a constant rate \\( n \\), i.e., \\( L(t) = L(0)e^{nt} \\).\n    The savings rate \\( s \\), the depreciation rate \\( \\delta \\), and the labor growth rate \\( n \\) are all constants.\n\n\nTo get started, we need to specify the values of these parameters. For example, we can use the following:\n\n    \\( s = 0.4 \\)\n    \\( \\delta = 0.1 \\)\n    \\( n = 0.02 \\)\n    \\( \\alpha = 0.33 \\)\n    Initial capital stock \\( K(0) = 1 \\)\n    Initial labor \\( L(0) = 1 \\)\n\n\nTo simulate the model, we'll use the Euler method for integrating the differential equations. This method approximates the value of the function at a future time as the value at the current time plus the derivative of the function at the current time multiplied by the time step.\n\nThen, we will plot the following four charts:\n\n    Capital over time\n    Labor over time\n    Output over time\n    Capital per worker over time\n\n\nDoes that sound good?\n\n    \n\n\nI just provided a short “Go ahead” to continue the generation of the program:\n\n\n    \n    \n         Follow-up Prompt:  Go ahead. \n    \n\n    \n\n    \n     Response (ChatGPT Advanced Data Analysis): \n    [+] click to expand\n    \n        import numpy as np\nimport matplotlib.pyplot as plt\n\n# Model parameters\ns = 0.4\ndelta = 0.1\nn = 0.02\nalpha = 0.33\nK0 = 1\nL0 = 1\nT = 100  # Total simulation time\n\n# Time grid\ndt = 0.01\ntimes = np.arange(0, T, dt)\n\n# Initialize arrays to store values of K, L, Y over time\nK = np.zeros(len(times))\nL = np.zeros(len(times))\nY = np.zeros(len(times))\n\n# Initial values\nK[0] = K0\nL[0] = L0\nY[0] = K0**alpha * L0**(1-alpha)\n\n# Euler method\nfor t in range(len(times)-1):\n    dK = s * Y[t] - delta * K[t]\n    dL = n * L[t]\n    K[t+1] = K[t] + dK * dt\n    L[t+1] = L[t] + dL * dt\n    Y[t+1] = K[t+1]**alpha * L[t+1]**(1-alpha)\n\n# Capital per worker\nK_L = K / L\n\n# Create plots\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot capital over time\naxs[0, 0].plot(times, K)\naxs[0, 0].set_title('Capital over time')\naxs[0, 0].set_xlabel('Time')\naxs[0, 0].set_ylabel('Capital')\n\n# Plot labor over time\naxs[0, 1].plot(times, L)\naxs[0, 1].set_title('Labor over time')\naxs[0, 1].set_xlabel('Time')\naxs[0, 1].set_ylabel('Labor')\n\n# Plot output over time\naxs[1, 0].plot(times, Y)\naxs[1, 0].set_title('Output over time')\naxs[1, 0].set_xlabel('Time')\naxs[1, 0].set_ylabel('Output')\n\n# Plot capital per worker over time\naxs[1, 1].plot(times, K_L)\naxs[1, 1].set_title('Capital per worker over time')\naxs[1, 1].set_xlabel('Time')\naxs[1, 1].set_ylabel('Capital per worker')\n\n# Make the layout tight\nplt.tight_layout()\nplt.show()\n        \n\n        Here are the four plots for the Solow growth model:\n        \n            Capital over time: The capital stock increases over time and approaches a steady state. (Author's note: Although the numerical simulation is correct, this point of the description is clearly wrong.)\n            Labor over time: Labor grows exponentially at a constant rate, reflecting the assumption of constant population growth in the Solow model.\n            Output over time: Output also increases over time and approaches a steady state. However, due to diminishing returns to capital, the growth of output slows down over time.\n            Capital per worker over time: Capital per worker also increases over time and approaches a steady state. In this simplified version of the model without technological progress, this growth rate is zero, so output per worker and capital per worker are constant at the steady state.\n        \n\n        These results illustrate the key predictions of the Solow growth model: in the long run, an economy approaches a steady state level of capital (both total and per worker), determined by the savings rate, depreciation rate, and population growth rate. Changes in these parameters can shift the steady state but cannot sustain long-run economic growth, which according to the model requires technological progress.\n    \n\n\n    \n    \n        \n             Analysis:  The model performed the simulation task as requested. It started with a detailed description of the Solow model, introduced parameter assumptions, asked for user approval, and wrote and executed the correct Python code. However, it also volunteered to interpret the results and incorrectly described the path of capital over time as \"approaching a steady state.\" Since it assumed positive population growth, this is clearly wrong and also contradicts the simulation displayed in the top left panel of the figure. (Advanced Data Analysis can generate figures but cannot actually \"see\" them, so it simply generated what seemed like a plausible description of the figure, thereby introducing an error.) Moreover, in a concluding paragraph, the LLM wrote: \"These results illustrate the key predictions of the Solow growth model: in the long run, an economy approaches a steady state level of capital (both total and per worker),\" which—under positive population growth—is clearly impossible.\n        \n    \n\n\nI also attempted to simulate the Ramsey model. The LLM correctly generated code to simulate the path of consumption and capital for given initial conditions, but it did not manage to solve for the correct starting point for consumption, even after I added a reminder to my prompt that initial consumption needs to lie on the stable arm of a saddle-path stable system.\n\n    \n    \n        \n            This is representative of the state of LLM coding capabilities at the time of writing—LLMs are useful assistants to automate many of the mundane parts of programming, but they require human oversight for the more difficult parts. Moreover, LLMs can also act as powerful tutors that help users find the packages and functions they need for specific use cases.\n        \n    \n\n\nCutting-edge LLMs, in particular Claude 3.5 Sonnet, also have the ability to outline a plan for how to approach coding projects. In the spirit of chain-of-thought prompting, they frequently deliver better results if first asked to outline a plan on how to code a programming task and then executing the plan."
  },
  {
    "objectID": "subs/coding.html#explaining-code",
    "href": "subs/coding.html#explaining-code",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Whereas the previous example wrote code based on English language instructions, LLMs can also do the reverse and explain what a given piece of code does in plain English, akin to a tutor. The following examples demonstrates this use case:\n\n\n    \n    \n         Prompt:  What does the following function do?\n        \n            def regression(X, y):   \n    X = np.hstack((np.ones((X.shape[0], 1)), X))   \n    XtXinv = np.linalg.inv(np.dot(X.T, X))   \n    beta1 = np.dot(np.dot(XtXinv, X.T), y)   \n    residuals = y - np.dot(X, beta1)    \n    V = np.diag(residuals**2)   \n    Vinv = np.linalg.inv(V)   \n    XtVinvXinv = np.linalg.inv(np.dot(X.T, np.dot(Vinv, X)))   \n    beta2 = np.dot(np.dot(XtVinvXinv, X.T), np.dot(Vinv, y))   \n    return beta1, beta2\n            \n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  This function performs a two-step generalized least squares regression. \n    [+] click to expand\n    \n        In the first step, it performs an ordinary least squares regression to estimate the parameters (beta1) of the model.\n\n        In the second step, it uses the residuals from the first step to estimate the variance of the errors, and then performs a weighted least squares regression to estimate the parameters (beta2) of the model, taking into account the heteroscedasticity (non-constant variance) of the errors.\n\n        The function returns the estimated parameters from both steps.\n    \n\n\n    \n    \n        \n             Analysis:  This functionality is particularly useful when using sources that have not documented their code well."
  },
  {
    "objectID": "subs/coding.html#translating-code",
    "href": "subs/coding.html#translating-code",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can also convert code in one programming language into another language, for example to port a project to another platform or to integrate code snippets found in an online coding forum such as StackExchange that is in the wrong language.\nThe following prompt, building on the preceding conversation, provides an example:\n\n\n    \n    \n         Follow-up Prompt:  Can you translate the function into MATLAB? \n    \n\n    \n\n    \n     Response (GPT-4):  Sure, here is the equivalent MATLAB code for the function: \n    [+] click to expand\n    \n        function [beta1, beta2] = regression(X, y)\n    X = [ones(size(X, 1), 1), X];\n    XtXinv = inv(X' * X);\n    beta1 = XtXinv * X' * y;\n    residuals = y - X * beta1;\n    V = diag(residuals.^2);\n    Vinv = inv(V);\n    XtVinvXinv = inv(X' * (Vinv * X));\n    beta2 = XtVinvXinv * X' * (Vinv * y);\nend\n        \n\n        Note: In MATLAB, the operator for matrix multiplication is *, not np.dot(). Also, the operator for element-wise power is .^, not **.\n    \n\n\n\n    \n    \n        \n             Analysis:  Current LLMs are quite reliable in translating short pieces of code across common programming languages. For longer sequences, human assistance is still required."
  },
  {
    "objectID": "subs/coding.html#debugging-code",
    "href": "subs/coding.html#debugging-code",
    "title": "Applications of LLMs",
    "section": "",
    "text": "One of the most frustrating parts of programming is to debug code. LLMs also exhibit useful capabilities in this domain. They can not only help to interpret error messages but also verify code.\nIn my first example, I simply pasted a typical error message from python that is obtained when the user forgets to import a library, without any further instructions:\n\n\n    \n    \n         Prompt:  Traceback (most recent call last):\n        \n            File \"C:/.../test.py\", line 20, in \n    X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\nNameError: name 'np' is not defined\n            \n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  The error message is telling you that the name 'np' is not defined. This usually happens when you try to use a library that you haven't imported yet. \n    [+] click to expand\n    \n        In your case, 'np' is a common alias for the numpy library. You can fix the error by importing numpy at the beginning of your script. Here's how you do it:\n\n        import numpy as np\n        \n\n        After adding this line, your script will know what 'np' is and it should work as expected.\n    \n\n\n\n    \n    \n        \n             Analysis:  The LLM correctly interpreted my prompt as a request for help to debug the error. It recognized the source of the error, explained it, and provided the code needed to rectify it.\n        \n    \n\n\nThe next example, building on the python function two examples earlier but with an error introduced, illustrates how LLMs can help to catch mistakes such as typos in code:\n\n\n    \n    \n         Prompt:  Can you debug the following function? \n        \n            [Code from preceding example, with a spelling mistake introduced by changing the definition of the variable Vinv to V_inv.]\n        \n        [+] click to expand\n    \n\n    \n\n    \n     Response (GPT-4):  The function seems to be implementing a form of weighted least squares regression, but there are a few issues with it: \n    [+] click to expand\n    \n        \n            The function uses NumPy functions and methods, but NumPy is not imported. You need to import NumPy at the beginning of your script.\n            The variable Vinv is not defined. It seems like it should be V_inv.\n        \n\n        Here is the corrected function:\n        import numpy as np\n\ndef regression(X, y):   \n    X = np.hstack((np.ones((X.shape[0], 1)), X))   \n    XtXinv = np.linalg.inv(np.dot(X.T, X))   \n    beta1 = np.dot(np.dot(XtXinv, X.T), y)   \n    residuals = y - np.dot(X, beta1)    \n    V = np.diag(residuals**2)   \n    V_inv = np.linalg.inv(V)  # Corrected variable name\n    XtVinvXinv = np.linalg.inv(np.dot(X.T, np.dot(V_inv, X)))   \n    beta2 = np.dot(np.dot(XtVinvXinv, X.T), np.dot(V_inv, y))   \n    return beta1, beta2\n        \n    \n\n\n\n    \n    \n        \n             Analysis:  The first point observes that the code does not run unless the NumPy package is imported (as in the previous example); the second point correctly caught the spelling mistake that I introduced.\n        \n    \n\n\nMore generally, LLMs are also sometimes able to detect when indices are mixed up, and to provide advice when one describes the ways in which a program malfunctions. They are less capable at detecting high-level mistakes in the algorithms underlying code – for this, human debugging is usually still required."
  },
  {
    "objectID": "subs/writing.html",
    "href": "subs/writing.html",
    "title": "Applications of LLMs",
    "section": "",
    "text": "The core competency of LLMs is to generate text. This implies that they are quite capable and useful for many tasks related to writing, from synthesizing sentences based on bullet points, changing the style of text, editing text, evaluating styles to generating titles, headlines, and tweets. I cover each below.\n\n    \n    \n        Basic writing tasks do not generally require the most cutting-edge LLM available.\n         For example, to synthesize basic text, any of the models listed earlier will do a good job. However, when the LLM is asked to go beyond the immediate instructions, differences start to emerge based on the capabilities of each model. At the time of writing, tools for synthesizing text are also starting to be included in office packages such as MS Office and Google Workspace as well as the associated email programs Outlook and Gmail. Alternatively, a dedicated writing assistant that offers plugins for many common applications (including web browsers and office packages) and that suggests corrections and stylistic improvements as the user is typing is grammarly.com. \n        [+]\n    \n  \n\n\nOne of the most useful capabilities of LLMs for writing assistance may be to translate rough bullet points into well-structured sentences that are clear and easy to read. The following is an example. Note that the bullets also include requests for the LLM to provide examples and offer solutions.\n\n\n    \n    \n          Prompt:  Write a paragraph in the style of an academic economist that integrates the following points. Include a topic sentence. \n       \n    Large language models (LLMs) automate many cognitive tasks.\n    The work of academic economists is largely cognitive (e.g., writing research papers, conducting data analysis, generating policy recommendations, reviewing literature).\n    We economists should therefore worry about recent progress in language models.\n    In the short run, these models can help us be more productive.\n    In the long run, there is a good likelihood that they will displace human economists.\n    We should think about how to prepare. [offer solutions] \n\n\n        [+] click to expand\n    \n\n    \n\n    \n  Response (GPT-4): \n[+] click to expand\n\n    The advent of large language models (LLMs) that automate a plethora of cognitive tasks presents a significant paradigm shift that academic economists should be cognizant of, given the cognitive nature of our work, which includes tasks such as data analysis, economic forecasting, and policy recommendation. The rapid advancements in language models could potentially disrupt our profession, necessitating a proactive approach to this emerging technology. In the short term, these models can augment our productivity by automating routine tasks, thereby allowing us to focus on more complex and nuanced aspects of economic research. However, in the long run, there is a substantial likelihood that these models could displace human economists, as they become increasingly adept at performing complex cognitive tasks. Consequently, it is incumbent upon us to prepare for this eventuality. This could involve developing a deeper understanding of these models to leverage their capabilities effectively, diversifying our skill sets to include areas not easily automated, and advocating for policies that ensure a just transition for those potentially displaced by these technological advancements.\n\n\n\n\n\n    \n    \n          Analysis:  Utilizing this allows researchers to concentrate their energy on the ideas in their text as opposed to the mundane writing process. The text is generally high-quality, although some claim that it is a bit sterile and may lack the idiosyncrasies and elements of surprise that characterize human writing.This is a feature that detectors of LLM-written text zero in on, for example the \n    This is a feature that detectors of LLM-written text zero in on, for example the tool \n    \n        GPTZero\n    . However, it should be noted that such tools are not always reliable and can easily be circumvented.\n\n\n    \n    \n  \n\n\n   \n\nLLMs are very responsive to requests to write in different styles.\n\n    \n    \n        I obtained both impressive and hilarious results when I replaced \"in the style of an academic economist\" with the request to write:\n         \n    in a colloquial style\n    in a style that is comprehensible to non-economists\n    in the style of {*enter your favorite economist, politician, \n    When I requested \"in the style of a gangster,\" the LLM started with \"Listen here, see, these big shot large language models (LLMs) are muscling in on our turf...\"\n*} \n\n\n\n        [+] click to expand\n    \n  \n\n\n  \n\n\nLLMs can also write text in LaTeX format, which automatically format mathematical expressions in the required format, and it can draft beamer slides in LaTeX code based on bullet points.\nWriting is of course a skill that is not only useful for research - cognitive workers in many areas report using, e.g., ChatGPT to draft emails, memos, performance reviews, or summaries based on a few bullet points. Likewise, professors report generating the first draft of letters of recommendation or syllabi using LLMs.\n\n\n\nAnother useful capability is editing. LLMs can edit text for grammatical or spelling mistakes, style, clarity, or simplicity. This set of capabilities is useful for all writers, but perhaps most for non-native speakers who want to improve their writing. In the following example, I have bolded each correction made by the LLM for emphasis:\n\n\n   \n   \n         Prompt:  Can you correct the following sentence?  \n   These paper describe six domain in which large language models (LLMs) displays emergant capbilities that are useful to the economic research.\n\n   \n\n   \n\n   \n  Response (GPT-4): This paper describes six domains in which large language models (LLMs) display emergent capabilities that are useful for economic research.\n\n\n\n\n\n   \n   \n         Follow-up Prompt:  Can you explain the main corrections you made? \n   \n\n   \n\n   \n  Response (GPT-4):  Sure, here are the main corrections: \n[+] click to expand\n\n   \n   \"These paper\" was corrected to \"This paper\". The subject-verb agreement was incorrect. If the subject is singular (like \"paper\"), the verb should also be singular (like \"describes\").\n   \"describe\" was corrected to \"describes\". The verb should match the singular subject \"paper\".\n   \"domain\" was corrected to \"domains\". The context implies that there are multiple domains, so the plural form should be used.\n   \"displays\" was corrected to \"display\". The subject \"LLMs\" is plural, so the verb should also be plural.\n   \"emergant\" was corrected to \"emergent\". This was a spelling mistake.\n   \"to the economic research\" was corrected to \"for economic research\". The preposition \"for\" is more appropriate in this context.\n\n\n\n\n\n\n   \n   \n         Analysis:  As illustrated in the follow-up question, the LLM can also largely explain its edits so that writers can learn from any corrections it has made. This latter capability has improved significantly going from GPT-3.5 to GPT-4. Notice, however, that it left out a seventh correction from the list -- it also corrected a typo in the word \"capabilities\". This highlights the need to carefully check the results of LLMs. \n   \n \n\n\n  \n\nAnother useful LLM application is to convert text to be comprehensible to readers of different levels, for example, using a prompt like “Rewrite the following text so that it is comprehensible to an eight-year-old”, “comprehensible to an eighth-grader,” or “comprehensible to a policymaker without economics education.”\n\n\n\nLLMs can also evaluate text for its style, its clarity, or similar. The following question about a draft version of the abstract of this paper turned out to be a bit of a deflating experience:\n\n\n   \n   \n         Prompt:  Give a concise list of the top 5 stylistic shortcomings of the following abstract: \n     Generative AI, in particular large language models (LLMs) such as ChatGPT, has the potential to revolutionize research. I describe dozens of use cases along six domains in which LLMs are starting to become useful as both research assistants and tutors: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro tasks. Moreover, these gains will grow as the performance of AI systems across all of these domains will continue to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper offer instructions for how to get started and will provide regular updates on the latest capabilities of generative AI that are useful for economists.  \n       [+] click to expand\n   \n\n   \n\n   \n  Response (GPT-4):  \n[+] click to expand\n\n   \n   Lack of Clarity: The abstract uses jargon and technical terms without\n       providing clear definitions or explanations, making it difficult for\n       readers unfamiliar with the topic to understand.\n   Overuse of Passive Voice: The abstract frequently uses passive\n       voice, which can make the writing seem less direct and engaging.\n   Lack of Specificity: The abstract mentions \"dozens\n       of use cases\" and \"six domains\" but does not provide any specific examples or details.\n   Redundancy: The abstract repeats the idea of AI's potential benefits\n       for economists multiple times without adding new information.\n   Lack of Structure: The abstract does not have a clear structure\n       or flow, making it difficult for readers to follow the author's argument.\n\n\n\n\n\n\n\n\n   \n   \n         Follow-up Prompt:  Can you rewrite it to correct these shortcomings?\n   \n\n   \n\n   \n  Response (GPT-4):  Sure, here are the main corrections: \n[+] click to expand\n\n   Generative AI, specifically large language models (LLMs) like ChatGPT, holds the potential to transform research. This paper explores the application of LLMs in six key areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. For each area, I provide practical instructions and real-world examples, categorizing the usefulness of LLMs from experimental to highly beneficial.   The focus of this paper is on the potential benefits for economists. By leveraging generative AI, economists can automate micro tasks, leading to significant productivity gains. As AI systems continue to evolve, these benefits are expected to increase.   The paper also delves into the long-term implications of AI-powered cognitive automation for economic research. Accompanying online resources provide a step-by-step guide on how to get started with generative AI, along with regular updates on its latest capabilities beneficial for economists. \n\n\n\n\n\n   \n   \n         Analysis:  The shortcomings identified by the LLM are well-taken, and the rewritten version does a decent job of alleviating some but not all of them. \n   \n \n\n\n  \n\n\n  \n\n\n    \n    \n        Other useful LLM prompts for style evaluation include:\n         \n    Which arguments are the hardest to follow in the following text?\n    Evaluate the clarity and coherence of the following text.\n    Are there any ambiguities in the following text?\n\n\n\n        [+] click to expand\n    \n  \n\n\n\n\nThe vision capabilities of most advaned LLMs allow them to interpret images and follow instrucions on how to process them. This can be useful, for example, when typing up mathematical equations. The following example illustrates the concept.\n\n\n    \n    \n          Prompt:  Convert the attached image to LaTeX code.  \n       \\includegraphics[width=0.4\\textwidth]{Demos/prodfct4}\n\n        [+] click to expand\n    \n\n    \n\n    \n  Response (GPT-4):  The LaTeX code for the equation you provided would look like this: \n[+] click to expand\n\n    $$\n    Y=F(K,L)=AK^{\\alpha}L^{\\beta},\\quad\\alpha,\\beta\\leq0\n    $$\n    This LaTeX code will render the production function \\( Y \\) as a function of capital \\( K \\) and labor \\( L \\), with \\( A \\) representing total factor productivity, and \\( \\alpha \\) and \\( \\beta \\) as the output elasticities of capital and labor, respectively, which are both non-positive in this case.\n\n\n\n\n\n    \n    \n          Analysis:  The result is clearly still lacking: it omits the square brackets, turns the Cobb-Douglas function into a CES function, replacing the exponent \\( \\rho \\) with \\(\\alpha\\) and \\(\\beta\\), and omits the exponent outside the square brackets. Gemini performed about equally well as ChatGPT; Claude 3 fared slightly worse on this task.\n    \n  \n\n\n   \n\nAn alternative is MathPix.com , a dedicated tool to convert math in pictures to LaTeX. However, since GPT-4, LLMs have improved a great deal at this task.\n\n\n\nAnother useful application is to come up with catchy headlines or paper titles, as illustrated by the following example based on the version of the abstract used in the previous example:\n\n\n    \n    \n          Prompt:  Brainstorm two or three catchy titles for a paper with the following abstract: \n        [Abstract from previous Chat inserted]\n    \n\n    \n\n    \n      Response (GPT-4): \n    [+] click to expand\n    \n        \n            \"Revolutionizing Economic Research: The Power of Generative AI and Large Language Models\"\n            \"Unleashing AI in Economics: A Comprehensive Guide to Utilizing Large Language Models\"\n            \"The Future of Economic Research: Harnessing the Potential of Generative AI and Large Language Models\"\n        \n    \n\n\n\n\n    \n    \n         Follow-up Prompt:  Make them a bit more sober and keep them short. \n    \n\n    \n\n    \n      Response (GPT-4): \n    [+] click to expand\n    \n        \n            \"Generative AI in Economic Research\"\n            \"Large Language Models: A New Tool for Economists\"\n            \"The Role of AI in Modern Economic Studies\"\n        \n    \n\n\n\n    \n    \n          Analysis:  The suggested titles fit the described work quite well and adhere closely to the requested styles."
  },
  {
    "objectID": "subs/writing.html#synthesizing-text",
    "href": "subs/writing.html#synthesizing-text",
    "title": "Applications of LLMs",
    "section": "",
    "text": "One of the most useful capabilities of LLMs for writing assistance may be to translate rough bullet points into well-structured sentences that are clear and easy to read. The following is an example. Note that the bullets also include requests for the LLM to provide examples and offer solutions.\n\n\n    \n    \n          Prompt:  Write a paragraph in the style of an academic economist that integrates the following points. Include a topic sentence. \n       \n    Large language models (LLMs) automate many cognitive tasks.\n    The work of academic economists is largely cognitive (e.g., writing research papers, conducting data analysis, generating policy recommendations, reviewing literature).\n    We economists should therefore worry about recent progress in language models.\n    In the short run, these models can help us be more productive.\n    In the long run, there is a good likelihood that they will displace human economists.\n    We should think about how to prepare. [offer solutions] \n\n\n        [+] click to expand\n    \n\n    \n\n    \n  Response (GPT-4): \n[+] click to expand\n\n    The advent of large language models (LLMs) that automate a plethora of cognitive tasks presents a significant paradigm shift that academic economists should be cognizant of, given the cognitive nature of our work, which includes tasks such as data analysis, economic forecasting, and policy recommendation. The rapid advancements in language models could potentially disrupt our profession, necessitating a proactive approach to this emerging technology. In the short term, these models can augment our productivity by automating routine tasks, thereby allowing us to focus on more complex and nuanced aspects of economic research. However, in the long run, there is a substantial likelihood that these models could displace human economists, as they become increasingly adept at performing complex cognitive tasks. Consequently, it is incumbent upon us to prepare for this eventuality. This could involve developing a deeper understanding of these models to leverage their capabilities effectively, diversifying our skill sets to include areas not easily automated, and advocating for policies that ensure a just transition for those potentially displaced by these technological advancements.\n\n\n\n\n\n    \n    \n          Analysis:  Utilizing this allows researchers to concentrate their energy on the ideas in their text as opposed to the mundane writing process. The text is generally high-quality, although some claim that it is a bit sterile and may lack the idiosyncrasies and elements of surprise that characterize human writing.This is a feature that detectors of LLM-written text zero in on, for example the \n    This is a feature that detectors of LLM-written text zero in on, for example the tool \n    \n        GPTZero\n    . However, it should be noted that such tools are not always reliable and can easily be circumvented.\n\n\n    \n    \n  \n\n\n   \n\nLLMs are very responsive to requests to write in different styles.\n\n    \n    \n        I obtained both impressive and hilarious results when I replaced \"in the style of an academic economist\" with the request to write:\n         \n    in a colloquial style\n    in a style that is comprehensible to non-economists\n    in the style of {*enter your favorite economist, politician, \n    When I requested \"in the style of a gangster,\" the LLM started with \"Listen here, see, these big shot large language models (LLMs) are muscling in on our turf...\"\n*} \n\n\n\n        [+] click to expand\n    \n  \n\n\n  \n\n\nLLMs can also write text in LaTeX format, which automatically format mathematical expressions in the required format, and it can draft beamer slides in LaTeX code based on bullet points.\nWriting is of course a skill that is not only useful for research - cognitive workers in many areas report using, e.g., ChatGPT to draft emails, memos, performance reviews, or summaries based on a few bullet points. Likewise, professors report generating the first draft of letters of recommendation or syllabi using LLMs."
  },
  {
    "objectID": "subs/writing.html#editing-text",
    "href": "subs/writing.html#editing-text",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Another useful capability is editing. LLMs can edit text for grammatical or spelling mistakes, style, clarity, or simplicity. This set of capabilities is useful for all writers, but perhaps most for non-native speakers who want to improve their writing. In the following example, I have bolded each correction made by the LLM for emphasis:\n\n\n   \n   \n         Prompt:  Can you correct the following sentence?  \n   These paper describe six domain in which large language models (LLMs) displays emergant capbilities that are useful to the economic research.\n\n   \n\n   \n\n   \n  Response (GPT-4): This paper describes six domains in which large language models (LLMs) display emergent capabilities that are useful for economic research.\n\n\n\n\n\n   \n   \n         Follow-up Prompt:  Can you explain the main corrections you made? \n   \n\n   \n\n   \n  Response (GPT-4):  Sure, here are the main corrections: \n[+] click to expand\n\n   \n   \"These paper\" was corrected to \"This paper\". The subject-verb agreement was incorrect. If the subject is singular (like \"paper\"), the verb should also be singular (like \"describes\").\n   \"describe\" was corrected to \"describes\". The verb should match the singular subject \"paper\".\n   \"domain\" was corrected to \"domains\". The context implies that there are multiple domains, so the plural form should be used.\n   \"displays\" was corrected to \"display\". The subject \"LLMs\" is plural, so the verb should also be plural.\n   \"emergant\" was corrected to \"emergent\". This was a spelling mistake.\n   \"to the economic research\" was corrected to \"for economic research\". The preposition \"for\" is more appropriate in this context.\n\n\n\n\n\n\n   \n   \n         Analysis:  As illustrated in the follow-up question, the LLM can also largely explain its edits so that writers can learn from any corrections it has made. This latter capability has improved significantly going from GPT-3.5 to GPT-4. Notice, however, that it left out a seventh correction from the list -- it also corrected a typo in the word \"capabilities\". This highlights the need to carefully check the results of LLMs. \n   \n \n\n\n  \n\nAnother useful LLM application is to convert text to be comprehensible to readers of different levels, for example, using a prompt like “Rewrite the following text so that it is comprehensible to an eight-year-old”, “comprehensible to an eighth-grader,” or “comprehensible to a policymaker without economics education.”"
  },
  {
    "objectID": "subs/writing.html#evaluating-text",
    "href": "subs/writing.html#evaluating-text",
    "title": "Applications of LLMs",
    "section": "",
    "text": "LLMs can also evaluate text for its style, its clarity, or similar. The following question about a draft version of the abstract of this paper turned out to be a bit of a deflating experience:\n\n\n   \n   \n         Prompt:  Give a concise list of the top 5 stylistic shortcomings of the following abstract: \n     Generative AI, in particular large language models (LLMs) such as ChatGPT, has the potential to revolutionize research. I describe dozens of use cases along six domains in which LLMs are starting to become useful as both research assistants and tutors: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro tasks. Moreover, these gains will grow as the performance of AI systems across all of these domains will continue to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper offer instructions for how to get started and will provide regular updates on the latest capabilities of generative AI that are useful for economists.  \n       [+] click to expand\n   \n\n   \n\n   \n  Response (GPT-4):  \n[+] click to expand\n\n   \n   Lack of Clarity: The abstract uses jargon and technical terms without\n       providing clear definitions or explanations, making it difficult for\n       readers unfamiliar with the topic to understand.\n   Overuse of Passive Voice: The abstract frequently uses passive\n       voice, which can make the writing seem less direct and engaging.\n   Lack of Specificity: The abstract mentions \"dozens\n       of use cases\" and \"six domains\" but does not provide any specific examples or details.\n   Redundancy: The abstract repeats the idea of AI's potential benefits\n       for economists multiple times without adding new information.\n   Lack of Structure: The abstract does not have a clear structure\n       or flow, making it difficult for readers to follow the author's argument.\n\n\n\n\n\n\n\n\n   \n   \n         Follow-up Prompt:  Can you rewrite it to correct these shortcomings?\n   \n\n   \n\n   \n  Response (GPT-4):  Sure, here are the main corrections: \n[+] click to expand\n\n   Generative AI, specifically large language models (LLMs) like ChatGPT, holds the potential to transform research. This paper explores the application of LLMs in six key areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. For each area, I provide practical instructions and real-world examples, categorizing the usefulness of LLMs from experimental to highly beneficial.   The focus of this paper is on the potential benefits for economists. By leveraging generative AI, economists can automate micro tasks, leading to significant productivity gains. As AI systems continue to evolve, these benefits are expected to increase.   The paper also delves into the long-term implications of AI-powered cognitive automation for economic research. Accompanying online resources provide a step-by-step guide on how to get started with generative AI, along with regular updates on its latest capabilities beneficial for economists. \n\n\n\n\n\n   \n   \n         Analysis:  The shortcomings identified by the LLM are well-taken, and the rewritten version does a decent job of alleviating some but not all of them. \n   \n \n\n\n  \n\n\n  \n\n\n    \n    \n        Other useful LLM prompts for style evaluation include:\n         \n    Which arguments are the hardest to follow in the following text?\n    Evaluate the clarity and coherence of the following text.\n    Are there any ambiguities in the following text?\n\n\n\n        [+] click to expand"
  },
  {
    "objectID": "subs/writing.html#latex-transcription",
    "href": "subs/writing.html#latex-transcription",
    "title": "Applications of LLMs",
    "section": "",
    "text": "The vision capabilities of most advaned LLMs allow them to interpret images and follow instrucions on how to process them. This can be useful, for example, when typing up mathematical equations. The following example illustrates the concept.\n\n\n    \n    \n          Prompt:  Convert the attached image to LaTeX code.  \n       \\includegraphics[width=0.4\\textwidth]{Demos/prodfct4}\n\n        [+] click to expand\n    \n\n    \n\n    \n  Response (GPT-4):  The LaTeX code for the equation you provided would look like this: \n[+] click to expand\n\n    $$\n    Y=F(K,L)=AK^{\\alpha}L^{\\beta},\\quad\\alpha,\\beta\\leq0\n    $$\n    This LaTeX code will render the production function \\( Y \\) as a function of capital \\( K \\) and labor \\( L \\), with \\( A \\) representing total factor productivity, and \\( \\alpha \\) and \\( \\beta \\) as the output elasticities of capital and labor, respectively, which are both non-positive in this case.\n\n\n\n\n\n    \n    \n          Analysis:  The result is clearly still lacking: it omits the square brackets, turns the Cobb-Douglas function into a CES function, replacing the exponent \\( \\rho \\) with \\(\\alpha\\) and \\(\\beta\\), and omits the exponent outside the square brackets. Gemini performed about equally well as ChatGPT; Claude 3 fared slightly worse on this task.\n    \n  \n\n\n   \n\nAn alternative is MathPix.com , a dedicated tool to convert math in pictures to LaTeX. However, since GPT-4, LLMs have improved a great deal at this task."
  },
  {
    "objectID": "subs/writing.html#generating-titles",
    "href": "subs/writing.html#generating-titles",
    "title": "Applications of LLMs",
    "section": "",
    "text": "Another useful application is to come up with catchy headlines or paper titles, as illustrated by the following example based on the version of the abstract used in the previous example:\n\n\n    \n    \n          Prompt:  Brainstorm two or three catchy titles for a paper with the following abstract: \n        [Abstract from previous Chat inserted]\n    \n\n    \n\n    \n      Response (GPT-4): \n    [+] click to expand\n    \n        \n            \"Revolutionizing Economic Research: The Power of Generative AI and Large Language Models\"\n            \"Unleashing AI in Economics: A Comprehensive Guide to Utilizing Large Language Models\"\n            \"The Future of Economic Research: Harnessing the Potential of Generative AI and Large Language Models\"\n        \n    \n\n\n\n\n    \n    \n         Follow-up Prompt:  Make them a bit more sober and keep them short. \n    \n\n    \n\n    \n      Response (GPT-4): \n    [+] click to expand\n    \n        \n            \"Generative AI in Economic Research\"\n            \"Large Language Models: A New Tool for Economists\"\n            \"The Role of AI in Modern Economic Studies\"\n        \n    \n\n\n\n    \n    \n          Analysis:  The suggested titles fit the described work quite well and adhere closely to the requested styles."
  }
]